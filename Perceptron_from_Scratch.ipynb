{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Implementation of Perceptron from scratch"],"metadata":{"id":"yEHBPrgN7WfO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CjUkdDAvhry"},"outputs":[],"source":["import numpy as np\n","# import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["    # Training data for AND gate\n","    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","    y = np.array([0, 0, 0, 1])\n","\n","    # #Training data y=f(x)=2x+3\n","    # X = np.array([[1],[2],[3],[4],[5]])\n","    # y = np.array([5,7,9,11,13])"],"metadata":{"id":"J2goHBJkxJ2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def step(x,th):\n","  if x>=th:\n","    return(1)\n","  return(0)\n","\n","def linearInt(x):\n","  return (round(x))\n","\n","def predict(X, y, weights):\n","  print(\"X\\tActual\\tPredicted\")\n","  for x_input, y_output in zip(X, y):\n","    inSum=np.sum(x_input * weights)\n","    y_pred = step(inSum,th)\n","    print(x_input,\"\\t\",y_output,\"\\t\",y_pred)\n"],"metadata":{"id":"bW79_0U927Lj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize constants\n","lr = 0.1\n","th = 0.5\n","\n","# Initialize weights array\n","weights = []\n","\n","# Loop through each element in X\n","for i in range(X.shape[1]): #+1 for te bias\n","    # Initialize w randomly between 0 and 1 using Python's random module & Convert w to have only one digit after the decimal point\n","    w = round(np.random.rand(),1)\n","    weights.append(w)\n","\n","print(\"Randomly initialized weights for each input:\")\n","for i in range(len(weights)):\n","    print(f\"weights[{i}]:\", weights[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ah4lhaEoHRe","executionInfo":{"status":"ok","timestamp":1735788988173,"user_tz":-345,"elapsed":590,"user":{"displayName":"Krishna Bikram Shah","userId":"10978043201894471543"}},"outputId":"6f149f9c-d8aa-4364-fe21-e9c6352a23f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Randomly initialized weights for each input:\n","weights[0]: 0.4\n","weights[1]: 0.7\n"]}]},{"cell_type":"code","source":["# initialize constants\n","lr = 0.1\n","th = 0.5\n","\n","# Initialize weights array\n","weights = []\n","\n","# Loop through each element in X\n","for i in range(X.shape[1]): #+1 for te bias\n","    # Initialize w randomly between 0 and 1 using Python's random module & Convert w to have only one digit after the decimal point\n","    w = round(np.random.rand(),1)\n","    weights.append(w)\n","\n","print(\"Randomly initialized weights for each input:\")\n","for i in range(len(weights)):\n","    print(f\"weights[{i}]:\", weights[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQgMzDi24BKF","outputId":"fbb0bb9d-8754-440d-87f7-6e6d267ec8e7","executionInfo":{"status":"ok","timestamp":1735529775110,"user_tz":-345,"elapsed":351,"user":{"displayName":"Krishna Bikram Shah","userId":"10978043201894471543"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Randomly initialized weights for each input:\n","weights[0]: 0.9\n","weights[1]: 0.9\n"]}]},{"cell_type":"code","source":["#For AND/OR Logic Gates\n","# print (step(0.5,th))\n","iterateFlag = True\n","while (iterateFlag):\n","  iterateFlag = False\n","  for x_input, y_output in zip(X, y):\n","    inSum=np.sum(x_input * weights)\n","    y_pred = step(inSum,th)\n","    err = y_output - y_pred\n","    if(err!=0):\n","      iterateFlag = True\n","      for i in range(len(weights)):\n","        dw = lr * x_input[i] * err\n","        weights[i] = weights[i] + dw\n","      print(\"input:\",x_input, \"actual output:\",y_output,\"predicted output: \",y_pred,\"updated weights:\", weights)\n","\n","print(\"Final weights:\", weights)"],"metadata":{"id":"d4XKGgwY4YNN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735789264458,"user_tz":-345,"elapsed":468,"user":{"displayName":"Krishna Bikram Shah","userId":"10978043201894471543"}},"outputId":"7e75d7a7-9a19-45af-dd65-f3d49ca87071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.69]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6799999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6699999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6599999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6499999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6399999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6299999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6199999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.6099999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5999999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5899999999999999]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5799999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5699999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5599999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5499999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5399999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5299999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5199999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.5099999999999998]\n","input: [0 1] actual output: 0 predicted output:  1 updated weights: [0.4, 0.4999999999999998]\n","Final weights: [0.4, 0.4999999999999998]\n"]}]},{"cell_type":"code","source":["# for y=f(x)=2x+3\n","\n","iterateFlag = True\n","# Lists to store MSE values and epoch numbers\n","mse_values = []\n","epochs = []\n","epoch_count = 0\n","\n","while (iterateFlag):\n","  epoch_count += 1\n","  squared_errors = []\n","  iterateFlag = False\n","\n","  for x_input, y_output in zip(X, y):\n","    inSum = np.sum(x_input * weights)\n","    inSum += 1 * weights[len(weights)-1]\n","    # y_pred = step(inSum,th)\n","    y_pred = linearInt(inSum)\n","    err = y_output - y_pred\n","    squared_errors.append(err**2)\n","    if(err!=0):\n","      iterateFlag = True\n","      for i in range(len(weights)-1):\n","        dw = lr * x_input[i] * err\n","        weights[i] = weights[i] + dw\n","      weights[len(weights)-1] += lr * np.sum(err)\n","      print(\"input:\",x_input, \"actual output:\",y_output,\"predicted output: \",y_pred,\"updated weights:\", weights)\n","  mse = np.mean(squared_errors)\n","  mse_values.append(mse)\n","  epochs.append(epoch_count)\n","print(\"Final weights:\", weights)\n","\n","\n","# Plot MSE vs. Epochs\n","plt.figure(figsize=(20, 6))  # Set figure size wider\n","plt.plot(epochs, mse_values, marker='o', linestyle='None', color='blue')  # Plot MSE values as dots\n","plt.xlabel('Epochs')\n","plt.ylabel('Mean Squared Error (MSE)')\n","plt.title('MSE vs. Epochs')\n","plt.grid(True)  # Add grid\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Mwtb4IIwFQE-","outputId":"b7ddf49e-7304-4a5a-fce3-433d0eceb1c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input: [1] actual output: 5 predicted output:  2 updated weights: [0.53, 0.53]\n","input: [2] actual output: 7 predicted output:  3 updated weights: [0.61, 0.5700000000000001]\n","input: [3] actual output: 9 predicted output:  4 updated weights: [0.76, 0.6200000000000001]\n","input: [4] actual output: 11 predicted output:  6 updated weights: [0.96, 0.6700000000000002]\n","input: [5] actual output: 13 predicted output:  9 updated weights: [1.16, 0.7100000000000002]\n","input: [1] actual output: 5 predicted output:  3 updated weights: [1.18, 0.7300000000000002]\n","input: [2] actual output: 7 predicted output:  5 updated weights: [1.22, 0.7500000000000002]\n","input: [3] actual output: 9 predicted output:  7 updated weights: [1.28, 0.7700000000000002]\n","input: [4] actual output: 11 predicted output:  9 updated weights: [1.36, 0.7900000000000003]\n","input: [5] actual output: 13 predicted output:  12 updated weights: [1.4100000000000001, 0.8000000000000003]\n","input: [1] actual output: 5 predicted output:  3 updated weights: [1.4300000000000002, 0.8200000000000003]\n","input: [2] actual output: 7 predicted output:  5 updated weights: [1.4700000000000002, 0.8400000000000003]\n","input: [3] actual output: 9 predicted output:  8 updated weights: [1.5000000000000002, 0.8500000000000003]\n","input: [4] actual output: 11 predicted output:  10 updated weights: [1.5400000000000003, 0.8600000000000003]\n","input: [1] actual output: 5 predicted output:  3 updated weights: [1.5600000000000003, 0.8800000000000003]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.5800000000000003, 0.8900000000000003]\n","input: [3] actual output: 9 predicted output:  8 updated weights: [1.6100000000000003, 0.9000000000000004]\n","input: [1] actual output: 5 predicted output:  3 updated weights: [1.6300000000000003, 0.9200000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.6500000000000004, 0.9300000000000004]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.6000000000000003, 0.9200000000000004]\n","input: [1] actual output: 5 predicted output:  3 updated weights: [1.6200000000000003, 0.9400000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.6400000000000003, 0.9500000000000004]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.5900000000000003, 0.9400000000000004]\n","input: [1] actual output: 5 predicted output:  3 updated weights: [1.6100000000000003, 0.9600000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.6300000000000003, 0.9700000000000004]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.5800000000000003, 0.9600000000000004]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.5900000000000003, 0.9700000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.6100000000000003, 0.9800000000000004]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.5600000000000003, 0.9700000000000004]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.5700000000000003, 0.9800000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.5900000000000003, 0.9900000000000004]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.5400000000000003, 0.9800000000000004]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.5500000000000003, 0.9900000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.5700000000000003, 1.0000000000000004]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.5200000000000002, 0.9900000000000004]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.5300000000000002, 1.0000000000000004]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.5500000000000003, 1.0100000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.5000000000000002, 1.0000000000000004]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.5100000000000002, 1.0100000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.5300000000000002, 1.0200000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.4800000000000002, 1.0100000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.4900000000000002, 1.0200000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.5100000000000002, 1.0300000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.4600000000000002, 1.0200000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.4700000000000002, 1.0300000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4900000000000002, 1.0400000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.4400000000000002, 1.0300000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.4500000000000002, 1.0400000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4700000000000002, 1.0500000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.4200000000000002, 1.0400000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.4300000000000002, 1.0500000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4500000000000002, 1.0600000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.4000000000000001, 1.0500000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.4100000000000001, 1.0600000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4300000000000002, 1.0700000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.3800000000000001, 1.0600000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.3900000000000001, 1.0700000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4100000000000001, 1.0800000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.36, 1.0700000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.37, 1.0800000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.3900000000000001, 1.0900000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.4000000000000001, 1.1000000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4200000000000002, 1.1100000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.37, 1.1000000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.3800000000000001, 1.1100000000000005]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.4000000000000001, 1.1200000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.35, 1.1100000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.36, 1.1200000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.3800000000000001, 1.1300000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.33, 1.1200000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.34, 1.1300000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.36, 1.1400000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.31, 1.1300000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.32, 1.1400000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.34, 1.1500000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.29, 1.1400000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.3, 1.1500000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.32, 1.1600000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.27, 1.1500000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.28, 1.1600000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.3, 1.1700000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.25, 1.1600000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.26, 1.1700000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.28, 1.1800000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.29, 1.1900000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.31, 1.2000000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.26, 1.1900000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.27, 1.2000000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.29, 1.2100000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.24, 1.2000000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.25, 1.2100000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.27, 1.2200000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.22, 1.2100000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.23, 1.2200000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.25, 1.2300000000000006]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.2, 1.2200000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.21, 1.2300000000000006]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.23, 1.2400000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.18, 1.2300000000000006]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.19, 1.2400000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.21, 1.2500000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.16, 1.2400000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.17, 1.2500000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.19, 1.2600000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.14, 1.2500000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.15, 1.2600000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.17, 1.2700000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.18, 1.2800000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.2, 1.2900000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.15, 1.2800000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.16, 1.2900000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.18, 1.3000000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.13, 1.2900000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.14, 1.3000000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.16, 1.3100000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.1099999999999999, 1.3000000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.1199999999999999, 1.3100000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.14, 1.3200000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.0899999999999999, 1.3100000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0999999999999999, 1.3200000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.1199999999999999, 1.3300000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.0699999999999998, 1.3200000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0799999999999998, 1.3300000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0999999999999999, 1.3400000000000007]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.0499999999999998, 1.3300000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0599999999999998, 1.3400000000000007]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0799999999999998, 1.3500000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.0299999999999998, 1.3400000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0399999999999998, 1.3500000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0599999999999998, 1.3600000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0699999999999998, 1.3700000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0899999999999999, 1.3800000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.0399999999999998, 1.3700000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0499999999999998, 1.3800000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0699999999999998, 1.3900000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [1.0199999999999998, 1.3800000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0299999999999998, 1.3900000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0499999999999998, 1.4000000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9999999999999998, 1.3900000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [1.0099999999999998, 1.4000000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0299999999999998, 1.4100000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9799999999999998, 1.4000000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9899999999999998, 1.4100000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [1.0099999999999998, 1.4200000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9599999999999997, 1.4100000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9699999999999998, 1.4200000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9899999999999998, 1.4300000000000008]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9399999999999997, 1.4200000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9499999999999997, 1.4300000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9699999999999998, 1.4400000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9799999999999998, 1.4500000000000008]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9999999999999998, 1.4600000000000009]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9499999999999997, 1.4500000000000008]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9599999999999997, 1.4600000000000009]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9799999999999998, 1.4700000000000009]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9299999999999997, 1.4600000000000009]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9399999999999997, 1.4700000000000009]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9599999999999997, 1.4800000000000009]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.9099999999999997, 1.4700000000000009]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.9199999999999997, 1.4800000000000009]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9399999999999997, 1.4900000000000009]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.8899999999999997, 1.4800000000000009]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8999999999999997, 1.4900000000000009]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.9199999999999997, 1.5000000000000009]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.8699999999999997, 1.4900000000000009]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8799999999999997, 1.5000000000000009]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8999999999999997, 1.510000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.8499999999999996, 1.5000000000000009]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8599999999999997, 1.510000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8799999999999997, 1.520000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.8299999999999996, 1.510000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8399999999999996, 1.520000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8599999999999997, 1.530000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8699999999999997, 1.540000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8899999999999997, 1.550000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.8399999999999996, 1.540000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8499999999999996, 1.550000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8699999999999997, 1.560000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.8199999999999996, 1.550000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8299999999999996, 1.560000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8499999999999996, 1.570000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7999999999999996, 1.560000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.8099999999999996, 1.570000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8299999999999996, 1.580000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7799999999999996, 1.570000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7899999999999996, 1.580000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.8099999999999996, 1.590000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7599999999999996, 1.580000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7699999999999996, 1.590000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7899999999999996, 1.600000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7399999999999995, 1.590000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7499999999999996, 1.600000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7699999999999996, 1.610000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7199999999999995, 1.600000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7299999999999995, 1.610000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7499999999999996, 1.620000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7599999999999996, 1.630000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7799999999999996, 1.640000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7299999999999995, 1.630000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7399999999999995, 1.640000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7599999999999996, 1.650000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.7099999999999995, 1.640000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.7199999999999995, 1.650000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7399999999999995, 1.660000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.6899999999999995, 1.650000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6999999999999995, 1.660000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.7199999999999995, 1.670000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.6699999999999995, 1.660000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6799999999999995, 1.670000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6999999999999995, 1.680000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.6499999999999995, 1.670000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6599999999999995, 1.680000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6799999999999995, 1.690000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.6299999999999994, 1.680000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6399999999999995, 1.690000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6599999999999995, 1.700000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.6099999999999994, 1.690000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6199999999999994, 1.700000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6399999999999995, 1.710000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6499999999999995, 1.720000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6699999999999995, 1.730000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.6199999999999994, 1.720000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6299999999999994, 1.730000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6499999999999995, 1.740000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.5999999999999994, 1.730000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.6099999999999994, 1.740000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6299999999999994, 1.750000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.5799999999999994, 1.740000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5899999999999994, 1.750000000000001]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.6099999999999994, 1.7600000000000011]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.5599999999999994, 1.750000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5699999999999994, 1.7600000000000011]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.5899999999999994, 1.7700000000000011]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.5399999999999994, 1.7600000000000011]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5499999999999994, 1.7700000000000011]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.5699999999999994, 1.7800000000000011]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.5199999999999994, 1.7700000000000011]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5299999999999994, 1.7800000000000011]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.5499999999999994, 1.7900000000000011]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5599999999999994, 1.8000000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.5099999999999993, 1.7900000000000011]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5199999999999994, 1.8000000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.5399999999999994, 1.8100000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.4899999999999994, 1.8000000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.4999999999999994, 1.8100000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.5199999999999994, 1.8200000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.46999999999999936, 1.8100000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.47999999999999937, 1.8200000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.4999999999999994, 1.8300000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.5099999999999993, 1.8400000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.45999999999999935, 1.8300000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.46999999999999936, 1.8400000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.4899999999999994, 1.8500000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.4399999999999994, 1.8400000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.4499999999999994, 1.8500000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.4699999999999994, 1.8600000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.41999999999999943, 1.8500000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.42999999999999944, 1.8600000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.44999999999999946, 1.8700000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.45999999999999946, 1.8800000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.4099999999999995, 1.8700000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.4199999999999995, 1.8800000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.4399999999999995, 1.8900000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.3899999999999995, 1.8800000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3999999999999995, 1.8900000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.41999999999999954, 1.9000000000000012]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.36999999999999955, 1.8900000000000012]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.37999999999999956, 1.9000000000000012]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.3999999999999996, 1.9100000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.4099999999999996, 1.9200000000000013]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.3599999999999996, 1.9100000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3699999999999996, 1.9200000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3799999999999996, 1.9300000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3899999999999996, 1.9400000000000013]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.33999999999999964, 1.9300000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.34999999999999964, 1.9400000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.35999999999999965, 1.9500000000000013]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.30999999999999966, 1.9400000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3199999999999997, 1.9500000000000013]\n","input: [2] actual output: 7 predicted output:  6 updated weights: [0.3399999999999997, 1.9600000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3499999999999997, 1.9700000000000013]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.2999999999999997, 1.9600000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.3099999999999997, 1.9700000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.31999999999999973, 1.9800000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.32999999999999974, 1.9900000000000013]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.27999999999999975, 1.9800000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.28999999999999976, 1.9900000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.29999999999999977, 2.0000000000000013]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.24999999999999978, 1.9900000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.2599999999999998, 2.0000000000000013]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.2699999999999998, 2.010000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.2799999999999998, 2.020000000000001]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.22999999999999982, 2.010000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.23999999999999982, 2.020000000000001]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.24999999999999983, 2.0300000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.25999999999999984, 2.0400000000000005]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.20999999999999985, 2.0300000000000007]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.21999999999999986, 2.0400000000000005]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.22999999999999987, 2.0500000000000003]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.23999999999999988, 2.06]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.1899999999999999, 2.0500000000000003]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.1999999999999999, 2.06]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.2099999999999999, 2.07]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.21999999999999992, 2.0799999999999996]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.16999999999999993, 2.07]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.17999999999999994, 2.0799999999999996]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.18999999999999995, 2.0899999999999994]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.19999999999999996, 2.099999999999999]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.14999999999999997, 2.0899999999999994]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.15999999999999998, 2.099999999999999]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.16999999999999998, 2.109999999999999]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.11999999999999998, 2.099999999999999]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.12999999999999998, 2.109999999999999]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.13999999999999999, 2.1199999999999988]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.15, 2.1299999999999986]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.09999999999999999, 2.1199999999999988]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.10999999999999999, 2.1299999999999986]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.11999999999999998, 2.1399999999999983]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.12999999999999998, 2.149999999999998]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.07999999999999997, 2.1399999999999983]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.08999999999999997, 2.149999999999998]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.09999999999999996, 2.159999999999998]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.10999999999999996, 2.1699999999999977]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.059999999999999956, 2.159999999999998]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.06999999999999995, 2.1699999999999977]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.07999999999999995, 2.1799999999999975]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.08999999999999994, 2.1899999999999973]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.03999999999999994, 2.1799999999999975]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.04999999999999994, 2.1899999999999973]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.05999999999999994, 2.199999999999997]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.06999999999999994, 2.209999999999997]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [0.019999999999999934, 2.199999999999997]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.029999999999999936, 2.209999999999997]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.03999999999999994, 2.2199999999999966]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [-0.010000000000000064, 2.209999999999997]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [-6.418476861114186e-17, 2.2199999999999966]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.009999999999999936, 2.2299999999999964]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [0.019999999999999934, 2.239999999999996]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [-0.03000000000000007, 2.2299999999999964]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [-0.020000000000000066, 2.239999999999996]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [-0.010000000000000066, 2.249999999999996]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [-6.591949208711867e-17, 2.259999999999996]\n","input: [5] actual output: 13 predicted output:  14 updated weights: [-0.05000000000000007, 2.249999999999996]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [-0.04000000000000007, 2.259999999999996]\n","input: [1] actual output: 5 predicted output:  4 updated weights: [-0.03000000000000007, 2.2699999999999956]\n","Final weights: [-0.03000000000000007, 2.2699999999999956]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to calculate Mean Squared Error (MSE)\n","def calculate_mse(y_true, y_pred):\n","    return np.mean((y_true - y_pred)**2)\n","\n","# Training data\n","X = np.array([[1], [2], [3], [4], [5]])\n","y = np.array([5, 7, 9, 11, 13])\n","\n","# Initialize weights\n","weights = np.array([0.1, 0.3])\n","\n","# Learning rate\n","lr = 0.01\n","\n","# Threshold\n","th = 0.5\n","\n","# Activation function (linear)\n","def linearInt(x):\n","    return x\n","\n","# Lists to store MSE values and epoch numbers\n","mse_values = []\n","epochs = []\n","epoch_count = 0\n","\n","# Training loop\n","iterateFlag = True\n","while iterateFlag:\n","    epoch_count += 1\n","    squared_errors = []\n","    iterateFlag = False\n","\n","    for x_input, y_output in zip(X, y):\n","        inSum = np.sum(x_input * weights)\n","        inSum += 1 * weights[-1]\n","        y_pred = linearInt(inSum)\n","        err = y_output - y_pred\n","        squared_errors.append(err**2)\n","        if err != 0:\n","            iterateFlag = True\n","            for i in range(len(weights)-1):\n","                dw = lr * x_input[i] * err\n","                weights[i] = round(weights[i] + dw, 3)  # Round to 3 decimal points\n","            weights[-1] = round(weights[-1] + lr * np.sum(err), 3)  # Round to 3 decimal points\n","            print(\"input:\", x_input, \"actual output:\", y_output, \"predicted output:\", y_pred, \"updated weights:\", weights)\n","    mse = np.mean(squared_errors)\n","    mse_values.append(mse)\n","    epochs.append(epoch_count)\n","\n","print(\"Final weights:\", weights)\n","\n","# Plot MSE vs. Epochs\n","plt.plot(epochs, mse_values)\n","plt.xlabel('Epochs')\n","plt.ylabel('Mean Squared Error (MSE)')\n","plt.title('MSE vs. Epochs')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iuKkR4FZLpdZ","outputId":"be90d3f5-9dc4-4ad3-c652-a0529439755e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","input: [3] actual output: 9 predicted output: 8.84 updated weights: [0.677 1.708]\n","input: [4] actual output: 11 predicted output: 11.248 updated weights: [0.667 1.706]\n","input: [5] actual output: 13 predicted output: 13.570999999999998 updated weights: [0.638 1.7  ]\n","input: [1] actual output: 5 predicted output: 4.038 updated weights: [0.648 1.71 ]\n","input: [2] actual output: 7 predicted output: 6.426 updated weights: [0.659 1.716]\n","input: [3] actual output: 9 predicted output: 8.841 updated weights: [0.664 1.718]\n","input: [4] actual output: 11 predicted output: 11.246 updated weights: [0.654 1.716]\n","input: [5] actual output: 13 predicted output: 13.565999999999999 updated weights: [0.626 1.71 ]\n","input: [1] actual output: 5 predicted output: 4.045999999999999 updated weights: [0.636 1.72 ]\n","input: [2] actual output: 7 predicted output: 6.4319999999999995 updated weights: [0.647 1.726]\n","input: [3] actual output: 9 predicted output: 8.844999999999999 updated weights: [0.652 1.728]\n","input: [4] actual output: 11 predicted output: 11.248 updated weights: [0.642 1.726]\n","input: [5] actual output: 13 predicted output: 13.565999999999999 updated weights: [0.614 1.72 ]\n","input: [1] actual output: 5 predicted output: 4.054 updated weights: [0.623 1.729]\n","input: [2] actual output: 7 predicted output: 6.433000000000001 updated weights: [0.634 1.735]\n","input: [3] actual output: 9 predicted output: 8.842 updated weights: [0.639 1.737]\n","input: [4] actual output: 11 predicted output: 11.241000000000001 updated weights: [0.629 1.735]\n","input: [5] actual output: 13 predicted output: 13.555 updated weights: [0.601 1.729]\n","input: [1] actual output: 5 predicted output: 4.059 updated weights: [0.61  1.738]\n","input: [2] actual output: 7 predicted output: 6.433999999999999 updated weights: [0.621 1.744]\n","input: [3] actual output: 9 predicted output: 8.839 updated weights: [0.626 1.746]\n","input: [4] actual output: 11 predicted output: 11.234 updated weights: [0.617 1.744]\n","input: [5] actual output: 13 predicted output: 13.549 updated weights: [0.59  1.739]\n","input: [1] actual output: 5 predicted output: 4.0680000000000005 updated weights: [0.599 1.748]\n","input: [2] actual output: 7 predicted output: 6.442 updated weights: [0.61  1.754]\n","input: [3] actual output: 9 predicted output: 8.846 updated weights: [0.615 1.756]\n","input: [4] actual output: 11 predicted output: 11.24 updated weights: [0.605 1.754]\n","input: [5] actual output: 13 predicted output: 13.549 updated weights: [0.578 1.749]\n","input: [1] actual output: 5 predicted output: 4.0760000000000005 updated weights: [0.587 1.758]\n","input: [2] actual output: 7 predicted output: 6.4479999999999995 updated weights: [0.598 1.764]\n","input: [3] actual output: 9 predicted output: 8.85 updated weights: [0.602 1.766]\n","input: [4] actual output: 11 predicted output: 11.238 updated weights: [0.592 1.764]\n","input: [5] actual output: 13 predicted output: 13.544 updated weights: [0.565 1.759]\n","input: [1] actual output: 5 predicted output: 4.083 updated weights: [0.574 1.768]\n","input: [2] actual output: 7 predicted output: 6.452 updated weights: [0.585 1.773]\n","input: [3] actual output: 9 predicted output: 8.847 updated weights: [0.59  1.775]\n","input: [4] actual output: 11 predicted output: 11.235 updated weights: [0.581 1.773]\n","input: [5] actual output: 13 predicted output: 13.543 updated weights: [0.554 1.768]\n","input: [1] actual output: 5 predicted output: 4.09 updated weights: [0.563 1.777]\n","input: [2] actual output: 7 predicted output: 6.457 updated weights: [0.574 1.782]\n","input: [3] actual output: 9 predicted output: 8.85 updated weights: [0.578 1.784]\n","input: [4] actual output: 11 predicted output: 11.232000000000001 updated weights: [0.569 1.782]\n","input: [5] actual output: 13 predicted output: 13.536999999999999 updated weights: [0.542 1.777]\n","input: [1] actual output: 5 predicted output: 4.096 updated weights: [0.551 1.786]\n","input: [2] actual output: 7 predicted output: 6.460000000000001 updated weights: [0.562 1.791]\n","input: [3] actual output: 9 predicted output: 8.85 updated weights: [0.567 1.792]\n","input: [4] actual output: 11 predicted output: 11.228 updated weights: [0.558 1.79 ]\n","input: [5] actual output: 13 predicted output: 13.529999999999998 updated weights: [0.532 1.785]\n","input: [1] actual output: 5 predicted output: 4.102 updated weights: [0.541 1.794]\n","input: [2] actual output: 7 predicted output: 6.464 updated weights: [0.552 1.799]\n","input: [3] actual output: 9 predicted output: 8.852 updated weights: [0.556 1.8  ]\n","input: [4] actual output: 11 predicted output: 11.224 updated weights: [0.547 1.798]\n","input: [5] actual output: 13 predicted output: 13.523000000000001 updated weights: [0.521 1.793]\n","input: [1] actual output: 5 predicted output: 4.107 updated weights: [0.53  1.802]\n","input: [2] actual output: 7 predicted output: 6.465999999999999 updated weights: [0.541 1.807]\n","input: [3] actual output: 9 predicted output: 8.850999999999999 updated weights: [0.545 1.808]\n","input: [4] actual output: 11 predicted output: 11.22 updated weights: [0.536 1.806]\n","input: [5] actual output: 13 predicted output: 13.516000000000002 updated weights: [0.51  1.801]\n","input: [1] actual output: 5 predicted output: 4.112 updated weights: [0.519 1.81 ]\n","input: [2] actual output: 7 predicted output: 6.468 updated weights: [0.53  1.815]\n","input: [3] actual output: 9 predicted output: 8.85 updated weights: [0.535 1.816]\n","input: [4] actual output: 11 predicted output: 11.22 updated weights: [0.526 1.814]\n","input: [5] actual output: 13 predicted output: 13.514 updated weights: [0.5   1.809]\n","input: [1] actual output: 5 predicted output: 4.118 updated weights: [0.509 1.818]\n","input: [2] actual output: 7 predicted output: 6.4719999999999995 updated weights: [0.52  1.823]\n","input: [3] actual output: 9 predicted output: 8.852 updated weights: [0.524 1.824]\n","input: [4] actual output: 11 predicted output: 11.216 updated weights: [0.515 1.822]\n","input: [5] actual output: 13 predicted output: 13.506999999999998 updated weights: [0.49  1.817]\n","input: [1] actual output: 5 predicted output: 4.124 updated weights: [0.499 1.826]\n","input: [2] actual output: 7 predicted output: 6.476000000000001 updated weights: [0.509 1.831]\n","input: [3] actual output: 9 predicted output: 8.851 updated weights: [0.513 1.832]\n","input: [4] actual output: 11 predicted output: 11.212000000000002 updated weights: [0.505 1.83 ]\n","input: [5] actual output: 13 predicted output: 13.505 updated weights: [0.48  1.825]\n","input: [1] actual output: 5 predicted output: 4.13 updated weights: [0.489 1.834]\n","input: [2] actual output: 7 predicted output: 6.48 updated weights: [0.499 1.839]\n","input: [3] actual output: 9 predicted output: 8.853 updated weights: [0.503 1.84 ]\n","input: [4] actual output: 11 predicted output: 11.212 updated weights: [0.495 1.838]\n","input: [5] actual output: 13 predicted output: 13.503 updated weights: [0.47  1.833]\n","input: [1] actual output: 5 predicted output: 4.136 updated weights: [0.479 1.842]\n","input: [2] actual output: 7 predicted output: 6.484 updated weights: [0.489 1.847]\n","input: [3] actual output: 9 predicted output: 8.855 updated weights: [0.493 1.848]\n","input: [4] actual output: 11 predicted output: 11.212000000000002 updated weights: [0.485 1.846]\n","input: [5] actual output: 13 predicted output: 13.501000000000001 updated weights: [0.46  1.841]\n","input: [1] actual output: 5 predicted output: 4.142 updated weights: [0.469 1.85 ]\n","input: [2] actual output: 7 predicted output: 6.4879999999999995 updated weights: [0.479 1.855]\n","input: [3] actual output: 9 predicted output: 8.857 updated weights: [0.483 1.856]\n","input: [4] actual output: 11 predicted output: 11.212 updated weights: [0.475 1.854]\n","input: [5] actual output: 13 predicted output: 13.498999999999999 updated weights: [0.45  1.849]\n","input: [1] actual output: 5 predicted output: 4.148 updated weights: [0.459 1.858]\n","input: [2] actual output: 7 predicted output: 6.492000000000001 updated weights: [0.469 1.863]\n","input: [3] actual output: 9 predicted output: 8.859 updated weights: [0.473 1.864]\n","input: [4] actual output: 11 predicted output: 11.212000000000002 updated weights: [0.465 1.862]\n","input: [5] actual output: 13 predicted output: 13.497000000000002 updated weights: [0.44  1.857]\n","input: [1] actual output: 5 predicted output: 4.154 updated weights: [0.448 1.865]\n","input: [2] actual output: 7 predicted output: 6.4910000000000005 updated weights: [0.458 1.87 ]\n","input: [3] actual output: 9 predicted output: 8.854 updated weights: [0.462 1.871]\n","input: [4] actual output: 11 predicted output: 11.203000000000001 updated weights: [0.454 1.869]\n","input: [5] actual output: 13 predicted output: 13.484 updated weights: [0.43  1.864]\n","input: [1] actual output: 5 predicted output: 4.158 updated weights: [0.438 1.872]\n","input: [2] actual output: 7 predicted output: 6.492 updated weights: [0.448 1.877]\n","input: [3] actual output: 9 predicted output: 8.852 updated weights: [0.452 1.878]\n","input: [4] actual output: 11 predicted output: 11.198 updated weights: [0.444 1.876]\n","input: [5] actual output: 13 predicted output: 13.475999999999999 updated weights: [0.42  1.871]\n","input: [1] actual output: 5 predicted output: 4.162 updated weights: [0.428 1.879]\n","input: [2] actual output: 7 predicted output: 6.493 updated weights: [0.438 1.884]\n","input: [3] actual output: 9 predicted output: 8.85 updated weights: [0.442 1.886]\n","input: [4] actual output: 11 predicted output: 11.197999999999999 updated weights: [0.434 1.884]\n","input: [5] actual output: 13 predicted output: 13.474 updated weights: [0.41  1.879]\n","input: [1] actual output: 5 predicted output: 4.168 updated weights: [0.418 1.887]\n","input: [2] actual output: 7 predicted output: 6.497 updated weights: [0.428 1.892]\n","input: [3] actual output: 9 predicted output: 8.852 updated weights: [0.432 1.893]\n","input: [4] actual output: 11 predicted output: 11.193000000000001 updated weights: [0.424 1.891]\n","input: [5] actual output: 13 predicted output: 13.466 updated weights: [0.401 1.886]\n","input: [1] actual output: 5 predicted output: 4.173 updated weights: [0.409 1.894]\n","input: [2] actual output: 7 predicted output: 6.5 updated weights: [0.419 1.899]\n","input: [3] actual output: 9 predicted output: 8.853 updated weights: [0.423 1.9  ]\n","input: [4] actual output: 11 predicted output: 11.192 updated weights: [0.415 1.898]\n","input: [5] actual output: 13 predicted output: 13.463 updated weights: [0.392 1.893]\n","input: [1] actual output: 5 predicted output: 4.178 updated weights: [0.4   1.901]\n","input: [2] actual output: 7 predicted output: 6.503 updated weights: [0.41  1.906]\n","input: [3] actual output: 9 predicted output: 8.854000000000001 updated weights: [0.414 1.907]\n","input: [4] actual output: 11 predicted output: 11.191 updated weights: [0.406 1.905]\n","input: [5] actual output: 13 predicted output: 13.459999999999999 updated weights: [0.383 1.9  ]\n","input: [1] actual output: 5 predicted output: 4.183 updated weights: [0.391 1.908]\n","input: [2] actual output: 7 predicted output: 6.506 updated weights: [0.401 1.913]\n","input: [3] actual output: 9 predicted output: 8.855 updated weights: [0.405 1.914]\n","input: [4] actual output: 11 predicted output: 11.19 updated weights: [0.397 1.912]\n","input: [5] actual output: 13 predicted output: 13.456999999999997 updated weights: [0.374 1.907]\n","input: [1] actual output: 5 predicted output: 4.188000000000001 updated weights: [0.382 1.915]\n","input: [2] actual output: 7 predicted output: 6.509 updated weights: [0.392 1.92 ]\n","input: [3] actual output: 9 predicted output: 8.856 updated weights: [0.396 1.921]\n","input: [4] actual output: 11 predicted output: 11.189 updated weights: [0.388 1.919]\n","input: [5] actual output: 13 predicted output: 13.454 updated weights: [0.365 1.914]\n","input: [1] actual output: 5 predicted output: 4.193 updated weights: [0.373 1.922]\n","input: [2] actual output: 7 predicted output: 6.512 updated weights: [0.383 1.927]\n","input: [3] actual output: 9 predicted output: 8.857000000000001 updated weights: [0.387 1.928]\n","input: [4] actual output: 11 predicted output: 11.187999999999999 updated weights: [0.379 1.926]\n","input: [5] actual output: 13 predicted output: 13.450999999999999 updated weights: [0.356 1.921]\n","input: [1] actual output: 5 predicted output: 4.198 updated weights: [0.364 1.929]\n","input: [2] actual output: 7 predicted output: 6.515000000000001 updated weights: [0.374 1.934]\n","input: [3] actual output: 9 predicted output: 8.857999999999999 updated weights: [0.378 1.935]\n","input: [4] actual output: 11 predicted output: 11.187000000000001 updated weights: [0.371 1.933]\n","input: [5] actual output: 13 predicted output: 13.453000000000001 updated weights: [0.348 1.928]\n","input: [1] actual output: 5 predicted output: 4.204 updated weights: [0.356 1.936]\n","input: [2] actual output: 7 predicted output: 6.52 updated weights: [0.366 1.941]\n","input: [3] actual output: 9 predicted output: 8.862 updated weights: [0.37  1.942]\n","input: [4] actual output: 11 predicted output: 11.19 updated weights: [0.362 1.94 ]\n","input: [5] actual output: 13 predicted output: 13.45 updated weights: [0.34  1.936]\n","input: [1] actual output: 5 predicted output: 4.212 updated weights: [0.348 1.944]\n","input: [2] actual output: 7 predicted output: 6.528 updated weights: [0.357 1.949]\n","input: [3] actual output: 9 predicted output: 8.867 updated weights: [0.361 1.95 ]\n","input: [4] actual output: 11 predicted output: 11.193999999999999 updated weights: [0.353 1.948]\n","input: [5] actual output: 13 predicted output: 13.453000000000001 updated weights: [0.33  1.943]\n","input: [1] actual output: 5 predicted output: 4.216 updated weights: [0.338 1.951]\n","input: [2] actual output: 7 predicted output: 6.529 updated weights: [0.347 1.956]\n","input: [3] actual output: 9 predicted output: 8.865 updated weights: [0.351 1.957]\n","input: [4] actual output: 11 predicted output: 11.189 updated weights: [0.343 1.955]\n","input: [5] actual output: 13 predicted output: 13.445 updated weights: [0.321 1.951]\n","input: [1] actual output: 5 predicted output: 4.223000000000001 updated weights: [0.329 1.959]\n","input: [2] actual output: 7 predicted output: 6.535 updated weights: [0.338 1.964]\n","input: [3] actual output: 9 predicted output: 8.87 updated weights: [0.342 1.965]\n","input: [4] actual output: 11 predicted output: 11.193 updated weights: [0.334 1.963]\n","input: [5] actual output: 13 predicted output: 13.448 updated weights: [0.312 1.959]\n","input: [1] actual output: 5 predicted output: 4.23 updated weights: [0.32  1.967]\n","input: [2] actual output: 7 predicted output: 6.541 updated weights: [0.329 1.972]\n","input: [3] actual output: 9 predicted output: 8.875 updated weights: [0.333 1.973]\n","input: [4] actual output: 11 predicted output: 11.197000000000001 updated weights: [0.325 1.971]\n","input: [5] actual output: 13 predicted output: 13.451 updated weights: [0.302 1.966]\n","input: [1] actual output: 5 predicted output: 4.234 updated weights: [0.31  1.974]\n","input: [2] actual output: 7 predicted output: 6.542 updated weights: [0.319 1.979]\n","input: [3] actual output: 9 predicted output: 8.873000000000001 updated weights: [0.323 1.98 ]\n","input: [4] actual output: 11 predicted output: 11.192 updated weights: [0.315 1.978]\n","input: [5] actual output: 13 predicted output: 13.443 updated weights: [0.293 1.974]\n","input: [1] actual output: 5 predicted output: 4.241 updated weights: [0.301 1.982]\n","input: [2] actual output: 7 predicted output: 6.548 updated weights: [0.31  1.987]\n","input: [3] actual output: 9 predicted output: 8.878 updated weights: [0.314 1.988]\n","input: [4] actual output: 11 predicted output: 11.196 updated weights: [0.306 1.986]\n","input: [5] actual output: 13 predicted output: 13.446 updated weights: [0.284 1.982]\n","input: [1] actual output: 5 predicted output: 4.248 updated weights: [0.292 1.99 ]\n","input: [2] actual output: 7 predicted output: 6.554 updated weights: [0.301 1.994]\n","input: [3] actual output: 9 predicted output: 8.879 updated weights: [0.305 1.995]\n","input: [4] actual output: 11 predicted output: 11.195 updated weights: [0.297 1.993]\n","input: [5] actual output: 13 predicted output: 13.443 updated weights: [0.275 1.989]\n","input: [1] actual output: 5 predicted output: 4.253 updated weights: [0.282 1.996]\n","input: [2] actual output: 7 predicted output: 6.552 updated weights: [0.291 2.   ]\n","input: [3] actual output: 9 predicted output: 8.873000000000001 updated weights: [0.295 2.001]\n","input: [4] actual output: 11 predicted output: 11.184999999999999 updated weights: [0.288 1.999]\n","input: [5] actual output: 13 predicted output: 13.434000000000001 updated weights: [0.266 1.995]\n","input: [1] actual output: 5 predicted output: 4.256 updated weights: [0.273 2.002]\n","input: [2] actual output: 7 predicted output: 6.552 updated weights: [0.282 2.006]\n","input: [3] actual output: 9 predicted output: 8.87 updated weights: [0.286 2.007]\n","input: [4] actual output: 11 predicted output: 11.179 updated weights: [0.279 2.005]\n","input: [5] actual output: 13 predicted output: 13.424999999999997 updated weights: [0.258 2.001]\n","input: [1] actual output: 5 predicted output: 4.26 updated weights: [0.265 2.008]\n","input: [2] actual output: 7 predicted output: 6.554 updated weights: [0.274 2.012]\n","input: [3] actual output: 9 predicted output: 8.87 updated weights: [0.278 2.013]\n","input: [4] actual output: 11 predicted output: 11.177 updated weights: [0.271 2.011]\n","input: [5] actual output: 13 predicted output: 13.421 updated weights: [0.25  2.007]\n","input: [1] actual output: 5 predicted output: 4.264 updated weights: [0.257 2.014]\n","input: [2] actual output: 7 predicted output: 6.555999999999999 updated weights: [0.266 2.018]\n","input: [3] actual output: 9 predicted output: 8.87 updated weights: [0.27  2.019]\n","input: [4] actual output: 11 predicted output: 11.175 updated weights: [0.263 2.017]\n","input: [5] actual output: 13 predicted output: 13.416999999999998 updated weights: [0.242 2.013]\n","input: [1] actual output: 5 predicted output: 4.268 updated weights: [0.249 2.02 ]\n","input: [2] actual output: 7 predicted output: 6.558 updated weights: [0.258 2.024]\n","input: [3] actual output: 9 predicted output: 8.870000000000001 updated weights: [0.262 2.025]\n","input: [4] actual output: 11 predicted output: 11.173 updated weights: [0.255 2.023]\n","input: [5] actual output: 13 predicted output: 13.413 updated weights: [0.234 2.019]\n","input: [1] actual output: 5 predicted output: 4.272 updated weights: [0.241 2.026]\n","input: [2] actual output: 7 predicted output: 6.56 updated weights: [0.25 2.03]\n","input: [3] actual output: 9 predicted output: 8.87 updated weights: [0.254 2.031]\n","input: [4] actual output: 11 predicted output: 11.171000000000001 updated weights: [0.247 2.029]\n","input: [5] actual output: 13 predicted output: 13.408999999999999 updated weights: [0.227 2.025]\n","input: [1] actual output: 5 predicted output: 4.276999999999999 updated weights: [0.234 2.032]\n","input: [2] actual output: 7 predicted output: 6.564 updated weights: [0.243 2.036]\n","input: [3] actual output: 9 predicted output: 8.873000000000001 updated weights: [0.247 2.037]\n","input: [4] actual output: 11 predicted output: 11.172999999999998 updated weights: [0.24  2.035]\n","input: [5] actual output: 13 predicted output: 13.41 updated weights: [0.219 2.031]\n","input: [1] actual output: 5 predicted output: 4.281000000000001 updated weights: [0.226 2.038]\n","input: [2] actual output: 7 predicted output: 6.565999999999999 updated weights: [0.235 2.042]\n","input: [3] actual output: 9 predicted output: 8.873 updated weights: [0.239 2.043]\n","input: [4] actual output: 11 predicted output: 11.171 updated weights: [0.232 2.041]\n","input: [5] actual output: 13 predicted output: 13.406 updated weights: [0.212 2.037]\n","input: [1] actual output: 5 predicted output: 4.286 updated weights: [0.219 2.044]\n","input: [2] actual output: 7 predicted output: 6.57 updated weights: [0.228 2.048]\n","input: [3] actual output: 9 predicted output: 8.876000000000001 updated weights: [0.232 2.049]\n","input: [4] actual output: 11 predicted output: 11.173 updated weights: [0.225 2.047]\n","input: [5] actual output: 13 predicted output: 13.407000000000002 updated weights: [0.205 2.043]\n","input: [1] actual output: 5 predicted output: 4.291 updated weights: [0.212 2.05 ]\n","input: [2] actual output: 7 predicted output: 6.574 updated weights: [0.221 2.054]\n","input: [3] actual output: 9 predicted output: 8.879 updated weights: [0.225 2.055]\n","input: [4] actual output: 11 predicted output: 11.175 updated weights: [0.218 2.053]\n","input: [5] actual output: 13 predicted output: 13.408000000000001 updated weights: [0.198 2.049]\n","input: [1] actual output: 5 predicted output: 4.295999999999999 updated weights: [0.205 2.056]\n","input: [2] actual output: 7 predicted output: 6.578 updated weights: [0.213 2.06 ]\n","input: [3] actual output: 9 predicted output: 8.879 updated weights: [0.217 2.061]\n","input: [4] actual output: 11 predicted output: 11.173 updated weights: [0.21  2.059]\n","input: [5] actual output: 13 predicted output: 13.404000000000003 updated weights: [0.19  2.055]\n","input: [1] actual output: 5 predicted output: 4.300000000000001 updated weights: [0.197 2.062]\n","input: [2] actual output: 7 predicted output: 6.58 updated weights: [0.205 2.066]\n","input: [3] actual output: 9 predicted output: 8.879 updated weights: [0.209 2.067]\n","input: [4] actual output: 11 predicted output: 11.171000000000001 updated weights: [0.202 2.065]\n","input: [5] actual output: 13 predicted output: 13.399999999999999 updated weights: [0.182 2.061]\n","input: [1] actual output: 5 predicted output: 4.304 updated weights: [0.189 2.068]\n","input: [2] actual output: 7 predicted output: 6.582000000000001 updated weights: [0.197 2.072]\n","input: [3] actual output: 9 predicted output: 8.879000000000001 updated weights: [0.201 2.073]\n","input: [4] actual output: 11 predicted output: 11.169 updated weights: [0.194 2.071]\n","input: [5] actual output: 13 predicted output: 13.396 updated weights: [0.174 2.067]\n","input: [1] actual output: 5 predicted output: 4.308 updated weights: [0.181 2.074]\n","input: [2] actual output: 7 predicted output: 6.584 updated weights: [0.189 2.078]\n","input: [3] actual output: 9 predicted output: 8.879 updated weights: [0.193 2.079]\n","input: [4] actual output: 11 predicted output: 11.167000000000002 updated weights: [0.186 2.077]\n","input: [5] actual output: 13 predicted output: 13.392 updated weights: [0.166 2.073]\n","input: [1] actual output: 5 predicted output: 4.311999999999999 updated weights: [0.173 2.08 ]\n","input: [2] actual output: 7 predicted output: 6.586 updated weights: [0.181 2.084]\n","input: [3] actual output: 9 predicted output: 8.879000000000001 updated weights: [0.185 2.085]\n","input: [4] actual output: 11 predicted output: 11.165 updated weights: [0.178 2.083]\n","input: [5] actual output: 13 predicted output: 13.388000000000002 updated weights: [0.159 2.079]\n","input: [1] actual output: 5 predicted output: 4.317 updated weights: [0.166 2.086]\n","input: [2] actual output: 7 predicted output: 6.59 updated weights: [0.174 2.09 ]\n","input: [3] actual output: 9 predicted output: 8.882 updated weights: [0.178 2.091]\n","input: [4] actual output: 11 predicted output: 11.167000000000002 updated weights: [0.171 2.089]\n","input: [5] actual output: 13 predicted output: 13.389000000000001 updated weights: [0.152 2.085]\n","input: [1] actual output: 5 predicted output: 4.322 updated weights: [0.159 2.092]\n","input: [2] actual output: 7 predicted output: 6.593999999999999 updated weights: [0.167 2.096]\n","input: [3] actual output: 9 predicted output: 8.885000000000002 updated weights: [0.17  2.097]\n","input: [4] actual output: 11 predicted output: 11.165 updated weights: [0.163 2.095]\n","input: [5] actual output: 13 predicted output: 13.385000000000002 updated weights: [0.144 2.091]\n","input: [1] actual output: 5 predicted output: 4.3260000000000005 updated weights: [0.151 2.098]\n","input: [2] actual output: 7 predicted output: 6.595999999999999 updated weights: [0.159 2.102]\n","input: [3] actual output: 9 predicted output: 8.885 updated weights: [0.162 2.103]\n","input: [4] actual output: 11 predicted output: 11.163 updated weights: [0.155 2.101]\n","input: [5] actual output: 13 predicted output: 13.381 updated weights: [0.136 2.097]\n","input: [1] actual output: 5 predicted output: 4.33 updated weights: [0.143 2.104]\n","input: [2] actual output: 7 predicted output: 6.598 updated weights: [0.151 2.108]\n","input: [3] actual output: 9 predicted output: 8.885 updated weights: [0.154 2.109]\n","input: [4] actual output: 11 predicted output: 11.161 updated weights: [0.148 2.107]\n","input: [5] actual output: 13 predicted output: 13.382000000000001 updated weights: [0.129 2.103]\n","input: [1] actual output: 5 predicted output: 4.335000000000001 updated weights: [0.136 2.11 ]\n","input: [2] actual output: 7 predicted output: 6.602 updated weights: [0.144 2.114]\n","input: [3] actual output: 9 predicted output: 8.887999999999998 updated weights: [0.147 2.115]\n","input: [4] actual output: 11 predicted output: 11.163 updated weights: [0.14  2.113]\n","input: [5] actual output: 13 predicted output: 13.377999999999998 updated weights: [0.121 2.109]\n","input: [1] actual output: 5 predicted output: 4.339 updated weights: [0.128 2.116]\n","input: [2] actual output: 7 predicted output: 6.604000000000001 updated weights: [0.136 2.12 ]\n","input: [3] actual output: 9 predicted output: 8.888000000000002 updated weights: [0.139 2.121]\n","input: [4] actual output: 11 predicted output: 11.161 updated weights: [0.133 2.119]\n","input: [5] actual output: 13 predicted output: 13.379000000000001 updated weights: [0.114 2.115]\n","input: [1] actual output: 5 predicted output: 4.344 updated weights: [0.121 2.122]\n","input: [2] actual output: 7 predicted output: 6.608 updated weights: [0.129 2.126]\n","input: [3] actual output: 9 predicted output: 8.891 updated weights: [0.132 2.127]\n","input: [4] actual output: 11 predicted output: 11.163 updated weights: [0.125 2.125]\n","input: [5] actual output: 13 predicted output: 13.375 updated weights: [0.106 2.121]\n","input: [1] actual output: 5 predicted output: 4.348 updated weights: [0.113 2.128]\n","input: [2] actual output: 7 predicted output: 6.61 updated weights: [0.121 2.132]\n","input: [3] actual output: 9 predicted output: 8.891 updated weights: [0.124 2.133]\n","input: [4] actual output: 11 predicted output: 11.161000000000001 updated weights: [0.118 2.131]\n","input: [5] actual output: 13 predicted output: 13.376 updated weights: [0.099 2.127]\n","input: [1] actual output: 5 predicted output: 4.353 updated weights: [0.105 2.133]\n","input: [2] actual output: 7 predicted output: 6.609 updated weights: [0.113 2.137]\n","input: [3] actual output: 9 predicted output: 8.887 updated weights: [0.116 2.138]\n","input: [4] actual output: 11 predicted output: 11.154 updated weights: [0.11  2.136]\n","input: [5] actual output: 13 predicted output: 13.366 updated weights: [0.092 2.132]\n","input: [1] actual output: 5 predicted output: 4.356 updated weights: [0.098 2.138]\n","input: [2] actual output: 7 predicted output: 6.609999999999999 updated weights: [0.106 2.142]\n","input: [3] actual output: 9 predicted output: 8.886 updated weights: [0.109 2.143]\n","input: [4] actual output: 11 predicted output: 11.151 updated weights: [0.103 2.141]\n","input: [5] actual output: 13 predicted output: 13.361 updated weights: [0.085 2.137]\n","input: [1] actual output: 5 predicted output: 4.359 updated weights: [0.091 2.143]\n","input: [2] actual output: 7 predicted output: 6.611 updated weights: [0.099 2.147]\n","input: [3] actual output: 9 predicted output: 8.884999999999998 updated weights: [0.102 2.148]\n","input: [4] actual output: 11 predicted output: 11.148 updated weights: [0.096 2.147]\n","input: [5] actual output: 13 predicted output: 13.362 updated weights: [0.078 2.143]\n","input: [1] actual output: 5 predicted output: 4.363999999999999 updated weights: [0.084 2.149]\n","input: [2] actual output: 7 predicted output: 6.615 updated weights: [0.092 2.153]\n","input: [3] actual output: 9 predicted output: 8.888 updated weights: [0.095 2.154]\n","input: [4] actual output: 11 predicted output: 11.15 updated weights: [0.089 2.152]\n","input: [5] actual output: 13 predicted output: 13.357000000000003 updated weights: [0.071 2.148]\n","input: [1] actual output: 5 predicted output: 4.367000000000001 updated weights: [0.077 2.154]\n","input: [2] actual output: 7 predicted output: 6.616 updated weights: [0.085 2.158]\n","input: [3] actual output: 9 predicted output: 8.887 updated weights: [0.088 2.159]\n","input: [4] actual output: 11 predicted output: 11.146999999999998 updated weights: [0.082 2.158]\n","input: [5] actual output: 13 predicted output: 13.357999999999999 updated weights: [0.064 2.154]\n","input: [1] actual output: 5 predicted output: 4.372 updated weights: [0.07 2.16]\n","input: [2] actual output: 7 predicted output: 6.62 updated weights: [0.078 2.164]\n","input: [3] actual output: 9 predicted output: 8.89 updated weights: [0.081 2.165]\n","input: [4] actual output: 11 predicted output: 11.149000000000001 updated weights: [0.075 2.164]\n","input: [5] actual output: 13 predicted output: 13.359 updated weights: [0.057 2.16 ]\n","input: [1] actual output: 5 predicted output: 4.377000000000001 updated weights: [0.063 2.166]\n","input: [2] actual output: 7 predicted output: 6.6240000000000006 updated weights: [0.071 2.17 ]\n","input: [3] actual output: 9 predicted output: 8.893 updated weights: [0.074 2.171]\n","input: [4] actual output: 11 predicted output: 11.150999999999998 updated weights: [0.068 2.169]\n","input: [5] actual output: 13 predicted output: 13.354000000000001 updated weights: [0.05  2.165]\n","input: [1] actual output: 5 predicted output: 4.38 updated weights: [0.056 2.171]\n","input: [2] actual output: 7 predicted output: 6.625 updated weights: [0.064 2.175]\n","input: [3] actual output: 9 predicted output: 8.892 updated weights: [0.067 2.176]\n","input: [4] actual output: 11 predicted output: 11.148000000000001 updated weights: [0.061 2.175]\n","input: [5] actual output: 13 predicted output: 13.355 updated weights: [0.043 2.171]\n","input: [1] actual output: 5 predicted output: 4.385 updated weights: [0.049 2.177]\n","input: [2] actual output: 7 predicted output: 6.629 updated weights: [0.056 2.181]\n","input: [3] actual output: 9 predicted output: 8.892 updated weights: [0.059 2.182]\n","input: [4] actual output: 11 predicted output: 11.146 updated weights: [0.053 2.181]\n","input: [5] actual output: 13 predicted output: 13.351000000000003 updated weights: [0.035 2.177]\n","input: [1] actual output: 5 predicted output: 4.389 updated weights: [0.041 2.183]\n","input: [2] actual output: 7 predicted output: 6.630999999999999 updated weights: [0.048 2.187]\n","input: [3] actual output: 9 predicted output: 8.892 updated weights: [0.051 2.188]\n","input: [4] actual output: 11 predicted output: 11.144000000000002 updated weights: [0.045 2.187]\n","input: [5] actual output: 13 predicted output: 13.346999999999998 updated weights: [0.028 2.184]\n","input: [1] actual output: 5 predicted output: 4.396000000000001 updated weights: [0.034 2.19 ]\n","input: [2] actual output: 7 predicted output: 6.638 updated weights: [0.041 2.194]\n","input: [3] actual output: 9 predicted output: 8.899000000000001 updated weights: [0.044 2.195]\n","input: [4] actual output: 11 predicted output: 11.151 updated weights: [0.038 2.193]\n","input: [5] actual output: 13 predicted output: 13.347999999999999 updated weights: [0.021 2.19 ]\n","input: [1] actual output: 5 predicted output: 4.401 updated weights: [0.027 2.196]\n","input: [2] actual output: 7 predicted output: 6.642000000000001 updated weights: [0.034 2.2  ]\n","input: [3] actual output: 9 predicted output: 8.902000000000001 updated weights: [0.037 2.201]\n","input: [4] actual output: 11 predicted output: 11.153 updated weights: [0.031 2.199]\n","input: [5] actual output: 13 predicted output: 13.348999999999998 updated weights: [0.014 2.196]\n","input: [1] actual output: 5 predicted output: 4.406000000000001 updated weights: [0.02  2.202]\n","input: [2] actual output: 7 predicted output: 6.646 updated weights: [0.027 2.206]\n","input: [3] actual output: 9 predicted output: 8.905000000000001 updated weights: [0.03  2.207]\n","input: [4] actual output: 11 predicted output: 11.154999999999998 updated weights: [0.024 2.205]\n","input: [5] actual output: 13 predicted output: 13.35 updated weights: [0.007 2.202]\n","input: [1] actual output: 5 predicted output: 4.411 updated weights: [0.013 2.208]\n","input: [2] actual output: 7 predicted output: 6.65 updated weights: [0.02  2.212]\n","input: [3] actual output: 9 predicted output: 8.908000000000001 updated weights: [0.023 2.213]\n","input: [4] actual output: 11 predicted output: 11.157 updated weights: [0.017 2.211]\n","input: [5] actual output: 13 predicted output: 13.351 updated weights: [-1.000e-03  2.207e+00]\n","input: [1] actual output: 5 predicted output: 4.413 updated weights: [0.005 2.213]\n","input: [2] actual output: 7 predicted output: 6.649 updated weights: [0.012 2.217]\n","input: [3] actual output: 9 predicted output: 8.904 updated weights: [0.015 2.218]\n","input: [4] actual output: 11 predicted output: 11.15 updated weights: [0.009 2.216]\n","input: [5] actual output: 13 predicted output: 13.341000000000001 updated weights: [-0.008  2.213]\n","input: [1] actual output: 5 predicted output: 4.418 updated weights: [-2.000e-03  2.219e+00]\n","input: [2] actual output: 7 predicted output: 6.6530000000000005 updated weights: [0.005 2.222]\n","input: [3] actual output: 9 predicted output: 8.903 updated weights: [0.008 2.223]\n","input: [4] actual output: 11 predicted output: 11.146999999999998 updated weights: [2.000e-03 2.222e+00]\n","input: [5] actual output: 13 predicted output: 13.341999999999999 updated weights: [-0.015  2.219]\n","input: [1] actual output: 5 predicted output: 4.423 updated weights: [-0.009  2.225]\n","input: [2] actual output: 7 predicted output: 6.657 updated weights: [-2.000e-03  2.228e+00]\n","input: [3] actual output: 9 predicted output: 8.906 updated weights: [1.000e-03 2.229e+00]\n","input: [4] actual output: 11 predicted output: 11.149000000000001 updated weights: [-0.005  2.228]\n","input: [5] actual output: 13 predicted output: 13.343 updated weights: [-0.022  2.225]\n","input: [1] actual output: 5 predicted output: 4.428000000000001 updated weights: [-0.016  2.231]\n","input: [2] actual output: 7 predicted output: 6.661 updated weights: [-0.009  2.234]\n","input: [3] actual output: 9 predicted output: 8.908999999999999 updated weights: [-0.006  2.235]\n","input: [4] actual output: 11 predicted output: 11.151 updated weights: [-0.012  2.233]\n","input: [5] actual output: 13 predicted output: 13.338000000000001 updated weights: [-0.029  2.23 ]\n","input: [1] actual output: 5 predicted output: 4.431 updated weights: [-0.023  2.236]\n","input: [2] actual output: 7 predicted output: 6.662000000000001 updated weights: [-0.016  2.239]\n","input: [3] actual output: 9 predicted output: 8.908 updated weights: [-0.013  2.24 ]\n","input: [4] actual output: 11 predicted output: 11.148000000000001 updated weights: [-0.019  2.239]\n","input: [5] actual output: 13 predicted output: 13.338999999999999 updated weights: [-0.036  2.236]\n","input: [1] actual output: 5 predicted output: 4.436 updated weights: [-0.03   2.242]\n","input: [2] actual output: 7 predicted output: 6.666 updated weights: [-0.023  2.245]\n","input: [3] actual output: 9 predicted output: 8.911000000000001 updated weights: [-0.02   2.246]\n","input: [4] actual output: 11 predicted output: 11.15 updated weights: [-0.026  2.244]\n","input: [5] actual output: 13 predicted output: 13.334 updated weights: [-0.043  2.241]\n","input: [1] actual output: 5 predicted output: 4.439 updated weights: [-0.037  2.247]\n","input: [2] actual output: 7 predicted output: 6.667 updated weights: [-0.03  2.25]\n","input: [3] actual output: 9 predicted output: 8.91 updated weights: [-0.027  2.251]\n","input: [4] actual output: 11 predicted output: 11.146999999999998 updated weights: [-0.033  2.25 ]\n","input: [5] actual output: 13 predicted output: 13.335 updated weights: [-0.05   2.247]\n","input: [1] actual output: 5 predicted output: 4.444 updated weights: [-0.044  2.253]\n","input: [2] actual output: 7 predicted output: 6.671 updated weights: [-0.037  2.256]\n","input: [3] actual output: 9 predicted output: 8.912999999999998 updated weights: [-0.034  2.257]\n","input: [4] actual output: 11 predicted output: 11.149000000000001 updated weights: [-0.04   2.256]\n","input: [5] actual output: 13 predicted output: 13.336 updated weights: [-0.057  2.253]\n","input: [1] actual output: 5 predicted output: 4.449 updated weights: [-0.051  2.259]\n","input: [2] actual output: 7 predicted output: 6.674999999999999 updated weights: [-0.044  2.262]\n","input: [3] actual output: 9 predicted output: 8.916 updated weights: [-0.041  2.263]\n","input: [4] actual output: 11 predicted output: 11.151 updated weights: [-0.047  2.261]\n","input: [5] actual output: 13 predicted output: 13.331 updated weights: [-0.064  2.258]\n","input: [1] actual output: 5 predicted output: 4.452 updated weights: [-0.059  2.263]\n","input: [2] actual output: 7 predicted output: 6.670999999999999 updated weights: [-0.052  2.266]\n","input: [3] actual output: 9 predicted output: 8.908000000000001 updated weights: [-0.049  2.267]\n","input: [4] actual output: 11 predicted output: 11.139 updated weights: [-0.055  2.266]\n","input: [5] actual output: 13 predicted output: 13.321 updated weights: [-0.071  2.263]\n","input: [1] actual output: 5 predicted output: 4.455 updated weights: [-0.066  2.268]\n","input: [2] actual output: 7 predicted output: 6.672 updated weights: [-0.059  2.271]\n","input: [3] actual output: 9 predicted output: 8.907 updated weights: [-0.056  2.272]\n","input: [4] actual output: 11 predicted output: 11.136 updated weights: [-0.061  2.271]\n","input: [5] actual output: 13 predicted output: 13.321000000000002 updated weights: [-0.077  2.268]\n","input: [1] actual output: 5 predicted output: 4.459 updated weights: [-0.072  2.273]\n","input: [2] actual output: 7 predicted output: 6.675000000000001 updated weights: [-0.066  2.276]\n","input: [3] actual output: 9 predicted output: 8.905999999999999 updated weights: [-0.063  2.277]\n","input: [4] actual output: 11 predicted output: 11.133 updated weights: [-0.068  2.276]\n","input: [5] actual output: 13 predicted output: 13.315999999999999 updated weights: [-0.084  2.273]\n","input: [1] actual output: 5 predicted output: 4.462 updated weights: [-0.079  2.278]\n","input: [2] actual output: 7 predicted output: 6.676 updated weights: [-0.073  2.281]\n","input: [3] actual output: 9 predicted output: 8.905 updated weights: [-0.07   2.282]\n","input: [4] actual output: 11 predicted output: 11.13 updated weights: [-0.075  2.281]\n","input: [5] actual output: 13 predicted output: 13.311000000000002 updated weights: [-0.091  2.278]\n","input: [1] actual output: 5 predicted output: 4.465 updated weights: [-0.086  2.283]\n","input: [2] actual output: 7 predicted output: 6.677 updated weights: [-0.08   2.286]\n","input: [3] actual output: 9 predicted output: 8.904 updated weights: [-0.077  2.287]\n","input: [4] actual output: 11 predicted output: 11.126999999999999 updated weights: [-0.082  2.286]\n","input: [5] actual output: 13 predicted output: 13.306 updated weights: [-0.097  2.283]\n","input: [1] actual output: 5 predicted output: 4.468999999999999 updated weights: [-0.092  2.288]\n","input: [2] actual output: 7 predicted output: 6.68 updated weights: [-0.086  2.291]\n","input: [3] actual output: 9 predicted output: 8.905999999999999 updated weights: [-0.083  2.292]\n","input: [4] actual output: 11 predicted output: 11.127999999999998 updated weights: [-0.088  2.291]\n","input: [5] actual output: 13 predicted output: 13.306000000000001 updated weights: [-0.103  2.288]\n","input: [1] actual output: 5 predicted output: 4.472999999999999 updated weights: [-0.098  2.293]\n","input: [2] actual output: 7 predicted output: 6.683000000000001 updated weights: [-0.092  2.296]\n","input: [3] actual output: 9 predicted output: 8.908 updated weights: [-0.089  2.297]\n","input: [4] actual output: 11 predicted output: 11.129000000000001 updated weights: [-0.094  2.296]\n","input: [5] actual output: 13 predicted output: 13.305999999999997 updated weights: [-0.109  2.293]\n","input: [1] actual output: 5 predicted output: 4.477 updated weights: [-0.104  2.298]\n","input: [2] actual output: 7 predicted output: 6.686 updated weights: [-0.098  2.301]\n","input: [3] actual output: 9 predicted output: 8.91 updated weights: [-0.095  2.302]\n","input: [4] actual output: 11 predicted output: 11.129999999999999 updated weights: [-0.1    2.301]\n","input: [5] actual output: 13 predicted output: 13.306000000000001 updated weights: [-0.115  2.298]\n","input: [1] actual output: 5 predicted output: 4.481 updated weights: [-0.11   2.303]\n","input: [2] actual output: 7 predicted output: 6.689 updated weights: [-0.104  2.306]\n","input: [3] actual output: 9 predicted output: 8.911999999999999 updated weights: [-0.101  2.307]\n","input: [4] actual output: 11 predicted output: 11.131 updated weights: [-0.106  2.306]\n","input: [5] actual output: 13 predicted output: 13.306000000000001 updated weights: [-0.121  2.303]\n","input: [1] actual output: 5 predicted output: 4.484999999999999 updated weights: [-0.116  2.308]\n","input: [2] actual output: 7 predicted output: 6.691999999999999 updated weights: [-0.11   2.311]\n","input: [3] actual output: 9 predicted output: 8.914 updated weights: [-0.107  2.312]\n","input: [4] actual output: 11 predicted output: 11.131999999999998 updated weights: [-0.112  2.311]\n","input: [5] actual output: 13 predicted output: 13.306 updated weights: [-0.127  2.308]\n","input: [1] actual output: 5 predicted output: 4.489 updated weights: [-0.122  2.313]\n","input: [2] actual output: 7 predicted output: 6.695 updated weights: [-0.116  2.316]\n","input: [3] actual output: 9 predicted output: 8.916 updated weights: [-0.113  2.317]\n","input: [4] actual output: 11 predicted output: 11.133000000000001 updated weights: [-0.118  2.316]\n","input: [5] actual output: 13 predicted output: 13.305999999999997 updated weights: [-0.133  2.313]\n","input: [1] actual output: 5 predicted output: 4.493 updated weights: [-0.128  2.318]\n","input: [2] actual output: 7 predicted output: 6.698 updated weights: [-0.122  2.321]\n","input: [3] actual output: 9 predicted output: 8.918000000000001 updated weights: [-0.12   2.322]\n","input: [4] actual output: 11 predicted output: 11.129999999999999 updated weights: [-0.125  2.321]\n","input: [5] actual output: 13 predicted output: 13.301 updated weights: [-0.14   2.318]\n","input: [1] actual output: 5 predicted output: 4.496 updated weights: [-0.135  2.323]\n","input: [2] actual output: 7 predicted output: 6.699 updated weights: [-0.129  2.326]\n","input: [3] actual output: 9 predicted output: 8.917 updated weights: [-0.127  2.327]\n","input: [4] actual output: 11 predicted output: 11.127 updated weights: [-0.132  2.326]\n","input: [5] actual output: 13 predicted output: 13.296000000000001 updated weights: [-0.147  2.323]\n","input: [1] actual output: 5 predicted output: 4.4990000000000006 updated weights: [-0.142  2.328]\n","input: [2] actual output: 7 predicted output: 6.699999999999999 updated weights: [-0.136  2.331]\n","input: [3] actual output: 9 predicted output: 8.916 updated weights: [-0.133  2.332]\n","input: [4] actual output: 11 predicted output: 11.128 updated weights: [-0.138  2.331]\n","input: [5] actual output: 13 predicted output: 13.296 updated weights: [-0.153  2.328]\n","input: [1] actual output: 5 predicted output: 4.503 updated weights: [-0.148  2.333]\n","input: [2] actual output: 7 predicted output: 6.703 updated weights: [-0.142  2.336]\n","input: [3] actual output: 9 predicted output: 8.918 updated weights: [-0.14   2.337]\n","input: [4] actual output: 11 predicted output: 11.125 updated weights: [-0.145  2.336]\n","input: [5] actual output: 13 predicted output: 13.291 updated weights: [-0.16   2.333]\n","input: [1] actual output: 5 predicted output: 4.506 updated weights: [-0.155  2.338]\n","input: [2] actual output: 7 predicted output: 6.704000000000001 updated weights: [-0.149  2.341]\n","input: [3] actual output: 9 predicted output: 8.917000000000002 updated weights: [-0.147  2.342]\n","input: [4] actual output: 11 predicted output: 11.122000000000002 updated weights: [-0.152  2.341]\n","input: [5] actual output: 13 predicted output: 13.286000000000001 updated weights: [-0.166  2.338]\n","input: [1] actual output: 5 predicted output: 4.51 updated weights: [-0.161  2.343]\n","input: [2] actual output: 7 predicted output: 6.707 updated weights: [-0.155  2.346]\n","input: [3] actual output: 9 predicted output: 8.919 updated weights: [-0.153  2.347]\n","input: [4] actual output: 11 predicted output: 11.123 updated weights: [-0.158  2.346]\n","input: [5] actual output: 13 predicted output: 13.286000000000001 updated weights: [-0.172  2.343]\n","input: [1] actual output: 5 predicted output: 4.513999999999999 updated weights: [-0.167  2.348]\n","input: [2] actual output: 7 predicted output: 6.71 updated weights: [-0.161  2.351]\n","input: [3] actual output: 9 predicted output: 8.921 updated weights: [-0.159  2.352]\n","input: [4] actual output: 11 predicted output: 11.124 updated weights: [-0.164  2.351]\n","input: [5] actual output: 13 predicted output: 13.285999999999998 updated weights: [-0.178  2.348]\n","input: [1] actual output: 5 predicted output: 4.518 updated weights: [-0.173  2.353]\n","input: [2] actual output: 7 predicted output: 6.713000000000001 updated weights: [-0.167  2.356]\n","input: [3] actual output: 9 predicted output: 8.922999999999998 updated weights: [-0.165  2.357]\n","input: [4] actual output: 11 predicted output: 11.125 updated weights: [-0.17   2.356]\n","input: [5] actual output: 13 predicted output: 13.286 updated weights: [-0.184  2.353]\n","input: [1] actual output: 5 predicted output: 4.522 updated weights: [-0.179  2.358]\n","input: [2] actual output: 7 predicted output: 6.716000000000001 updated weights: [-0.173  2.361]\n","input: [3] actual output: 9 predicted output: 8.925 updated weights: [-0.171  2.362]\n","input: [4] actual output: 11 predicted output: 11.126000000000001 updated weights: [-0.176  2.361]\n","input: [5] actual output: 13 predicted output: 13.286000000000001 updated weights: [-0.19   2.358]\n","input: [1] actual output: 5 predicted output: 4.526 updated weights: [-0.185  2.363]\n","input: [2] actual output: 7 predicted output: 6.718999999999999 updated weights: [-0.179  2.366]\n","input: [3] actual output: 9 predicted output: 8.927000000000001 updated weights: [-0.177  2.367]\n","input: [4] actual output: 11 predicted output: 11.126999999999999 updated weights: [-0.182  2.366]\n","input: [5] actual output: 13 predicted output: 13.286 updated weights: [-0.196  2.363]\n","input: [1] actual output: 5 predicted output: 4.529999999999999 updated weights: [-0.191  2.368]\n","input: [2] actual output: 7 predicted output: 6.7219999999999995 updated weights: [-0.185  2.371]\n","input: [3] actual output: 9 predicted output: 8.929 updated weights: [-0.183  2.372]\n","input: [4] actual output: 11 predicted output: 11.128 updated weights: [-0.188  2.371]\n","input: [5] actual output: 13 predicted output: 13.286000000000001 updated weights: [-0.202  2.368]\n","input: [1] actual output: 5 predicted output: 4.534 updated weights: [-0.197  2.373]\n","input: [2] actual output: 7 predicted output: 6.7250000000000005 updated weights: [-0.192  2.376]\n","input: [3] actual output: 9 predicted output: 8.927999999999999 updated weights: [-0.19   2.377]\n","input: [4] actual output: 11 predicted output: 11.125 updated weights: [-0.195  2.376]\n","input: [5] actual output: 13 predicted output: 13.280999999999999 updated weights: [-0.209  2.373]\n","input: [1] actual output: 5 predicted output: 4.537000000000001 updated weights: [-0.204  2.378]\n","input: [2] actual output: 7 predicted output: 6.726 updated weights: [-0.199  2.381]\n","input: [3] actual output: 9 predicted output: 8.927 updated weights: [-0.197  2.382]\n","input: [4] actual output: 11 predicted output: 11.122 updated weights: [-0.202  2.381]\n","input: [5] actual output: 13 predicted output: 13.276 updated weights: [-0.216  2.378]\n","input: [1] actual output: 5 predicted output: 4.54 updated weights: [-0.211  2.383]\n","input: [2] actual output: 7 predicted output: 6.727 updated weights: [-0.206  2.386]\n","input: [3] actual output: 9 predicted output: 8.926 updated weights: [-0.204  2.387]\n","input: [4] actual output: 11 predicted output: 11.119 updated weights: [-0.209  2.386]\n","input: [5] actual output: 13 predicted output: 13.271 updated weights: [-0.223  2.383]\n","input: [1] actual output: 5 predicted output: 4.543 updated weights: [-0.218  2.388]\n","input: [2] actual output: 7 predicted output: 6.728 updated weights: [-0.213  2.391]\n","input: [3] actual output: 9 predicted output: 8.925 updated weights: [-0.211  2.392]\n","input: [4] actual output: 11 predicted output: 11.116 updated weights: [-0.216  2.391]\n","input: [5] actual output: 13 predicted output: 13.266 updated weights: [-0.229  2.388]\n","input: [1] actual output: 5 predicted output: 4.547 updated weights: [-0.224  2.393]\n","input: [2] actual output: 7 predicted output: 6.730999999999999 updated weights: [-0.219  2.396]\n","input: [3] actual output: 9 predicted output: 8.927 updated weights: [-0.217  2.397]\n","input: [4] actual output: 11 predicted output: 11.116999999999999 updated weights: [-0.222  2.396]\n","input: [5] actual output: 13 predicted output: 13.266000000000002 updated weights: [-0.235  2.393]\n","input: [1] actual output: 5 predicted output: 4.551 updated weights: [-0.231  2.397]\n","input: [2] actual output: 7 predicted output: 6.728999999999999 updated weights: [-0.226  2.4  ]\n","input: [3] actual output: 9 predicted output: 8.921999999999999 updated weights: [-0.224  2.401]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.228  2.4  ]\n","input: [5] actual output: 13 predicted output: 13.26 updated weights: [-0.241  2.397]\n","input: [1] actual output: 5 predicted output: 4.552999999999999 updated weights: [-0.237  2.401]\n","input: [2] actual output: 7 predicted output: 6.728999999999999 updated weights: [-0.232  2.404]\n","input: [3] actual output: 9 predicted output: 8.92 updated weights: [-0.23   2.405]\n","input: [4] actual output: 11 predicted output: 11.104999999999999 updated weights: [-0.234  2.404]\n","input: [5] actual output: 13 predicted output: 13.254 updated weights: [-0.247  2.401]\n","input: [1] actual output: 5 predicted output: 4.555 updated weights: [-0.243  2.405]\n","input: [2] actual output: 7 predicted output: 6.728999999999999 updated weights: [-0.238  2.408]\n","input: [3] actual output: 9 predicted output: 8.918 updated weights: [-0.236  2.409]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.24   2.408]\n","input: [5] actual output: 13 predicted output: 13.248 updated weights: [-0.252  2.406]\n","input: [1] actual output: 5 predicted output: 4.5600000000000005 updated weights: [-0.248  2.41 ]\n","input: [2] actual output: 7 predicted output: 6.734 updated weights: [-0.243  2.413]\n","input: [3] actual output: 9 predicted output: 8.922999999999998 updated weights: [-0.241  2.414]\n","input: [4] actual output: 11 predicted output: 11.106 updated weights: [-0.245  2.413]\n","input: [5] actual output: 13 predicted output: 13.253 updated weights: [-0.258  2.41 ]\n","input: [1] actual output: 5 predicted output: 4.562 updated weights: [-0.254  2.414]\n","input: [2] actual output: 7 predicted output: 6.734 updated weights: [-0.249  2.417]\n","input: [3] actual output: 9 predicted output: 8.921 updated weights: [-0.247  2.418]\n","input: [4] actual output: 11 predicted output: 11.102 updated weights: [-0.251  2.417]\n","input: [5] actual output: 13 predicted output: 13.246999999999998 updated weights: [-0.263  2.415]\n","input: [1] actual output: 5 predicted output: 4.567 updated weights: [-0.259  2.419]\n","input: [2] actual output: 7 predicted output: 6.739000000000001 updated weights: [-0.254  2.422]\n","input: [3] actual output: 9 predicted output: 8.926 updated weights: [-0.252  2.423]\n","input: [4] actual output: 11 predicted output: 11.107000000000001 updated weights: [-0.256  2.422]\n","input: [5] actual output: 13 predicted output: 13.252000000000002 updated weights: [-0.269  2.419]\n","input: [1] actual output: 5 predicted output: 4.569 updated weights: [-0.265  2.423]\n","input: [2] actual output: 7 predicted output: 6.739 updated weights: [-0.26   2.426]\n","input: [3] actual output: 9 predicted output: 8.924 updated weights: [-0.258  2.427]\n","input: [4] actual output: 11 predicted output: 11.103 updated weights: [-0.262  2.426]\n","input: [5] actual output: 13 predicted output: 13.246 updated weights: [-0.274  2.424]\n","input: [1] actual output: 5 predicted output: 4.574 updated weights: [-0.27   2.428]\n","input: [2] actual output: 7 predicted output: 6.744 updated weights: [-0.265  2.431]\n","input: [3] actual output: 9 predicted output: 8.929 updated weights: [-0.263  2.432]\n","input: [4] actual output: 11 predicted output: 11.108 updated weights: [-0.267  2.431]\n","input: [5] actual output: 13 predicted output: 13.251000000000001 updated weights: [-0.28   2.428]\n","input: [1] actual output: 5 predicted output: 4.576 updated weights: [-0.276  2.432]\n","input: [2] actual output: 7 predicted output: 6.744 updated weights: [-0.271  2.435]\n","input: [3] actual output: 9 predicted output: 8.927 updated weights: [-0.269  2.436]\n","input: [4] actual output: 11 predicted output: 11.104 updated weights: [-0.273  2.435]\n","input: [5] actual output: 13 predicted output: 13.245000000000001 updated weights: [-0.285  2.433]\n","input: [1] actual output: 5 predicted output: 4.5809999999999995 updated weights: [-0.281  2.437]\n","input: [2] actual output: 7 predicted output: 6.748999999999999 updated weights: [-0.276  2.44 ]\n","input: [3] actual output: 9 predicted output: 8.932 updated weights: [-0.274  2.441]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.278  2.44 ]\n","input: [5] actual output: 13 predicted output: 13.249999999999998 updated weights: [-0.29   2.438]\n","input: [1] actual output: 5 predicted output: 4.586 updated weights: [-0.286  2.442]\n","input: [2] actual output: 7 predicted output: 6.7540000000000004 updated weights: [-0.281  2.444]\n","input: [3] actual output: 9 predicted output: 8.933 updated weights: [-0.279  2.445]\n","input: [4] actual output: 11 predicted output: 11.109 updated weights: [-0.283  2.444]\n","input: [5] actual output: 13 predicted output: 13.248999999999999 updated weights: [-0.295  2.442]\n","input: [1] actual output: 5 predicted output: 4.589 updated weights: [-0.291  2.446]\n","input: [2] actual output: 7 predicted output: 6.756 updated weights: [-0.286  2.448]\n","input: [3] actual output: 9 predicted output: 8.934 updated weights: [-0.284  2.449]\n","input: [4] actual output: 11 predicted output: 11.109 updated weights: [-0.288  2.448]\n","input: [5] actual output: 13 predicted output: 13.248000000000001 updated weights: [-0.3    2.446]\n","input: [1] actual output: 5 predicted output: 4.5920000000000005 updated weights: [-0.296  2.45 ]\n","input: [2] actual output: 7 predicted output: 6.758000000000001 updated weights: [-0.291  2.452]\n","input: [3] actual output: 9 predicted output: 8.934999999999999 updated weights: [-0.289  2.453]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.293  2.452]\n","input: [5] actual output: 13 predicted output: 13.247 updated weights: [-0.305  2.45 ]\n","input: [1] actual output: 5 predicted output: 4.595000000000001 updated weights: [-0.301  2.454]\n","input: [2] actual output: 7 predicted output: 6.76 updated weights: [-0.296  2.456]\n","input: [3] actual output: 9 predicted output: 8.936 updated weights: [-0.294  2.457]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.298  2.456]\n","input: [5] actual output: 13 predicted output: 13.245999999999999 updated weights: [-0.31   2.454]\n","input: [1] actual output: 5 predicted output: 4.598000000000001 updated weights: [-0.306  2.458]\n","input: [2] actual output: 7 predicted output: 6.7620000000000005 updated weights: [-0.301  2.46 ]\n","input: [3] actual output: 9 predicted output: 8.937000000000001 updated weights: [-0.299  2.461]\n","input: [4] actual output: 11 predicted output: 11.109 updated weights: [-0.303  2.46 ]\n","input: [5] actual output: 13 predicted output: 13.245000000000001 updated weights: [-0.315  2.458]\n","input: [1] actual output: 5 predicted output: 4.601000000000001 updated weights: [-0.311  2.462]\n","input: [2] actual output: 7 predicted output: 6.764000000000001 updated weights: [-0.306  2.464]\n","input: [3] actual output: 9 predicted output: 8.937999999999999 updated weights: [-0.304  2.465]\n","input: [4] actual output: 11 predicted output: 11.109 updated weights: [-0.308  2.464]\n","input: [5] actual output: 13 predicted output: 13.244000000000002 updated weights: [-0.32   2.462]\n","input: [1] actual output: 5 predicted output: 4.604000000000001 updated weights: [-0.316  2.466]\n","input: [2] actual output: 7 predicted output: 6.766000000000001 updated weights: [-0.311  2.468]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.309  2.469]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.313  2.468]\n","input: [5] actual output: 13 predicted output: 13.243 updated weights: [-0.325  2.466]\n","input: [1] actual output: 5 predicted output: 4.607 updated weights: [-0.321  2.47 ]\n","input: [2] actual output: 7 predicted output: 6.768000000000001 updated weights: [-0.316  2.472]\n","input: [3] actual output: 9 predicted output: 8.94 updated weights: [-0.314  2.473]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.318  2.472]\n","input: [5] actual output: 13 predicted output: 13.241999999999999 updated weights: [-0.33  2.47]\n","input: [1] actual output: 5 predicted output: 4.61 updated weights: [-0.326  2.474]\n","input: [2] actual output: 7 predicted output: 6.7700000000000005 updated weights: [-0.321  2.476]\n","input: [3] actual output: 9 predicted output: 8.940999999999999 updated weights: [-0.319  2.477]\n","input: [4] actual output: 11 predicted output: 11.109 updated weights: [-0.323  2.476]\n","input: [5] actual output: 13 predicted output: 13.241 updated weights: [-0.335  2.474]\n","input: [1] actual output: 5 predicted output: 4.613 updated weights: [-0.331  2.478]\n","input: [2] actual output: 7 predicted output: 6.772 updated weights: [-0.326  2.48 ]\n","input: [3] actual output: 9 predicted output: 8.942 updated weights: [-0.324  2.481]\n","input: [4] actual output: 11 predicted output: 11.109 updated weights: [-0.328  2.48 ]\n","input: [5] actual output: 13 predicted output: 13.24 updated weights: [-0.34   2.478]\n","input: [1] actual output: 5 predicted output: 4.6160000000000005 updated weights: [-0.336  2.482]\n","input: [2] actual output: 7 predicted output: 6.774000000000001 updated weights: [-0.331  2.484]\n","input: [3] actual output: 9 predicted output: 8.943 updated weights: [-0.329  2.485]\n","input: [4] actual output: 11 predicted output: 11.108999999999998 updated weights: [-0.333  2.484]\n","input: [5] actual output: 13 predicted output: 13.238999999999999 updated weights: [-0.345  2.482]\n","input: [1] actual output: 5 predicted output: 4.619000000000001 updated weights: [-0.341  2.486]\n","input: [2] actual output: 7 predicted output: 6.776 updated weights: [-0.337  2.488]\n","input: [3] actual output: 9 predicted output: 8.941 updated weights: [-0.335  2.489]\n","input: [4] actual output: 11 predicted output: 11.105 updated weights: [-0.339  2.488]\n","input: [5] actual output: 13 predicted output: 13.232999999999999 updated weights: [-0.351  2.486]\n","input: [1] actual output: 5 predicted output: 4.621 updated weights: [-0.347  2.49 ]\n","input: [2] actual output: 7 predicted output: 6.776000000000001 updated weights: [-0.343  2.492]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.341  2.493]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.345  2.492]\n","input: [5] actual output: 13 predicted output: 13.227 updated weights: [-0.356  2.49 ]\n","input: [1] actual output: 5 predicted output: 4.6240000000000006 updated weights: [-0.352  2.494]\n","input: [2] actual output: 7 predicted output: 6.7780000000000005 updated weights: [-0.348  2.496]\n","input: [3] actual output: 9 predicted output: 8.94 updated weights: [-0.346  2.497]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.35   2.496]\n","input: [5] actual output: 13 predicted output: 13.226 updated weights: [-0.361  2.494]\n","input: [1] actual output: 5 predicted output: 4.627000000000001 updated weights: [-0.357  2.498]\n","input: [2] actual output: 7 predicted output: 6.78 updated weights: [-0.353  2.5  ]\n","input: [3] actual output: 9 predicted output: 8.940999999999999 updated weights: [-0.351  2.501]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.355  2.5  ]\n","input: [5] actual output: 13 predicted output: 13.225 updated weights: [-0.366  2.498]\n","input: [1] actual output: 5 predicted output: 4.630000000000001 updated weights: [-0.362  2.502]\n","input: [2] actual output: 7 predicted output: 6.781999999999999 updated weights: [-0.358  2.504]\n","input: [3] actual output: 9 predicted output: 8.942 updated weights: [-0.356  2.505]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.36   2.504]\n","input: [5] actual output: 13 predicted output: 13.223999999999998 updated weights: [-0.371  2.502]\n","input: [1] actual output: 5 predicted output: 4.632999999999999 updated weights: [-0.367  2.506]\n","input: [2] actual output: 7 predicted output: 6.783999999999999 updated weights: [-0.363  2.508]\n","input: [3] actual output: 9 predicted output: 8.943000000000001 updated weights: [-0.361  2.509]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.365  2.508]\n","input: [5] actual output: 13 predicted output: 13.222999999999999 updated weights: [-0.376  2.506]\n","input: [1] actual output: 5 predicted output: 4.635999999999999 updated weights: [-0.372  2.51 ]\n","input: [2] actual output: 7 predicted output: 6.786 updated weights: [-0.368  2.512]\n","input: [3] actual output: 9 predicted output: 8.943999999999999 updated weights: [-0.366  2.513]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.37   2.512]\n","input: [5] actual output: 13 predicted output: 13.222000000000001 updated weights: [-0.381  2.51 ]\n","input: [1] actual output: 5 predicted output: 4.638999999999999 updated weights: [-0.377  2.514]\n","input: [2] actual output: 7 predicted output: 6.7879999999999985 updated weights: [-0.373  2.516]\n","input: [3] actual output: 9 predicted output: 8.945 updated weights: [-0.371  2.517]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.375  2.516]\n","input: [5] actual output: 13 predicted output: 13.221 updated weights: [-0.386  2.514]\n","input: [1] actual output: 5 predicted output: 4.6419999999999995 updated weights: [-0.382  2.518]\n","input: [2] actual output: 7 predicted output: 6.789999999999999 updated weights: [-0.378  2.52 ]\n","input: [3] actual output: 9 predicted output: 8.946 updated weights: [-0.376  2.521]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.38  2.52]\n","input: [5] actual output: 13 predicted output: 13.219999999999999 updated weights: [-0.391  2.518]\n","input: [1] actual output: 5 predicted output: 4.645 updated weights: [-0.387  2.522]\n","input: [2] actual output: 7 predicted output: 6.792 updated weights: [-0.383  2.524]\n","input: [3] actual output: 9 predicted output: 8.947 updated weights: [-0.381  2.525]\n","input: [4] actual output: 11 predicted output: 11.101 updated weights: [-0.385  2.524]\n","input: [5] actual output: 13 predicted output: 13.219000000000001 updated weights: [-0.396  2.522]\n","input: [1] actual output: 5 predicted output: 4.648 updated weights: [-0.392  2.526]\n","input: [2] actual output: 7 predicted output: 6.794 updated weights: [-0.388  2.528]\n","input: [3] actual output: 9 predicted output: 8.948 updated weights: [-0.386  2.529]\n","input: [4] actual output: 11 predicted output: 11.100999999999999 updated weights: [-0.39   2.528]\n","input: [5] actual output: 13 predicted output: 13.218000000000002 updated weights: [-0.401  2.526]\n","input: [1] actual output: 5 predicted output: 4.651 updated weights: [-0.398  2.529]\n","input: [2] actual output: 7 predicted output: 6.7909999999999995 updated weights: [-0.394  2.531]\n","input: [3] actual output: 9 predicted output: 8.942 updated weights: [-0.392  2.532]\n","input: [4] actual output: 11 predicted output: 11.092 updated weights: [-0.396  2.531]\n","input: [5] actual output: 13 predicted output: 13.206000000000001 updated weights: [-0.406  2.529]\n","input: [1] actual output: 5 predicted output: 4.651999999999999 updated weights: [-0.403  2.532]\n","input: [2] actual output: 7 predicted output: 6.79 updated weights: [-0.399  2.534]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.397  2.535]\n","input: [4] actual output: 11 predicted output: 11.087 updated weights: [-0.4    2.534]\n","input: [5] actual output: 13 predicted output: 13.203999999999997 updated weights: [-0.41   2.532]\n","input: [1] actual output: 5 predicted output: 4.654 updated weights: [-0.407  2.535]\n","input: [2] actual output: 7 predicted output: 6.791 updated weights: [-0.403  2.537]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.401  2.538]\n","input: [4] actual output: 11 predicted output: 11.085999999999999 updated weights: [-0.404  2.537]\n","input: [5] actual output: 13 predicted output: 13.201999999999998 updated weights: [-0.414  2.535]\n","input: [1] actual output: 5 predicted output: 4.656000000000001 updated weights: [-0.411  2.538]\n","input: [2] actual output: 7 predicted output: 6.792 updated weights: [-0.407  2.54 ]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.405  2.541]\n","input: [4] actual output: 11 predicted output: 11.085 updated weights: [-0.408  2.54 ]\n","input: [5] actual output: 13 predicted output: 13.2 updated weights: [-0.418  2.538]\n","input: [1] actual output: 5 predicted output: 4.6579999999999995 updated weights: [-0.415  2.541]\n","input: [2] actual output: 7 predicted output: 6.792999999999999 updated weights: [-0.411  2.543]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.409  2.544]\n","input: [4] actual output: 11 predicted output: 11.084000000000001 updated weights: [-0.412  2.543]\n","input: [5] actual output: 13 predicted output: 13.198 updated weights: [-0.422  2.541]\n","input: [1] actual output: 5 predicted output: 4.66 updated weights: [-0.419  2.544]\n","input: [2] actual output: 7 predicted output: 6.7940000000000005 updated weights: [-0.415  2.546]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.413  2.547]\n","input: [4] actual output: 11 predicted output: 11.083000000000002 updated weights: [-0.416  2.546]\n","input: [5] actual output: 13 predicted output: 13.195999999999998 updated weights: [-0.426  2.544]\n","input: [1] actual output: 5 predicted output: 4.662 updated weights: [-0.423  2.547]\n","input: [2] actual output: 7 predicted output: 6.795 updated weights: [-0.419  2.549]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.417  2.55 ]\n","input: [4] actual output: 11 predicted output: 11.082 updated weights: [-0.42   2.549]\n","input: [5] actual output: 13 predicted output: 13.193999999999999 updated weights: [-0.43   2.547]\n","input: [1] actual output: 5 predicted output: 4.664 updated weights: [-0.427  2.55 ]\n","input: [2] actual output: 7 predicted output: 6.795999999999999 updated weights: [-0.423  2.552]\n","input: [3] actual output: 9 predicted output: 8.939 updated weights: [-0.421  2.553]\n","input: [4] actual output: 11 predicted output: 11.081 updated weights: [-0.424  2.552]\n","input: [5] actual output: 13 predicted output: 13.192 updated weights: [-0.434  2.55 ]\n","input: [1] actual output: 5 predicted output: 4.6659999999999995 updated weights: [-0.431  2.553]\n","input: [2] actual output: 7 predicted output: 6.797 updated weights: [-0.427  2.555]\n","input: [3] actual output: 9 predicted output: 8.939000000000002 updated weights: [-0.425  2.556]\n","input: [4] actual output: 11 predicted output: 11.080000000000002 updated weights: [-0.428  2.555]\n","input: [5] actual output: 13 predicted output: 13.19 updated weights: [-0.437  2.553]\n","input: [1] actual output: 5 predicted output: 4.6690000000000005 updated weights: [-0.434  2.556]\n","input: [2] actual output: 7 predicted output: 6.8 updated weights: [-0.43   2.558]\n","input: [3] actual output: 9 predicted output: 8.942 updated weights: [-0.428  2.559]\n","input: [4] actual output: 11 predicted output: 11.083000000000002 updated weights: [-0.431  2.558]\n","input: [5] actual output: 13 predicted output: 13.193 updated weights: [-0.441  2.556]\n","input: [1] actual output: 5 predicted output: 4.671 updated weights: [-0.438  2.559]\n","input: [2] actual output: 7 predicted output: 6.801 updated weights: [-0.434  2.561]\n","input: [3] actual output: 9 predicted output: 8.942 updated weights: [-0.432  2.562]\n","input: [4] actual output: 11 predicted output: 11.081999999999999 updated weights: [-0.435  2.561]\n","input: [5] actual output: 13 predicted output: 13.190999999999999 updated weights: [-0.445  2.559]\n","input: [1] actual output: 5 predicted output: 4.673 updated weights: [-0.442  2.562]\n","input: [2] actual output: 7 predicted output: 6.802 updated weights: [-0.438  2.564]\n","input: [3] actual output: 9 predicted output: 8.942 updated weights: [-0.436  2.565]\n","input: [4] actual output: 11 predicted output: 11.081 updated weights: [-0.439  2.564]\n","input: [5] actual output: 13 predicted output: 13.189 updated weights: [-0.448  2.562]\n","input: [1] actual output: 5 predicted output: 4.676 updated weights: [-0.445  2.565]\n","input: [2] actual output: 7 predicted output: 6.805 updated weights: [-0.441  2.567]\n","input: [3] actual output: 9 predicted output: 8.945 updated weights: [-0.439  2.568]\n","input: [4] actual output: 11 predicted output: 11.084 updated weights: [-0.442  2.567]\n","input: [5] actual output: 13 predicted output: 13.192 updated weights: [-0.452  2.565]\n","input: [1] actual output: 5 predicted output: 4.678 updated weights: [-0.449  2.568]\n","input: [2] actual output: 7 predicted output: 6.806000000000001 updated weights: [-0.445  2.57 ]\n","input: [3] actual output: 9 predicted output: 8.944999999999999 updated weights: [-0.443  2.571]\n","input: [4] actual output: 11 predicted output: 11.083 updated weights: [-0.446  2.57 ]\n","input: [5] actual output: 13 predicted output: 13.19 updated weights: [-0.455  2.568]\n","input: [1] actual output: 5 predicted output: 4.681 updated weights: [-0.452  2.571]\n","input: [2] actual output: 7 predicted output: 6.809000000000001 updated weights: [-0.448  2.573]\n","input: [3] actual output: 9 predicted output: 8.947999999999999 updated weights: [-0.446  2.574]\n","input: [4] actual output: 11 predicted output: 11.085999999999999 updated weights: [-0.449  2.573]\n","input: [5] actual output: 13 predicted output: 13.193000000000001 updated weights: [-0.459  2.571]\n","input: [1] actual output: 5 predicted output: 4.683 updated weights: [-0.456  2.574]\n","input: [2] actual output: 7 predicted output: 6.81 updated weights: [-0.452  2.576]\n","input: [3] actual output: 9 predicted output: 8.948 updated weights: [-0.45   2.577]\n","input: [4] actual output: 11 predicted output: 11.084999999999999 updated weights: [-0.453  2.576]\n","input: [5] actual output: 13 predicted output: 13.191 updated weights: [-0.463  2.574]\n","input: [1] actual output: 5 predicted output: 4.685 updated weights: [-0.46   2.577]\n","input: [2] actual output: 7 predicted output: 6.811 updated weights: [-0.456  2.579]\n","input: [3] actual output: 9 predicted output: 8.948 updated weights: [-0.454  2.58 ]\n","input: [4] actual output: 11 predicted output: 11.084 updated weights: [-0.457  2.579]\n","input: [5] actual output: 13 predicted output: 13.189000000000002 updated weights: [-0.466  2.577]\n","input: [1] actual output: 5 predicted output: 4.688 updated weights: [-0.463  2.58 ]\n","input: [2] actual output: 7 predicted output: 6.814 updated weights: [-0.459  2.582]\n","input: [3] actual output: 9 predicted output: 8.951 updated weights: [-0.458  2.582]\n","input: [4] actual output: 11 predicted output: 11.078 updated weights: [-0.461  2.581]\n","input: [5] actual output: 13 predicted output: 13.181 updated weights: [-0.47   2.579]\n","input: [1] actual output: 5 predicted output: 4.688000000000001 updated weights: [-0.467  2.582]\n","input: [2] actual output: 7 predicted output: 6.811999999999999 updated weights: [-0.463  2.584]\n","input: [3] actual output: 9 predicted output: 8.947000000000001 updated weights: [-0.461  2.585]\n","input: [4] actual output: 11 predicted output: 11.081 updated weights: [-0.464  2.584]\n","input: [5] actual output: 13 predicted output: 13.184 updated weights: [-0.473  2.582]\n","input: [1] actual output: 5 predicted output: 4.691 updated weights: [-0.47   2.585]\n","input: [2] actual output: 7 predicted output: 6.815 updated weights: [-0.466  2.587]\n","input: [3] actual output: 9 predicted output: 8.950000000000001 updated weights: [-0.465  2.588]\n","input: [4] actual output: 11 predicted output: 11.080000000000002 updated weights: [-0.468  2.587]\n","input: [5] actual output: 13 predicted output: 13.182 updated weights: [-0.477  2.585]\n","input: [1] actual output: 5 predicted output: 4.693 updated weights: [-0.474  2.588]\n","input: [2] actual output: 7 predicted output: 6.816 updated weights: [-0.47  2.59]\n","input: [3] actual output: 9 predicted output: 8.95 updated weights: [-0.468  2.59 ]\n","input: [4] actual output: 11 predicted output: 11.078 updated weights: [-0.471  2.589]\n","input: [5] actual output: 13 predicted output: 13.179 updated weights: [-0.48   2.587]\n","input: [1] actual output: 5 predicted output: 4.694000000000001 updated weights: [-0.477  2.59 ]\n","input: [2] actual output: 7 predicted output: 6.816 updated weights: [-0.473  2.592]\n","input: [3] actual output: 9 predicted output: 8.949 updated weights: [-0.471  2.593]\n","input: [4] actual output: 11 predicted output: 11.081 updated weights: [-0.474  2.592]\n","input: [5] actual output: 13 predicted output: 13.182 updated weights: [-0.483  2.59 ]\n","input: [1] actual output: 5 predicted output: 4.696999999999999 updated weights: [-0.48   2.593]\n","input: [2] actual output: 7 predicted output: 6.819 updated weights: [-0.476  2.595]\n","input: [3] actual output: 9 predicted output: 8.952 updated weights: [-0.475  2.595]\n","input: [4] actual output: 11 predicted output: 11.075000000000001 updated weights: [-0.478  2.594]\n","input: [5] actual output: 13 predicted output: 13.173999999999998 updated weights: [-0.487  2.592]\n","input: [1] actual output: 5 predicted output: 4.697 updated weights: [-0.484  2.595]\n","input: [2] actual output: 7 predicted output: 6.817 updated weights: [-0.48   2.597]\n","input: [3] actual output: 9 predicted output: 8.948 updated weights: [-0.478  2.598]\n","input: [4] actual output: 11 predicted output: 11.078 updated weights: [-0.481  2.597]\n","input: [5] actual output: 13 predicted output: 13.177 updated weights: [-0.49   2.595]\n","input: [1] actual output: 5 predicted output: 4.700000000000001 updated weights: [-0.487  2.598]\n","input: [2] actual output: 7 predicted output: 6.819999999999999 updated weights: [-0.483  2.6  ]\n","input: [3] actual output: 9 predicted output: 8.951 updated weights: [-0.482  2.6  ]\n","input: [4] actual output: 11 predicted output: 11.072000000000001 updated weights: [-0.485  2.599]\n","input: [5] actual output: 13 predicted output: 13.169 updated weights: [-0.493  2.597]\n","input: [1] actual output: 5 predicted output: 4.7010000000000005 updated weights: [-0.49  2.6 ]\n","input: [2] actual output: 7 predicted output: 6.82 updated weights: [-0.486  2.602]\n","input: [3] actual output: 9 predicted output: 8.95 updated weights: [-0.484  2.602]\n","input: [4] actual output: 11 predicted output: 11.074 updated weights: [-0.487  2.601]\n","input: [5] actual output: 13 predicted output: 13.171 updated weights: [-0.496  2.599]\n","input: [1] actual output: 5 predicted output: 4.702 updated weights: [-0.493  2.602]\n","input: [2] actual output: 7 predicted output: 6.82 updated weights: [-0.489  2.604]\n","input: [3] actual output: 9 predicted output: 8.949000000000002 updated weights: [-0.487  2.605]\n","input: [4] actual output: 11 predicted output: 11.077 updated weights: [-0.49   2.604]\n","input: [5] actual output: 13 predicted output: 13.174 updated weights: [-0.499  2.602]\n","input: [1] actual output: 5 predicted output: 4.705 updated weights: [-0.496  2.605]\n","input: [2] actual output: 7 predicted output: 6.823 updated weights: [-0.492  2.607]\n","input: [3] actual output: 9 predicted output: 8.952000000000002 updated weights: [-0.491  2.607]\n","input: [4] actual output: 11 predicted output: 11.071000000000002 updated weights: [-0.494  2.606]\n","input: [5] actual output: 13 predicted output: 13.165999999999999 updated weights: [-0.502  2.604]\n","input: [1] actual output: 5 predicted output: 4.706 updated weights: [-0.499  2.607]\n","input: [2] actual output: 7 predicted output: 6.823 updated weights: [-0.495  2.609]\n","input: [3] actual output: 9 predicted output: 8.951 updated weights: [-0.494  2.609]\n","input: [4] actual output: 11 predicted output: 11.069 updated weights: [-0.497  2.608]\n","input: [5] actual output: 13 predicted output: 13.163000000000002 updated weights: [-0.505  2.606]\n","input: [1] actual output: 5 predicted output: 4.707 updated weights: [-0.502  2.609]\n","input: [2] actual output: 7 predicted output: 6.823 updated weights: [-0.498  2.611]\n","input: [3] actual output: 9 predicted output: 8.950000000000001 updated weights: [-0.497  2.612]\n","input: [4] actual output: 11 predicted output: 11.072000000000001 updated weights: [-0.5    2.611]\n","input: [5] actual output: 13 predicted output: 13.166000000000002 updated weights: [-0.508  2.609]\n","input: [1] actual output: 5 predicted output: 4.71 updated weights: [-0.505  2.612]\n","input: [2] actual output: 7 predicted output: 6.8260000000000005 updated weights: [-0.502  2.614]\n","input: [3] actual output: 9 predicted output: 8.95 updated weights: [-0.5    2.614]\n","input: [4] actual output: 11 predicted output: 11.07 updated weights: [-0.503  2.613]\n","input: [5] actual output: 13 predicted output: 13.162999999999998 updated weights: [-0.511  2.611]\n","input: [1] actual output: 5 predicted output: 4.711 updated weights: [-0.508  2.614]\n","input: [2] actual output: 7 predicted output: 6.826 updated weights: [-0.505  2.616]\n","input: [3] actual output: 9 predicted output: 8.949 updated weights: [-0.503  2.617]\n","input: [4] actual output: 11 predicted output: 11.073 updated weights: [-0.506  2.616]\n","input: [5] actual output: 13 predicted output: 13.166 updated weights: [-0.514  2.614]\n","input: [1] actual output: 5 predicted output: 4.7139999999999995 updated weights: [-0.511  2.617]\n","input: [2] actual output: 7 predicted output: 6.829 updated weights: [-0.508  2.619]\n","input: [3] actual output: 9 predicted output: 8.952000000000002 updated weights: [-0.507  2.619]\n","input: [4] actual output: 11 predicted output: 11.067 updated weights: [-0.51   2.618]\n","input: [5] actual output: 13 predicted output: 13.158 updated weights: [-0.518  2.616]\n","input: [1] actual output: 5 predicted output: 4.714 updated weights: [-0.515  2.619]\n","input: [2] actual output: 7 predicted output: 6.827 updated weights: [-0.512  2.621]\n","input: [3] actual output: 9 predicted output: 8.948 updated weights: [-0.51   2.622]\n","input: [4] actual output: 11 predicted output: 11.07 updated weights: [-0.513  2.621]\n","input: [5] actual output: 13 predicted output: 13.161000000000001 updated weights: [-0.521  2.619]\n","input: [1] actual output: 5 predicted output: 4.7170000000000005 updated weights: [-0.518  2.622]\n","input: [2] actual output: 7 predicted output: 6.83 updated weights: [-0.515  2.624]\n","input: [3] actual output: 9 predicted output: 8.951 updated weights: [-0.514  2.624]\n","input: [4] actual output: 11 predicted output: 11.064000000000002 updated weights: [-0.517  2.623]\n","input: [5] actual output: 13 predicted output: 13.153000000000002 updated weights: [-0.525  2.621]\n","input: [1] actual output: 5 predicted output: 4.7170000000000005 updated weights: [-0.522  2.624]\n","input: [2] actual output: 7 predicted output: 6.828000000000001 updated weights: [-0.519  2.626]\n","input: [3] actual output: 9 predicted output: 8.947 updated weights: [-0.517  2.627]\n","input: [4] actual output: 11 predicted output: 11.067 updated weights: [-0.52   2.626]\n","input: [5] actual output: 13 predicted output: 13.155999999999999 updated weights: [-0.528  2.624]\n","input: [1] actual output: 5 predicted output: 4.720000000000001 updated weights: [-0.525  2.627]\n","input: [2] actual output: 7 predicted output: 6.8309999999999995 updated weights: [-0.522  2.629]\n","input: [3] actual output: 9 predicted output: 8.950000000000001 updated weights: [-0.521  2.63 ]\n","input: [4] actual output: 11 predicted output: 11.065999999999999 updated weights: [-0.524  2.629]\n","input: [5] actual output: 13 predicted output: 13.153999999999998 updated weights: [-0.532  2.627]\n","input: [1] actual output: 5 predicted output: 4.7219999999999995 updated weights: [-0.529  2.63 ]\n","input: [2] actual output: 7 predicted output: 6.832 updated weights: [-0.526  2.632]\n","input: [3] actual output: 9 predicted output: 8.950000000000001 updated weights: [-0.525  2.633]\n","input: [4] actual output: 11 predicted output: 11.065000000000001 updated weights: [-0.528  2.632]\n","input: [5] actual output: 13 predicted output: 13.152 updated weights: [-0.536  2.63 ]\n","input: [1] actual output: 5 predicted output: 4.724 updated weights: [-0.533  2.633]\n","input: [2] actual output: 7 predicted output: 6.833 updated weights: [-0.53   2.635]\n","input: [3] actual output: 9 predicted output: 8.95 updated weights: [-0.528  2.636]\n","input: [4] actual output: 11 predicted output: 11.068000000000001 updated weights: [-0.531  2.635]\n","input: [5] actual output: 13 predicted output: 13.155 updated weights: [-0.539  2.633]\n","input: [1] actual output: 5 predicted output: 4.727 updated weights: [-0.536  2.636]\n","input: [2] actual output: 7 predicted output: 6.836 updated weights: [-0.533  2.638]\n","input: [3] actual output: 9 predicted output: 8.953 updated weights: [-0.532  2.638]\n","input: [4] actual output: 11 predicted output: 11.062 updated weights: [-0.534  2.637]\n","input: [5] actual output: 13 predicted output: 13.152000000000001 updated weights: [-0.542  2.635]\n","input: [1] actual output: 5 predicted output: 4.728 updated weights: [-0.539  2.638]\n","input: [2] actual output: 7 predicted output: 6.835999999999999 updated weights: [-0.536  2.64 ]\n","input: [3] actual output: 9 predicted output: 8.952 updated weights: [-0.535  2.64 ]\n","input: [4] actual output: 11 predicted output: 11.06 updated weights: [-0.537  2.639]\n","input: [5] actual output: 13 predicted output: 13.148999999999997 updated weights: [-0.544  2.638]\n","input: [1] actual output: 5 predicted output: 4.731999999999999 updated weights: [-0.541  2.641]\n","input: [2] actual output: 7 predicted output: 6.841 updated weights: [-0.538  2.643]\n","input: [3] actual output: 9 predicted output: 8.957999999999998 updated weights: [-0.537  2.643]\n","input: [4] actual output: 11 predicted output: 11.067 updated weights: [-0.54   2.642]\n","input: [5] actual output: 13 predicted output: 13.151999999999997 updated weights: [-0.548  2.64 ]\n","input: [1] actual output: 5 predicted output: 4.732 updated weights: [-0.545  2.643]\n","input: [2] actual output: 7 predicted output: 6.8389999999999995 updated weights: [-0.542  2.645]\n","input: [3] actual output: 9 predicted output: 8.954 updated weights: [-0.541  2.645]\n","input: [4] actual output: 11 predicted output: 11.061 updated weights: [-0.543  2.644]\n","input: [5] actual output: 13 predicted output: 13.149000000000001 updated weights: [-0.55   2.643]\n","input: [1] actual output: 5 predicted output: 4.736 updated weights: [-0.547  2.646]\n","input: [2] actual output: 7 predicted output: 6.843999999999999 updated weights: [-0.544  2.648]\n","input: [3] actual output: 9 predicted output: 8.96 updated weights: [-0.543  2.648]\n","input: [4] actual output: 11 predicted output: 11.068 updated weights: [-0.546  2.647]\n","input: [5] actual output: 13 predicted output: 13.152 updated weights: [-0.554  2.645]\n","input: [1] actual output: 5 predicted output: 4.736000000000001 updated weights: [-0.551  2.648]\n","input: [2] actual output: 7 predicted output: 6.8420000000000005 updated weights: [-0.548  2.65 ]\n","input: [3] actual output: 9 predicted output: 8.956 updated weights: [-0.547  2.65 ]\n","input: [4] actual output: 11 predicted output: 11.062 updated weights: [-0.549  2.649]\n","input: [5] actual output: 13 predicted output: 13.149000000000001 updated weights: [-0.556  2.648]\n","input: [1] actual output: 5 predicted output: 4.74 updated weights: [-0.553  2.651]\n","input: [2] actual output: 7 predicted output: 6.8469999999999995 updated weights: [-0.55   2.653]\n","input: [3] actual output: 9 predicted output: 8.962 updated weights: [-0.549  2.653]\n","input: [4] actual output: 11 predicted output: 11.069 updated weights: [-0.552  2.652]\n","input: [5] actual output: 13 predicted output: 13.152000000000001 updated weights: [-0.56  2.65]\n","input: [1] actual output: 5 predicted output: 4.74 updated weights: [-0.557  2.653]\n","input: [2] actual output: 7 predicted output: 6.845000000000001 updated weights: [-0.554  2.655]\n","input: [3] actual output: 9 predicted output: 8.958 updated weights: [-0.553  2.655]\n","input: [4] actual output: 11 predicted output: 11.062999999999999 updated weights: [-0.556  2.654]\n","input: [5] actual output: 13 predicted output: 13.143999999999998 updated weights: [-0.563  2.653]\n","input: [1] actual output: 5 predicted output: 4.743 updated weights: [-0.56   2.656]\n","input: [2] actual output: 7 predicted output: 6.848000000000001 updated weights: [-0.557  2.658]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.556  2.658]\n","input: [4] actual output: 11 predicted output: 11.065999999999999 updated weights: [-0.559  2.657]\n","input: [5] actual output: 13 predicted output: 13.147 updated weights: [-0.566  2.656]\n","input: [1] actual output: 5 predicted output: 4.746 updated weights: [-0.563  2.659]\n","input: [2] actual output: 7 predicted output: 6.851 updated weights: [-0.56  2.66]\n","input: [3] actual output: 9 predicted output: 8.96 updated weights: [-0.559  2.66 ]\n","input: [4] actual output: 11 predicted output: 11.064 updated weights: [-0.562  2.659]\n","input: [5] actual output: 13 predicted output: 13.143999999999998 updated weights: [-0.569  2.658]\n","input: [1] actual output: 5 predicted output: 4.747 updated weights: [-0.566  2.661]\n","input: [2] actual output: 7 predicted output: 6.851000000000001 updated weights: [-0.563  2.662]\n","input: [3] actual output: 9 predicted output: 8.959 updated weights: [-0.562  2.662]\n","input: [4] actual output: 11 predicted output: 11.061999999999998 updated weights: [-0.564  2.661]\n","input: [5] actual output: 13 predicted output: 13.145999999999999 updated weights: [-0.571  2.66 ]\n","input: [1] actual output: 5 predicted output: 4.7490000000000006 updated weights: [-0.568  2.663]\n","input: [2] actual output: 7 predicted output: 6.853 updated weights: [-0.565  2.664]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.564  2.664]\n","input: [4] actual output: 11 predicted output: 11.064 updated weights: [-0.567  2.663]\n","input: [5] actual output: 13 predicted output: 13.143 updated weights: [-0.574  2.662]\n","input: [1] actual output: 5 predicted output: 4.75 updated weights: [-0.572  2.664]\n","input: [2] actual output: 7 predicted output: 6.848000000000001 updated weights: [-0.569  2.666]\n","input: [3] actual output: 9 predicted output: 8.956999999999999 updated weights: [-0.568  2.666]\n","input: [4] actual output: 11 predicted output: 11.058 updated weights: [-0.57   2.665]\n","input: [5] actual output: 13 predicted output: 13.14 updated weights: [-0.577  2.664]\n","input: [1] actual output: 5 predicted output: 4.751 updated weights: [-0.575  2.666]\n","input: [2] actual output: 7 predicted output: 6.848000000000001 updated weights: [-0.572  2.668]\n","input: [3] actual output: 9 predicted output: 8.956000000000003 updated weights: [-0.571  2.668]\n","input: [4] actual output: 11 predicted output: 11.056000000000001 updated weights: [-0.573  2.667]\n","input: [5] actual output: 13 predicted output: 13.136999999999999 updated weights: [-0.58   2.666]\n","input: [1] actual output: 5 predicted output: 4.752 updated weights: [-0.578  2.668]\n","input: [2] actual output: 7 predicted output: 6.848000000000001 updated weights: [-0.575  2.67 ]\n","input: [3] actual output: 9 predicted output: 8.955 updated weights: [-0.574  2.67 ]\n","input: [4] actual output: 11 predicted output: 11.054 updated weights: [-0.576  2.669]\n","input: [5] actual output: 13 predicted output: 13.134 updated weights: [-0.583  2.668]\n","input: [1] actual output: 5 predicted output: 4.753 updated weights: [-0.581  2.67 ]\n","input: [2] actual output: 7 predicted output: 6.848 updated weights: [-0.578  2.672]\n","input: [3] actual output: 9 predicted output: 8.954 updated weights: [-0.577  2.672]\n","input: [4] actual output: 11 predicted output: 11.052000000000001 updated weights: [-0.579  2.671]\n","input: [5] actual output: 13 predicted output: 13.130999999999998 updated weights: [-0.586  2.67 ]\n","input: [1] actual output: 5 predicted output: 4.754 updated weights: [-0.584  2.672]\n","input: [2] actual output: 7 predicted output: 6.848000000000001 updated weights: [-0.581  2.674]\n","input: [3] actual output: 9 predicted output: 8.953 updated weights: [-0.58   2.674]\n","input: [4] actual output: 11 predicted output: 11.049999999999999 updated weights: [-0.582  2.673]\n","input: [5] actual output: 13 predicted output: 13.128 updated weights: [-0.588  2.672]\n","input: [1] actual output: 5 predicted output: 4.756 updated weights: [-0.586  2.674]\n","input: [2] actual output: 7 predicted output: 6.85 updated weights: [-0.583  2.676]\n","input: [3] actual output: 9 predicted output: 8.955000000000002 updated weights: [-0.582  2.676]\n","input: [4] actual output: 11 predicted output: 11.052000000000001 updated weights: [-0.584  2.675]\n","input: [5] actual output: 13 predicted output: 13.129999999999999 updated weights: [-0.59   2.674]\n","input: [1] actual output: 5 predicted output: 4.758 updated weights: [-0.588  2.676]\n","input: [2] actual output: 7 predicted output: 6.852 updated weights: [-0.585  2.677]\n","input: [3] actual output: 9 predicted output: 8.953000000000001 updated weights: [-0.584  2.677]\n","input: [4] actual output: 11 predicted output: 11.049 updated weights: [-0.586  2.677]\n","input: [5] actual output: 13 predicted output: 13.132 updated weights: [-0.593  2.676]\n","input: [1] actual output: 5 predicted output: 4.759 updated weights: [-0.591  2.678]\n","input: [2] actual output: 7 predicted output: 6.851999999999999 updated weights: [-0.588  2.679]\n","input: [3] actual output: 9 predicted output: 8.952 updated weights: [-0.587  2.679]\n","input: [4] actual output: 11 predicted output: 11.046999999999999 updated weights: [-0.589  2.679]\n","input: [5] actual output: 13 predicted output: 13.129 updated weights: [-0.595  2.678]\n","input: [1] actual output: 5 predicted output: 4.761 updated weights: [-0.593  2.68 ]\n","input: [2] actual output: 7 predicted output: 6.854000000000001 updated weights: [-0.59   2.681]\n","input: [3] actual output: 9 predicted output: 8.954 updated weights: [-0.589  2.681]\n","input: [4] actual output: 11 predicted output: 11.049 updated weights: [-0.591  2.681]\n","input: [5] actual output: 13 predicted output: 13.131 updated weights: [-0.598  2.68 ]\n","input: [1] actual output: 5 predicted output: 4.7620000000000005 updated weights: [-0.596  2.682]\n","input: [2] actual output: 7 predicted output: 6.853999999999999 updated weights: [-0.593  2.683]\n","input: [3] actual output: 9 predicted output: 8.953 updated weights: [-0.592  2.683]\n","input: [4] actual output: 11 predicted output: 11.046999999999999 updated weights: [-0.594  2.683]\n","input: [5] actual output: 13 predicted output: 13.128 updated weights: [-0.6    2.682]\n","input: [1] actual output: 5 predicted output: 4.763999999999999 updated weights: [-0.598  2.684]\n","input: [2] actual output: 7 predicted output: 6.856000000000001 updated weights: [-0.595  2.685]\n","input: [3] actual output: 9 predicted output: 8.955 updated weights: [-0.594  2.685]\n","input: [4] actual output: 11 predicted output: 11.049000000000001 updated weights: [-0.596  2.685]\n","input: [5] actual output: 13 predicted output: 13.13 updated weights: [-0.602  2.684]\n","input: [1] actual output: 5 predicted output: 4.766 updated weights: [-0.6    2.686]\n","input: [2] actual output: 7 predicted output: 6.858 updated weights: [-0.597  2.687]\n","input: [3] actual output: 9 predicted output: 8.956999999999999 updated weights: [-0.596  2.687]\n","input: [4] actual output: 11 predicted output: 11.050999999999998 updated weights: [-0.598  2.686]\n","input: [5] actual output: 13 predicted output: 13.126 updated weights: [-0.604  2.685]\n","input: [1] actual output: 5 predicted output: 4.766 updated weights: [-0.602  2.687]\n","input: [2] actual output: 7 predicted output: 6.856999999999999 updated weights: [-0.599  2.688]\n","input: [3] actual output: 9 predicted output: 8.955 updated weights: [-0.598  2.688]\n","input: [4] actual output: 11 predicted output: 11.048000000000002 updated weights: [-0.6    2.688]\n","input: [5] actual output: 13 predicted output: 13.128000000000002 updated weights: [-0.606  2.687]\n","input: [1] actual output: 5 predicted output: 4.768 updated weights: [-0.604  2.689]\n","input: [2] actual output: 7 predicted output: 6.859 updated weights: [-0.601  2.69 ]\n","input: [3] actual output: 9 predicted output: 8.957 updated weights: [-0.6   2.69]\n","input: [4] actual output: 11 predicted output: 11.049999999999999 updated weights: [-0.602  2.69 ]\n","input: [5] actual output: 13 predicted output: 13.129999999999999 updated weights: [-0.608  2.689]\n","input: [1] actual output: 5 predicted output: 4.77 updated weights: [-0.606  2.691]\n","input: [2] actual output: 7 predicted output: 6.861 updated weights: [-0.603  2.692]\n","input: [3] actual output: 9 predicted output: 8.959 updated weights: [-0.602  2.692]\n","input: [4] actual output: 11 predicted output: 11.052000000000001 updated weights: [-0.604  2.691]\n","input: [5] actual output: 13 predicted output: 13.125999999999998 updated weights: [-0.61  2.69]\n","input: [1] actual output: 5 predicted output: 4.77 updated weights: [-0.608  2.692]\n","input: [2] actual output: 7 predicted output: 6.86 updated weights: [-0.605  2.693]\n","input: [3] actual output: 9 predicted output: 8.957 updated weights: [-0.604  2.693]\n","input: [4] actual output: 11 predicted output: 11.049 updated weights: [-0.606  2.693]\n","input: [5] actual output: 13 predicted output: 13.128 updated weights: [-0.612  2.692]\n","input: [1] actual output: 5 predicted output: 4.772 updated weights: [-0.61   2.694]\n","input: [2] actual output: 7 predicted output: 6.862 updated weights: [-0.607  2.695]\n","input: [3] actual output: 9 predicted output: 8.959 updated weights: [-0.606  2.695]\n","input: [4] actual output: 11 predicted output: 11.051 updated weights: [-0.608  2.694]\n","input: [5] actual output: 13 predicted output: 13.123999999999999 updated weights: [-0.614  2.693]\n","input: [1] actual output: 5 predicted output: 4.772 updated weights: [-0.612  2.695]\n","input: [2] actual output: 7 predicted output: 6.860999999999999 updated weights: [-0.609  2.696]\n","input: [3] actual output: 9 predicted output: 8.957 updated weights: [-0.608  2.696]\n","input: [4] actual output: 11 predicted output: 11.048 updated weights: [-0.61   2.696]\n","input: [5] actual output: 13 predicted output: 13.126 updated weights: [-0.616  2.695]\n","input: [1] actual output: 5 predicted output: 4.773999999999999 updated weights: [-0.614  2.697]\n","input: [2] actual output: 7 predicted output: 6.863 updated weights: [-0.611  2.698]\n","input: [3] actual output: 9 predicted output: 8.959 updated weights: [-0.61   2.698]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.612  2.698]\n","input: [5] actual output: 13 predicted output: 13.128 updated weights: [-0.618  2.697]\n","input: [1] actual output: 5 predicted output: 4.776 updated weights: [-0.616  2.699]\n","input: [2] actual output: 7 predicted output: 6.864999999999999 updated weights: [-0.613  2.7  ]\n","input: [3] actual output: 9 predicted output: 8.961000000000002 updated weights: [-0.612  2.7  ]\n","input: [4] actual output: 11 predicted output: 11.052 updated weights: [-0.614  2.699]\n","input: [5] actual output: 13 predicted output: 13.123999999999999 updated weights: [-0.62   2.698]\n","input: [1] actual output: 5 predicted output: 4.776 updated weights: [-0.618  2.7  ]\n","input: [2] actual output: 7 predicted output: 6.864000000000001 updated weights: [-0.615  2.701]\n","input: [3] actual output: 9 predicted output: 8.959 updated weights: [-0.614  2.701]\n","input: [4] actual output: 11 predicted output: 11.049000000000001 updated weights: [-0.616  2.701]\n","input: [5] actual output: 13 predicted output: 13.126000000000001 updated weights: [-0.622  2.7  ]\n","input: [1] actual output: 5 predicted output: 4.7780000000000005 updated weights: [-0.62   2.702]\n","input: [2] actual output: 7 predicted output: 6.866 updated weights: [-0.617  2.703]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.616  2.703]\n","input: [4] actual output: 11 predicted output: 11.050999999999998 updated weights: [-0.618  2.702]\n","input: [5] actual output: 13 predicted output: 13.122 updated weights: [-0.624  2.701]\n","input: [1] actual output: 5 predicted output: 4.7780000000000005 updated weights: [-0.622  2.703]\n","input: [2] actual output: 7 predicted output: 6.865 updated weights: [-0.619  2.704]\n","input: [3] actual output: 9 predicted output: 8.959 updated weights: [-0.618  2.704]\n","input: [4] actual output: 11 predicted output: 11.048000000000002 updated weights: [-0.62   2.704]\n","input: [5] actual output: 13 predicted output: 13.124000000000002 updated weights: [-0.626  2.703]\n","input: [1] actual output: 5 predicted output: 4.779999999999999 updated weights: [-0.624  2.705]\n","input: [2] actual output: 7 predicted output: 6.867 updated weights: [-0.621  2.706]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.62   2.706]\n","input: [4] actual output: 11 predicted output: 11.049999999999999 updated weights: [-0.622  2.706]\n","input: [5] actual output: 13 predicted output: 13.126 updated weights: [-0.628  2.705]\n","input: [1] actual output: 5 predicted output: 4.782 updated weights: [-0.626  2.707]\n","input: [2] actual output: 7 predicted output: 6.869 updated weights: [-0.623  2.708]\n","input: [3] actual output: 9 predicted output: 8.963000000000001 updated weights: [-0.622  2.708]\n","input: [4] actual output: 11 predicted output: 11.052000000000001 updated weights: [-0.624  2.707]\n","input: [5] actual output: 13 predicted output: 13.122 updated weights: [-0.63   2.706]\n","input: [1] actual output: 5 predicted output: 4.782 updated weights: [-0.628  2.708]\n","input: [2] actual output: 7 predicted output: 6.868 updated weights: [-0.625  2.709]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.624  2.709]\n","input: [4] actual output: 11 predicted output: 11.049 updated weights: [-0.626  2.709]\n","input: [5] actual output: 13 predicted output: 13.123999999999999 updated weights: [-0.632  2.708]\n","input: [1] actual output: 5 predicted output: 4.784000000000001 updated weights: [-0.63  2.71]\n","input: [2] actual output: 7 predicted output: 6.87 updated weights: [-0.627  2.711]\n","input: [3] actual output: 9 predicted output: 8.963 updated weights: [-0.626  2.711]\n","input: [4] actual output: 11 predicted output: 11.051 updated weights: [-0.628  2.71 ]\n","input: [5] actual output: 13 predicted output: 13.120000000000001 updated weights: [-0.634  2.709]\n","input: [1] actual output: 5 predicted output: 4.784000000000001 updated weights: [-0.632  2.711]\n","input: [2] actual output: 7 predicted output: 6.869 updated weights: [-0.629  2.712]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.628  2.712]\n","input: [4] actual output: 11 predicted output: 11.048 updated weights: [-0.63   2.712]\n","input: [5] actual output: 13 predicted output: 13.122 updated weights: [-0.636  2.711]\n","input: [1] actual output: 5 predicted output: 4.786 updated weights: [-0.634  2.713]\n","input: [2] actual output: 7 predicted output: 6.871 updated weights: [-0.631  2.714]\n","input: [3] actual output: 9 predicted output: 8.963 updated weights: [-0.63   2.714]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.632  2.714]\n","input: [5] actual output: 13 predicted output: 13.124 updated weights: [-0.638  2.713]\n","input: [1] actual output: 5 predicted output: 4.788 updated weights: [-0.636  2.715]\n","input: [2] actual output: 7 predicted output: 6.872999999999999 updated weights: [-0.633  2.716]\n","input: [3] actual output: 9 predicted output: 8.965 updated weights: [-0.632  2.716]\n","input: [4] actual output: 11 predicted output: 11.052 updated weights: [-0.634  2.715]\n","input: [5] actual output: 13 predicted output: 13.12 updated weights: [-0.64   2.714]\n","input: [1] actual output: 5 predicted output: 4.788 updated weights: [-0.638  2.716]\n","input: [2] actual output: 7 predicted output: 6.872000000000001 updated weights: [-0.635  2.717]\n","input: [3] actual output: 9 predicted output: 8.963 updated weights: [-0.634  2.717]\n","input: [4] actual output: 11 predicted output: 11.049000000000001 updated weights: [-0.636  2.717]\n","input: [5] actual output: 13 predicted output: 13.122000000000002 updated weights: [-0.642  2.716]\n","input: [1] actual output: 5 predicted output: 4.790000000000001 updated weights: [-0.64   2.718]\n","input: [2] actual output: 7 predicted output: 6.874 updated weights: [-0.637  2.719]\n","input: [3] actual output: 9 predicted output: 8.965 updated weights: [-0.636  2.719]\n","input: [4] actual output: 11 predicted output: 11.050999999999998 updated weights: [-0.638  2.718]\n","input: [5] actual output: 13 predicted output: 13.118 updated weights: [-0.644  2.717]\n","input: [1] actual output: 5 predicted output: 4.79 updated weights: [-0.642  2.719]\n","input: [2] actual output: 7 predicted output: 6.872999999999999 updated weights: [-0.639  2.72 ]\n","input: [3] actual output: 9 predicted output: 8.963000000000001 updated weights: [-0.638  2.72 ]\n","input: [4] actual output: 11 predicted output: 11.048000000000002 updated weights: [-0.64  2.72]\n","input: [5] actual output: 13 predicted output: 13.120000000000003 updated weights: [-0.646  2.719]\n","input: [1] actual output: 5 predicted output: 4.792 updated weights: [-0.644  2.721]\n","input: [2] actual output: 7 predicted output: 6.875 updated weights: [-0.642  2.722]\n","input: [3] actual output: 9 predicted output: 8.962 updated weights: [-0.641  2.722]\n","input: [4] actual output: 11 predicted output: 11.046 updated weights: [-0.643  2.722]\n","input: [5] actual output: 13 predicted output: 13.116999999999999 updated weights: [-0.649  2.721]\n","input: [1] actual output: 5 predicted output: 4.793 updated weights: [-0.647  2.723]\n","input: [2] actual output: 7 predicted output: 6.874999999999999 updated weights: [-0.644  2.724]\n","input: [3] actual output: 9 predicted output: 8.964 updated weights: [-0.643  2.724]\n","input: [4] actual output: 11 predicted output: 11.048000000000002 updated weights: [-0.645  2.724]\n","input: [5] actual output: 13 predicted output: 13.119000000000002 updated weights: [-0.651  2.723]\n","input: [1] actual output: 5 predicted output: 4.795 updated weights: [-0.649  2.725]\n","input: [2] actual output: 7 predicted output: 6.877000000000001 updated weights: [-0.647  2.726]\n","input: [3] actual output: 9 predicted output: 8.963000000000001 updated weights: [-0.646  2.726]\n","input: [4] actual output: 11 predicted output: 11.046 updated weights: [-0.648  2.726]\n","input: [5] actual output: 13 predicted output: 13.116 updated weights: [-0.654  2.725]\n","input: [1] actual output: 5 predicted output: 4.796 updated weights: [-0.652  2.727]\n","input: [2] actual output: 7 predicted output: 6.876999999999999 updated weights: [-0.65   2.728]\n","input: [3] actual output: 9 predicted output: 8.962000000000002 updated weights: [-0.649  2.728]\n","input: [4] actual output: 11 predicted output: 11.044 updated weights: [-0.651  2.728]\n","input: [5] actual output: 13 predicted output: 13.113000000000001 updated weights: [-0.657  2.727]\n","input: [1] actual output: 5 predicted output: 4.797 updated weights: [-0.655  2.729]\n","input: [2] actual output: 7 predicted output: 6.877 updated weights: [-0.653  2.73 ]\n","input: [3] actual output: 9 predicted output: 8.961 updated weights: [-0.652  2.73 ]\n","input: [4] actual output: 11 predicted output: 11.042 updated weights: [-0.654  2.73 ]\n","input: [5] actual output: 13 predicted output: 13.110000000000001 updated weights: [-0.66   2.729]\n","input: [1] actual output: 5 predicted output: 4.798 updated weights: [-0.658  2.731]\n","input: [2] actual output: 7 predicted output: 6.877 updated weights: [-0.656  2.732]\n","input: [3] actual output: 9 predicted output: 8.96 updated weights: [-0.655  2.732]\n","input: [4] actual output: 11 predicted output: 11.04 updated weights: [-0.657  2.732]\n","input: [5] actual output: 13 predicted output: 13.107 updated weights: [-0.662  2.731]\n","input: [1] actual output: 5 predicted output: 4.8 updated weights: [-0.66   2.733]\n","input: [2] actual output: 7 predicted output: 6.879 updated weights: [-0.658  2.734]\n","input: [3] actual output: 9 predicted output: 8.962 updated weights: [-0.657  2.734]\n","input: [4] actual output: 11 predicted output: 11.042 updated weights: [-0.659  2.734]\n","input: [5] actual output: 13 predicted output: 13.109 updated weights: [-0.664  2.733]\n","input: [1] actual output: 5 predicted output: 4.802 updated weights: [-0.662  2.735]\n","input: [2] actual output: 7 predicted output: 6.881 updated weights: [-0.66   2.736]\n","input: [3] actual output: 9 predicted output: 8.964 updated weights: [-0.659  2.736]\n","input: [4] actual output: 11 predicted output: 11.044 updated weights: [-0.661  2.736]\n","input: [5] actual output: 13 predicted output: 13.111000000000002 updated weights: [-0.667  2.735]\n","input: [1] actual output: 5 predicted output: 4.802999999999999 updated weights: [-0.665  2.737]\n","input: [2] actual output: 7 predicted output: 6.881 updated weights: [-0.663  2.738]\n","input: [3] actual output: 9 predicted output: 8.963000000000001 updated weights: [-0.662  2.738]\n","input: [4] actual output: 11 predicted output: 11.042 updated weights: [-0.664  2.738]\n","input: [5] actual output: 13 predicted output: 13.107999999999999 updated weights: [-0.669  2.737]\n","input: [1] actual output: 5 predicted output: 4.805 updated weights: [-0.667  2.739]\n","input: [2] actual output: 7 predicted output: 6.883 updated weights: [-0.665  2.74 ]\n","input: [3] actual output: 9 predicted output: 8.965 updated weights: [-0.664  2.74 ]\n","input: [4] actual output: 11 predicted output: 11.044 updated weights: [-0.666  2.74 ]\n","input: [5] actual output: 13 predicted output: 13.110000000000001 updated weights: [-0.672  2.739]\n","input: [1] actual output: 5 predicted output: 4.805999999999999 updated weights: [-0.67   2.741]\n","input: [2] actual output: 7 predicted output: 6.883000000000001 updated weights: [-0.668  2.742]\n","input: [3] actual output: 9 predicted output: 8.963999999999999 updated weights: [-0.667  2.742]\n","input: [4] actual output: 11 predicted output: 11.042000000000002 updated weights: [-0.669  2.742]\n","input: [5] actual output: 13 predicted output: 13.107 updated weights: [-0.674  2.741]\n","input: [1] actual output: 5 predicted output: 4.808 updated weights: [-0.672  2.743]\n","input: [2] actual output: 7 predicted output: 6.885 updated weights: [-0.67   2.744]\n","input: [3] actual output: 9 predicted output: 8.966000000000001 updated weights: [-0.669  2.744]\n","input: [4] actual output: 11 predicted output: 11.044 updated weights: [-0.671  2.744]\n","input: [5] actual output: 13 predicted output: 13.109 updated weights: [-0.676  2.743]\n","input: [1] actual output: 5 predicted output: 4.81 updated weights: [-0.674  2.745]\n","input: [2] actual output: 7 predicted output: 6.8870000000000005 updated weights: [-0.672  2.746]\n","input: [3] actual output: 9 predicted output: 8.968 updated weights: [-0.671  2.746]\n","input: [4] actual output: 11 predicted output: 11.046000000000001 updated weights: [-0.673  2.746]\n","input: [5] actual output: 13 predicted output: 13.111 updated weights: [-0.679  2.745]\n","input: [1] actual output: 5 predicted output: 4.811 updated weights: [-0.677  2.747]\n","input: [2] actual output: 7 predicted output: 6.887 updated weights: [-0.675  2.748]\n","input: [3] actual output: 9 predicted output: 8.966999999999999 updated weights: [-0.674  2.748]\n","input: [4] actual output: 11 predicted output: 11.044 updated weights: [-0.676  2.748]\n","input: [5] actual output: 13 predicted output: 13.108 updated weights: [-0.681  2.747]\n","input: [1] actual output: 5 predicted output: 4.813 updated weights: [-0.679  2.749]\n","input: [2] actual output: 7 predicted output: 6.889000000000001 updated weights: [-0.677  2.75 ]\n","input: [3] actual output: 9 predicted output: 8.969 updated weights: [-0.676  2.75 ]\n","input: [4] actual output: 11 predicted output: 11.046 updated weights: [-0.678  2.75 ]\n","input: [5] actual output: 13 predicted output: 13.11 updated weights: [-0.684  2.749]\n","input: [1] actual output: 5 predicted output: 4.814 updated weights: [-0.682  2.751]\n","input: [2] actual output: 7 predicted output: 6.888999999999999 updated weights: [-0.68   2.752]\n","input: [3] actual output: 9 predicted output: 8.968 updated weights: [-0.679  2.752]\n","input: [4] actual output: 11 predicted output: 11.043999999999997 updated weights: [-0.681  2.752]\n","input: [5] actual output: 13 predicted output: 13.106999999999996 updated weights: [-0.686  2.751]\n","input: [1] actual output: 5 predicted output: 4.816 updated weights: [-0.684  2.753]\n","input: [2] actual output: 7 predicted output: 6.891 updated weights: [-0.682  2.754]\n","input: [3] actual output: 9 predicted output: 8.97 updated weights: [-0.681  2.754]\n","input: [4] actual output: 11 predicted output: 11.046 updated weights: [-0.683  2.754]\n","input: [5] actual output: 13 predicted output: 13.109 updated weights: [-0.688  2.753]\n","input: [1] actual output: 5 predicted output: 4.8180000000000005 updated weights: [-0.686  2.755]\n","input: [2] actual output: 7 predicted output: 6.893 updated weights: [-0.684  2.756]\n","input: [3] actual output: 9 predicted output: 8.972 updated weights: [-0.683  2.756]\n","input: [4] actual output: 11 predicted output: 11.047999999999998 updated weights: [-0.685  2.756]\n","input: [5] actual output: 13 predicted output: 13.110999999999999 updated weights: [-0.691  2.755]\n","input: [1] actual output: 5 predicted output: 4.819 updated weights: [-0.689  2.757]\n","input: [2] actual output: 7 predicted output: 6.893000000000001 updated weights: [-0.687  2.758]\n","input: [3] actual output: 9 predicted output: 8.971 updated weights: [-0.686  2.758]\n","input: [4] actual output: 11 predicted output: 11.046 updated weights: [-0.688  2.758]\n","input: [5] actual output: 13 predicted output: 13.108 updated weights: [-0.693  2.757]\n","input: [1] actual output: 5 predicted output: 4.821 updated weights: [-0.691  2.759]\n","input: [2] actual output: 7 predicted output: 6.895 updated weights: [-0.689  2.76 ]\n","input: [3] actual output: 9 predicted output: 8.972999999999999 updated weights: [-0.688  2.76 ]\n","input: [4] actual output: 11 predicted output: 11.048 updated weights: [-0.69  2.76]\n","input: [5] actual output: 13 predicted output: 13.11 updated weights: [-0.695  2.759]\n","input: [1] actual output: 5 predicted output: 4.823 updated weights: [-0.693  2.761]\n","input: [2] actual output: 7 predicted output: 6.897 updated weights: [-0.691  2.762]\n","input: [3] actual output: 9 predicted output: 8.975 updated weights: [-0.69   2.762]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.692  2.762]\n","input: [5] actual output: 13 predicted output: 13.112000000000002 updated weights: [-0.698  2.761]\n","input: [1] actual output: 5 predicted output: 4.824 updated weights: [-0.696  2.763]\n","input: [2] actual output: 7 predicted output: 6.897 updated weights: [-0.694  2.764]\n","input: [3] actual output: 9 predicted output: 8.974 updated weights: [-0.693  2.764]\n","input: [4] actual output: 11 predicted output: 11.047999999999998 updated weights: [-0.695  2.764]\n","input: [5] actual output: 13 predicted output: 13.108999999999998 updated weights: [-0.7    2.763]\n","input: [1] actual output: 5 predicted output: 4.826 updated weights: [-0.698  2.765]\n","input: [2] actual output: 7 predicted output: 6.899000000000001 updated weights: [-0.696  2.766]\n","input: [3] actual output: 9 predicted output: 8.975999999999999 updated weights: [-0.695  2.766]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.697  2.766]\n","input: [5] actual output: 13 predicted output: 13.111 updated weights: [-0.703  2.765]\n","input: [1] actual output: 5 predicted output: 4.827 updated weights: [-0.701  2.767]\n","input: [2] actual output: 7 predicted output: 6.898999999999999 updated weights: [-0.699  2.768]\n","input: [3] actual output: 9 predicted output: 8.974999999999998 updated weights: [-0.698  2.768]\n","input: [4] actual output: 11 predicted output: 11.047999999999998 updated weights: [-0.7    2.768]\n","input: [5] actual output: 13 predicted output: 13.108 updated weights: [-0.705  2.767]\n","input: [1] actual output: 5 predicted output: 4.829 updated weights: [-0.703  2.769]\n","input: [2] actual output: 7 predicted output: 6.901000000000001 updated weights: [-0.701  2.77 ]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.7   2.77]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.702  2.77 ]\n","input: [5] actual output: 13 predicted output: 13.11 updated weights: [-0.707  2.769]\n","input: [1] actual output: 5 predicted output: 4.831 updated weights: [-0.705  2.771]\n","input: [2] actual output: 7 predicted output: 6.903 updated weights: [-0.703  2.772]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.702  2.772]\n","input: [4] actual output: 11 predicted output: 11.052 updated weights: [-0.704  2.771]\n","input: [5] actual output: 13 predicted output: 13.106000000000002 updated weights: [-0.709  2.77 ]\n","input: [1] actual output: 5 predicted output: 4.8309999999999995 updated weights: [-0.707  2.772]\n","input: [2] actual output: 7 predicted output: 6.901999999999999 updated weights: [-0.705  2.773]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.704  2.773]\n","input: [4] actual output: 11 predicted output: 11.049 updated weights: [-0.706  2.773]\n","input: [5] actual output: 13 predicted output: 13.108 updated weights: [-0.711  2.772]\n","input: [1] actual output: 5 predicted output: 4.833 updated weights: [-0.709  2.774]\n","input: [2] actual output: 7 predicted output: 6.904 updated weights: [-0.707  2.775]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.706  2.775]\n","input: [4] actual output: 11 predicted output: 11.051 updated weights: [-0.708  2.774]\n","input: [5] actual output: 13 predicted output: 13.104000000000003 updated weights: [-0.713  2.773]\n","input: [1] actual output: 5 predicted output: 4.833 updated weights: [-0.711  2.775]\n","input: [2] actual output: 7 predicted output: 6.9030000000000005 updated weights: [-0.709  2.776]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.708  2.776]\n","input: [4] actual output: 11 predicted output: 11.047999999999998 updated weights: [-0.71   2.776]\n","input: [5] actual output: 13 predicted output: 13.105999999999998 updated weights: [-0.715  2.775]\n","input: [1] actual output: 5 predicted output: 4.835 updated weights: [-0.713  2.777]\n","input: [2] actual output: 7 predicted output: 6.905 updated weights: [-0.711  2.778]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.71   2.778]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.712  2.778]\n","input: [5] actual output: 13 predicted output: 13.108000000000002 updated weights: [-0.717  2.777]\n","input: [1] actual output: 5 predicted output: 4.837 updated weights: [-0.715  2.779]\n","input: [2] actual output: 7 predicted output: 6.907 updated weights: [-0.713  2.78 ]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.712  2.78 ]\n","input: [4] actual output: 11 predicted output: 11.051999999999998 updated weights: [-0.714  2.779]\n","input: [5] actual output: 13 predicted output: 13.104 updated weights: [-0.719  2.778]\n","input: [1] actual output: 5 predicted output: 4.837 updated weights: [-0.717  2.78 ]\n","input: [2] actual output: 7 predicted output: 6.905999999999999 updated weights: [-0.715  2.781]\n","input: [3] actual output: 9 predicted output: 8.979000000000001 updated weights: [-0.714  2.781]\n","input: [4] actual output: 11 predicted output: 11.049000000000001 updated weights: [-0.716  2.781]\n","input: [5] actual output: 13 predicted output: 13.106000000000002 updated weights: [-0.721  2.78 ]\n","input: [1] actual output: 5 predicted output: 4.8389999999999995 updated weights: [-0.719  2.782]\n","input: [2] actual output: 7 predicted output: 6.908 updated weights: [-0.717  2.783]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.716  2.783]\n","input: [4] actual output: 11 predicted output: 11.051 updated weights: [-0.718  2.782]\n","input: [5] actual output: 13 predicted output: 13.102 updated weights: [-0.723  2.781]\n","input: [1] actual output: 5 predicted output: 4.839 updated weights: [-0.721  2.783]\n","input: [2] actual output: 7 predicted output: 6.907 updated weights: [-0.719  2.784]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.718  2.784]\n","input: [4] actual output: 11 predicted output: 11.047999999999998 updated weights: [-0.72   2.784]\n","input: [5] actual output: 13 predicted output: 13.104 updated weights: [-0.725  2.783]\n","input: [1] actual output: 5 predicted output: 4.840999999999999 updated weights: [-0.723  2.785]\n","input: [2] actual output: 7 predicted output: 6.909000000000001 updated weights: [-0.721  2.786]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.72   2.786]\n","input: [4] actual output: 11 predicted output: 11.049999999999999 updated weights: [-0.722  2.786]\n","input: [5] actual output: 13 predicted output: 13.106 updated weights: [-0.727  2.785]\n","input: [1] actual output: 5 predicted output: 4.843 updated weights: [-0.725  2.787]\n","input: [2] actual output: 7 predicted output: 6.911 updated weights: [-0.723  2.788]\n","input: [3] actual output: 9 predicted output: 8.982999999999999 updated weights: [-0.722  2.788]\n","input: [4] actual output: 11 predicted output: 11.052 updated weights: [-0.724  2.787]\n","input: [5] actual output: 13 predicted output: 13.101999999999997 updated weights: [-0.729  2.786]\n","input: [1] actual output: 5 predicted output: 4.843 updated weights: [-0.727  2.788]\n","input: [2] actual output: 7 predicted output: 6.91 updated weights: [-0.725  2.789]\n","input: [3] actual output: 9 predicted output: 8.981000000000002 updated weights: [-0.724  2.789]\n","input: [4] actual output: 11 predicted output: 11.049000000000001 updated weights: [-0.726  2.789]\n","input: [5] actual output: 13 predicted output: 13.104000000000001 updated weights: [-0.731  2.788]\n","input: [1] actual output: 5 predicted output: 4.845 updated weights: [-0.729  2.79 ]\n","input: [2] actual output: 7 predicted output: 6.912 updated weights: [-0.727  2.791]\n","input: [3] actual output: 9 predicted output: 8.982999999999999 updated weights: [-0.726  2.791]\n","input: [4] actual output: 11 predicted output: 11.051 updated weights: [-0.728  2.79 ]\n","input: [5] actual output: 13 predicted output: 13.099999999999998 updated weights: [-0.733  2.789]\n","input: [1] actual output: 5 predicted output: 4.845000000000001 updated weights: [-0.731  2.791]\n","input: [2] actual output: 7 predicted output: 6.911 updated weights: [-0.729  2.792]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.728  2.792]\n","input: [4] actual output: 11 predicted output: 11.048 updated weights: [-0.73   2.792]\n","input: [5] actual output: 13 predicted output: 13.101999999999999 updated weights: [-0.735  2.791]\n","input: [1] actual output: 5 predicted output: 4.8469999999999995 updated weights: [-0.733  2.793]\n","input: [2] actual output: 7 predicted output: 6.913 updated weights: [-0.731  2.794]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.73   2.794]\n","input: [4] actual output: 11 predicted output: 11.05 updated weights: [-0.732  2.794]\n","input: [5] actual output: 13 predicted output: 13.104000000000001 updated weights: [-0.737  2.793]\n","input: [1] actual output: 5 predicted output: 4.849 updated weights: [-0.735  2.795]\n","input: [2] actual output: 7 predicted output: 6.915 updated weights: [-0.733  2.796]\n","input: [3] actual output: 9 predicted output: 8.985 updated weights: [-0.733  2.796]\n","input: [4] actual output: 11 predicted output: 11.047999999999998 updated weights: [-0.735  2.796]\n","input: [5] actual output: 13 predicted output: 13.100999999999999 updated weights: [-0.74   2.795]\n","input: [1] actual output: 5 predicted output: 4.85 updated weights: [-0.738  2.796]\n","input: [2] actual output: 7 predicted output: 6.911999999999999 updated weights: [-0.736  2.797]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.735  2.797]\n","input: [4] actual output: 11 predicted output: 11.045000000000002 updated weights: [-0.737  2.797]\n","input: [5] actual output: 13 predicted output: 13.097000000000001 updated weights: [-0.742  2.796]\n","input: [1] actual output: 5 predicted output: 4.85 updated weights: [-0.74   2.798]\n","input: [2] actual output: 7 predicted output: 6.914 updated weights: [-0.738  2.799]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.737  2.799]\n","input: [4] actual output: 11 predicted output: 11.046999999999999 updated weights: [-0.739  2.799]\n","input: [5] actual output: 13 predicted output: 13.098999999999998 updated weights: [-0.744  2.798]\n","input: [1] actual output: 5 predicted output: 4.852 updated weights: [-0.743  2.799]\n","input: [2] actual output: 7 predicted output: 6.911 updated weights: [-0.741  2.8  ]\n","input: [3] actual output: 9 predicted output: 8.976999999999999 updated weights: [-0.74  2.8 ]\n","input: [4] actual output: 11 predicted output: 11.04 updated weights: [-0.742  2.8  ]\n","input: [5] actual output: 13 predicted output: 13.09 updated weights: [-0.746  2.799]\n","input: [1] actual output: 5 predicted output: 4.852 updated weights: [-0.745  2.8  ]\n","input: [2] actual output: 7 predicted output: 6.909999999999999 updated weights: [-0.743  2.801]\n","input: [3] actual output: 9 predicted output: 8.975000000000001 updated weights: [-0.742  2.801]\n","input: [4] actual output: 11 predicted output: 11.037 updated weights: [-0.743  2.801]\n","input: [5] actual output: 13 predicted output: 13.091000000000001 updated weights: [-0.748  2.8  ]\n","input: [1] actual output: 5 predicted output: 4.851999999999999 updated weights: [-0.747  2.801]\n","input: [2] actual output: 7 predicted output: 6.909000000000001 updated weights: [-0.745  2.802]\n","input: [3] actual output: 9 predicted output: 8.973 updated weights: [-0.744  2.802]\n","input: [4] actual output: 11 predicted output: 11.033999999999999 updated weights: [-0.745  2.802]\n","input: [5] actual output: 13 predicted output: 13.087 updated weights: [-0.749  2.801]\n","input: [1] actual output: 5 predicted output: 4.853 updated weights: [-0.748  2.802]\n","input: [2] actual output: 7 predicted output: 6.91 updated weights: [-0.746  2.803]\n","input: [3] actual output: 9 predicted output: 8.974 updated weights: [-0.745  2.803]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.746  2.803]\n","input: [5] actual output: 13 predicted output: 13.088000000000001 updated weights: [-0.75   2.802]\n","input: [1] actual output: 5 predicted output: 4.854 updated weights: [-0.749  2.803]\n","input: [2] actual output: 7 predicted output: 6.911 updated weights: [-0.747  2.804]\n","input: [3] actual output: 9 predicted output: 8.975 updated weights: [-0.746  2.804]\n","input: [4] actual output: 11 predicted output: 11.036 updated weights: [-0.747  2.804]\n","input: [5] actual output: 13 predicted output: 13.089 updated weights: [-0.751  2.803]\n","input: [1] actual output: 5 predicted output: 4.855 updated weights: [-0.75   2.804]\n","input: [2] actual output: 7 predicted output: 6.911999999999999 updated weights: [-0.748  2.805]\n","input: [3] actual output: 9 predicted output: 8.976 updated weights: [-0.747  2.805]\n","input: [4] actual output: 11 predicted output: 11.037 updated weights: [-0.748  2.805]\n","input: [5] actual output: 13 predicted output: 13.09 updated weights: [-0.752  2.804]\n","input: [1] actual output: 5 predicted output: 4.856 updated weights: [-0.751  2.805]\n","input: [2] actual output: 7 predicted output: 6.913 updated weights: [-0.749  2.806]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.748  2.806]\n","input: [4] actual output: 11 predicted output: 11.038 updated weights: [-0.75   2.806]\n","input: [5] actual output: 13 predicted output: 13.086000000000002 updated weights: [-0.754  2.805]\n","input: [1] actual output: 5 predicted output: 4.856 updated weights: [-0.753  2.806]\n","input: [2] actual output: 7 predicted output: 6.912 updated weights: [-0.751  2.807]\n","input: [3] actual output: 9 predicted output: 8.975 updated weights: [-0.75   2.807]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.751  2.807]\n","input: [5] actual output: 13 predicted output: 13.087000000000002 updated weights: [-0.755  2.806]\n","input: [1] actual output: 5 predicted output: 4.857 updated weights: [-0.754  2.807]\n","input: [2] actual output: 7 predicted output: 6.913 updated weights: [-0.752  2.808]\n","input: [3] actual output: 9 predicted output: 8.975999999999999 updated weights: [-0.751  2.808]\n","input: [4] actual output: 11 predicted output: 11.036 updated weights: [-0.752  2.808]\n","input: [5] actual output: 13 predicted output: 13.088 updated weights: [-0.756  2.807]\n","input: [1] actual output: 5 predicted output: 4.8580000000000005 updated weights: [-0.755  2.808]\n","input: [2] actual output: 7 predicted output: 6.914 updated weights: [-0.753  2.809]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.752  2.809]\n","input: [4] actual output: 11 predicted output: 11.037000000000003 updated weights: [-0.753  2.809]\n","input: [5] actual output: 13 predicted output: 13.089000000000002 updated weights: [-0.757  2.808]\n","input: [1] actual output: 5 predicted output: 4.859 updated weights: [-0.756  2.809]\n","input: [2] actual output: 7 predicted output: 6.915 updated weights: [-0.754  2.81 ]\n","input: [3] actual output: 9 predicted output: 8.978 updated weights: [-0.753  2.81 ]\n","input: [4] actual output: 11 predicted output: 11.038 updated weights: [-0.755  2.81 ]\n","input: [5] actual output: 13 predicted output: 13.085 updated weights: [-0.759  2.809]\n","input: [1] actual output: 5 predicted output: 4.859 updated weights: [-0.758  2.81 ]\n","input: [2] actual output: 7 predicted output: 6.914 updated weights: [-0.756  2.811]\n","input: [3] actual output: 9 predicted output: 8.975999999999999 updated weights: [-0.755  2.811]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.756  2.811]\n","input: [5] actual output: 13 predicted output: 13.085999999999999 updated weights: [-0.76  2.81]\n","input: [1] actual output: 5 predicted output: 4.859999999999999 updated weights: [-0.759  2.811]\n","input: [2] actual output: 7 predicted output: 6.915 updated weights: [-0.757  2.812]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.756  2.812]\n","input: [4] actual output: 11 predicted output: 11.036 updated weights: [-0.757  2.812]\n","input: [5] actual output: 13 predicted output: 13.086999999999998 updated weights: [-0.761  2.811]\n","input: [1] actual output: 5 predicted output: 4.861 updated weights: [-0.76   2.812]\n","input: [2] actual output: 7 predicted output: 6.915999999999999 updated weights: [-0.758  2.813]\n","input: [3] actual output: 9 predicted output: 8.978 updated weights: [-0.757  2.813]\n","input: [4] actual output: 11 predicted output: 11.037 updated weights: [-0.758  2.813]\n","input: [5] actual output: 13 predicted output: 13.088000000000003 updated weights: [-0.762  2.812]\n","input: [1] actual output: 5 predicted output: 4.862 updated weights: [-0.761  2.813]\n","input: [2] actual output: 7 predicted output: 6.917 updated weights: [-0.759  2.814]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.758  2.814]\n","input: [4] actual output: 11 predicted output: 11.038 updated weights: [-0.76   2.814]\n","input: [5] actual output: 13 predicted output: 13.084 updated weights: [-0.764  2.813]\n","input: [1] actual output: 5 predicted output: 4.862 updated weights: [-0.763  2.814]\n","input: [2] actual output: 7 predicted output: 6.916 updated weights: [-0.761  2.815]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.76   2.815]\n","input: [4] actual output: 11 predicted output: 11.034999999999998 updated weights: [-0.761  2.815]\n","input: [5] actual output: 13 predicted output: 13.084999999999999 updated weights: [-0.765  2.814]\n","input: [1] actual output: 5 predicted output: 4.8629999999999995 updated weights: [-0.764  2.815]\n","input: [2] actual output: 7 predicted output: 6.917 updated weights: [-0.762  2.816]\n","input: [3] actual output: 9 predicted output: 8.978000000000002 updated weights: [-0.761  2.816]\n","input: [4] actual output: 11 predicted output: 11.035999999999998 updated weights: [-0.762  2.816]\n","input: [5] actual output: 13 predicted output: 13.085999999999999 updated weights: [-0.766  2.815]\n","input: [1] actual output: 5 predicted output: 4.864 updated weights: [-0.765  2.816]\n","input: [2] actual output: 7 predicted output: 6.917999999999999 updated weights: [-0.763  2.817]\n","input: [3] actual output: 9 predicted output: 8.979000000000001 updated weights: [-0.762  2.817]\n","input: [4] actual output: 11 predicted output: 11.037 updated weights: [-0.763  2.817]\n","input: [5] actual output: 13 predicted output: 13.087000000000002 updated weights: [-0.767  2.816]\n","input: [1] actual output: 5 predicted output: 4.865 updated weights: [-0.766  2.817]\n","input: [2] actual output: 7 predicted output: 6.9190000000000005 updated weights: [-0.764  2.818]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.763  2.818]\n","input: [4] actual output: 11 predicted output: 11.038 updated weights: [-0.765  2.818]\n","input: [5] actual output: 13 predicted output: 13.083 updated weights: [-0.769  2.817]\n","input: [1] actual output: 5 predicted output: 4.865 updated weights: [-0.768  2.818]\n","input: [2] actual output: 7 predicted output: 6.917999999999999 updated weights: [-0.766  2.819]\n","input: [3] actual output: 9 predicted output: 8.978000000000002 updated weights: [-0.765  2.819]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.766  2.819]\n","input: [5] actual output: 13 predicted output: 13.084 updated weights: [-0.77   2.818]\n","input: [1] actual output: 5 predicted output: 4.866 updated weights: [-0.769  2.819]\n","input: [2] actual output: 7 predicted output: 6.919 updated weights: [-0.767  2.82 ]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.766  2.82 ]\n","input: [4] actual output: 11 predicted output: 11.036 updated weights: [-0.767  2.82 ]\n","input: [5] actual output: 13 predicted output: 13.085 updated weights: [-0.771  2.819]\n","input: [1] actual output: 5 predicted output: 4.867 updated weights: [-0.77  2.82]\n","input: [2] actual output: 7 predicted output: 6.92 updated weights: [-0.768  2.821]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.767  2.821]\n","input: [4] actual output: 11 predicted output: 11.037 updated weights: [-0.768  2.821]\n","input: [5] actual output: 13 predicted output: 13.086 updated weights: [-0.772  2.82 ]\n","input: [1] actual output: 5 predicted output: 4.868 updated weights: [-0.771  2.821]\n","input: [2] actual output: 7 predicted output: 6.921000000000001 updated weights: [-0.769  2.822]\n","input: [3] actual output: 9 predicted output: 8.981000000000002 updated weights: [-0.768  2.822]\n","input: [4] actual output: 11 predicted output: 11.038 updated weights: [-0.77   2.822]\n","input: [5] actual output: 13 predicted output: 13.082 updated weights: [-0.774  2.821]\n","input: [1] actual output: 5 predicted output: 4.868 updated weights: [-0.773  2.822]\n","input: [2] actual output: 7 predicted output: 6.92 updated weights: [-0.771  2.823]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.77   2.823]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.771  2.823]\n","input: [5] actual output: 13 predicted output: 13.083 updated weights: [-0.775  2.822]\n","input: [1] actual output: 5 predicted output: 4.869 updated weights: [-0.774  2.823]\n","input: [2] actual output: 7 predicted output: 6.920999999999999 updated weights: [-0.772  2.824]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.771  2.824]\n","input: [4] actual output: 11 predicted output: 11.036 updated weights: [-0.772  2.824]\n","input: [5] actual output: 13 predicted output: 13.083999999999998 updated weights: [-0.776  2.823]\n","input: [1] actual output: 5 predicted output: 4.869999999999999 updated weights: [-0.775  2.824]\n","input: [2] actual output: 7 predicted output: 6.922 updated weights: [-0.773  2.825]\n","input: [3] actual output: 9 predicted output: 8.981000000000002 updated weights: [-0.772  2.825]\n","input: [4] actual output: 11 predicted output: 11.036999999999999 updated weights: [-0.773  2.825]\n","input: [5] actual output: 13 predicted output: 13.085 updated weights: [-0.777  2.824]\n","input: [1] actual output: 5 predicted output: 4.8709999999999996 updated weights: [-0.776  2.825]\n","input: [2] actual output: 7 predicted output: 6.923000000000001 updated weights: [-0.774  2.826]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.773  2.826]\n","input: [4] actual output: 11 predicted output: 11.038 updated weights: [-0.775  2.826]\n","input: [5] actual output: 13 predicted output: 13.081000000000001 updated weights: [-0.779  2.825]\n","input: [1] actual output: 5 predicted output: 4.871 updated weights: [-0.778  2.826]\n","input: [2] actual output: 7 predicted output: 6.922000000000001 updated weights: [-0.776  2.827]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.775  2.827]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.776  2.827]\n","input: [5] actual output: 13 predicted output: 13.081999999999999 updated weights: [-0.78   2.826]\n","input: [1] actual output: 5 predicted output: 4.872 updated weights: [-0.779  2.827]\n","input: [2] actual output: 7 predicted output: 6.923 updated weights: [-0.777  2.828]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.776  2.828]\n","input: [4] actual output: 11 predicted output: 11.035999999999998 updated weights: [-0.777  2.828]\n","input: [5] actual output: 13 predicted output: 13.082999999999998 updated weights: [-0.781  2.827]\n","input: [1] actual output: 5 predicted output: 4.872999999999999 updated weights: [-0.78   2.828]\n","input: [2] actual output: 7 predicted output: 6.9239999999999995 updated weights: [-0.778  2.829]\n","input: [3] actual output: 9 predicted output: 8.982000000000001 updated weights: [-0.777  2.829]\n","input: [4] actual output: 11 predicted output: 11.037 updated weights: [-0.778  2.829]\n","input: [5] actual output: 13 predicted output: 13.084000000000001 updated weights: [-0.782  2.828]\n","input: [1] actual output: 5 predicted output: 4.874 updated weights: [-0.781  2.829]\n","input: [2] actual output: 7 predicted output: 6.925000000000001 updated weights: [-0.78  2.83]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.779  2.83 ]\n","input: [4] actual output: 11 predicted output: 11.034 updated weights: [-0.78  2.83]\n","input: [5] actual output: 13 predicted output: 13.08 updated weights: [-0.784  2.829]\n","input: [1] actual output: 5 predicted output: 4.8740000000000006 updated weights: [-0.783  2.83 ]\n","input: [2] actual output: 7 predicted output: 6.924 updated weights: [-0.781  2.831]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.78   2.831]\n","input: [4] actual output: 11 predicted output: 11.035 updated weights: [-0.781  2.831]\n","input: [5] actual output: 13 predicted output: 13.081 updated weights: [-0.785  2.83 ]\n","input: [1] actual output: 5 predicted output: 4.875 updated weights: [-0.784  2.831]\n","input: [2] actual output: 7 predicted output: 6.924999999999999 updated weights: [-0.782  2.832]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.781  2.832]\n","input: [4] actual output: 11 predicted output: 11.035999999999998 updated weights: [-0.782  2.832]\n","input: [5] actual output: 13 predicted output: 13.082 updated weights: [-0.786  2.831]\n","input: [1] actual output: 5 predicted output: 4.8759999999999994 updated weights: [-0.785  2.832]\n","input: [2] actual output: 7 predicted output: 6.925999999999999 updated weights: [-0.784  2.833]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.783  2.833]\n","input: [4] actual output: 11 predicted output: 11.033000000000001 updated weights: [-0.784  2.833]\n","input: [5] actual output: 13 predicted output: 13.078000000000001 updated weights: [-0.788  2.832]\n","input: [1] actual output: 5 predicted output: 4.8759999999999994 updated weights: [-0.787  2.833]\n","input: [2] actual output: 7 predicted output: 6.925000000000001 updated weights: [-0.786  2.834]\n","input: [3] actual output: 9 predicted output: 8.978 updated weights: [-0.785  2.834]\n","input: [4] actual output: 11 predicted output: 11.03 updated weights: [-0.786  2.834]\n","input: [5] actual output: 13 predicted output: 13.074 updated weights: [-0.79   2.833]\n","input: [1] actual output: 5 predicted output: 4.876 updated weights: [-0.789  2.834]\n","input: [2] actual output: 7 predicted output: 6.9239999999999995 updated weights: [-0.787  2.835]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.786  2.835]\n","input: [4] actual output: 11 predicted output: 11.030999999999999 updated weights: [-0.787  2.835]\n","input: [5] actual output: 13 predicted output: 13.075 updated weights: [-0.791  2.834]\n","input: [1] actual output: 5 predicted output: 4.877000000000001 updated weights: [-0.79   2.835]\n","input: [2] actual output: 7 predicted output: 6.925 updated weights: [-0.788  2.836]\n","input: [3] actual output: 9 predicted output: 8.979999999999999 updated weights: [-0.787  2.836]\n","input: [4] actual output: 11 predicted output: 11.032 updated weights: [-0.788  2.836]\n","input: [5] actual output: 13 predicted output: 13.075999999999999 updated weights: [-0.792  2.835]\n","input: [1] actual output: 5 predicted output: 4.878 updated weights: [-0.791  2.836]\n","input: [2] actual output: 7 predicted output: 6.926 updated weights: [-0.79   2.837]\n","input: [3] actual output: 9 predicted output: 8.978000000000002 updated weights: [-0.789  2.837]\n","input: [4] actual output: 11 predicted output: 11.029 updated weights: [-0.79   2.837]\n","input: [5] actual output: 13 predicted output: 13.072 updated weights: [-0.794  2.836]\n","input: [1] actual output: 5 predicted output: 4.878 updated weights: [-0.793  2.837]\n","input: [2] actual output: 7 predicted output: 6.925000000000001 updated weights: [-0.792  2.838]\n","input: [3] actual output: 9 predicted output: 8.975999999999999 updated weights: [-0.791  2.838]\n","input: [4] actual output: 11 predicted output: 11.026 updated weights: [-0.792  2.838]\n","input: [5] actual output: 13 predicted output: 13.068000000000001 updated weights: [-0.795  2.837]\n","input: [1] actual output: 5 predicted output: 4.8790000000000004 updated weights: [-0.794  2.838]\n","input: [2] actual output: 7 predicted output: 6.926 updated weights: [-0.793  2.839]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.792  2.839]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.793  2.839]\n","input: [5] actual output: 13 predicted output: 13.069 updated weights: [-0.796  2.838]\n","input: [1] actual output: 5 predicted output: 4.88 updated weights: [-0.795  2.839]\n","input: [2] actual output: 7 predicted output: 6.927 updated weights: [-0.794  2.84 ]\n","input: [3] actual output: 9 predicted output: 8.978 updated weights: [-0.793  2.84 ]\n","input: [4] actual output: 11 predicted output: 11.027999999999999 updated weights: [-0.794  2.84 ]\n","input: [5] actual output: 13 predicted output: 13.069999999999999 updated weights: [-0.798  2.839]\n","input: [1] actual output: 5 predicted output: 4.88 updated weights: [-0.797  2.84 ]\n","input: [2] actual output: 7 predicted output: 6.925999999999999 updated weights: [-0.796  2.841]\n","input: [3] actual output: 9 predicted output: 8.975999999999999 updated weights: [-0.795  2.841]\n","input: [4] actual output: 11 predicted output: 11.025000000000002 updated weights: [-0.796  2.841]\n","input: [5] actual output: 13 predicted output: 13.066000000000003 updated weights: [-0.799  2.84 ]\n","input: [1] actual output: 5 predicted output: 4.881 updated weights: [-0.798  2.841]\n","input: [2] actual output: 7 predicted output: 6.9270000000000005 updated weights: [-0.797  2.842]\n","input: [3] actual output: 9 predicted output: 8.977 updated weights: [-0.796  2.842]\n","input: [4] actual output: 11 predicted output: 11.026000000000002 updated weights: [-0.797  2.842]\n","input: [5] actual output: 13 predicted output: 13.067000000000002 updated weights: [-0.8    2.841]\n","input: [1] actual output: 5 predicted output: 4.882000000000001 updated weights: [-0.799  2.842]\n","input: [2] actual output: 7 predicted output: 6.928000000000001 updated weights: [-0.798  2.843]\n","input: [3] actual output: 9 predicted output: 8.978 updated weights: [-0.797  2.843]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.798  2.843]\n","input: [5] actual output: 13 predicted output: 13.068 updated weights: [-0.801  2.842]\n","input: [1] actual output: 5 predicted output: 4.883 updated weights: [-0.8    2.843]\n","input: [2] actual output: 7 predicted output: 6.929 updated weights: [-0.799  2.844]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.798  2.844]\n","input: [4] actual output: 11 predicted output: 11.027999999999999 updated weights: [-0.799  2.844]\n","input: [5] actual output: 13 predicted output: 13.068999999999997 updated weights: [-0.802  2.843]\n","input: [1] actual output: 5 predicted output: 4.884 updated weights: [-0.801  2.844]\n","input: [2] actual output: 7 predicted output: 6.93 updated weights: [-0.8    2.845]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.799  2.845]\n","input: [4] actual output: 11 predicted output: 11.029000000000002 updated weights: [-0.8    2.845]\n","input: [5] actual output: 13 predicted output: 13.070000000000002 updated weights: [-0.804  2.844]\n","input: [1] actual output: 5 predicted output: 4.884 updated weights: [-0.803  2.845]\n","input: [2] actual output: 7 predicted output: 6.929 updated weights: [-0.802  2.846]\n","input: [3] actual output: 9 predicted output: 8.978 updated weights: [-0.801  2.846]\n","input: [4] actual output: 11 predicted output: 11.026 updated weights: [-0.802  2.846]\n","input: [5] actual output: 13 predicted output: 13.066 updated weights: [-0.805  2.845]\n","input: [1] actual output: 5 predicted output: 4.885 updated weights: [-0.804  2.846]\n","input: [2] actual output: 7 predicted output: 6.93 updated weights: [-0.803  2.847]\n","input: [3] actual output: 9 predicted output: 8.979 updated weights: [-0.802  2.847]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.803  2.847]\n","input: [5] actual output: 13 predicted output: 13.066999999999998 updated weights: [-0.806  2.846]\n","input: [1] actual output: 5 predicted output: 4.886 updated weights: [-0.805  2.847]\n","input: [2] actual output: 7 predicted output: 6.930999999999999 updated weights: [-0.804  2.848]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.803  2.848]\n","input: [4] actual output: 11 predicted output: 11.027999999999999 updated weights: [-0.804  2.848]\n","input: [5] actual output: 13 predicted output: 13.067999999999998 updated weights: [-0.807  2.847]\n","input: [1] actual output: 5 predicted output: 4.8870000000000005 updated weights: [-0.806  2.848]\n","input: [2] actual output: 7 predicted output: 6.9319999999999995 updated weights: [-0.805  2.849]\n","input: [3] actual output: 9 predicted output: 8.981000000000002 updated weights: [-0.804  2.849]\n","input: [4] actual output: 11 predicted output: 11.029 updated weights: [-0.805  2.849]\n","input: [5] actual output: 13 predicted output: 13.069 updated weights: [-0.808  2.848]\n","input: [1] actual output: 5 predicted output: 4.888 updated weights: [-0.807  2.849]\n","input: [2] actual output: 7 predicted output: 6.933000000000001 updated weights: [-0.806  2.85 ]\n","input: [3] actual output: 9 predicted output: 8.982000000000001 updated weights: [-0.805  2.85 ]\n","input: [4] actual output: 11 predicted output: 11.03 updated weights: [-0.806  2.85 ]\n","input: [5] actual output: 13 predicted output: 13.069999999999999 updated weights: [-0.81   2.849]\n","input: [1] actual output: 5 predicted output: 4.888 updated weights: [-0.809  2.85 ]\n","input: [2] actual output: 7 predicted output: 6.932 updated weights: [-0.808  2.851]\n","input: [3] actual output: 9 predicted output: 8.98 updated weights: [-0.807  2.851]\n","input: [4] actual output: 11 predicted output: 11.027000000000001 updated weights: [-0.808  2.851]\n","input: [5] actual output: 13 predicted output: 13.065999999999999 updated weights: [-0.811  2.85 ]\n","input: [1] actual output: 5 predicted output: 4.889 updated weights: [-0.81   2.851]\n","input: [2] actual output: 7 predicted output: 6.933 updated weights: [-0.809  2.852]\n","input: [3] actual output: 9 predicted output: 8.981 updated weights: [-0.808  2.852]\n","input: [4] actual output: 11 predicted output: 11.027999999999999 updated weights: [-0.809  2.852]\n","input: [5] actual output: 13 predicted output: 13.067 updated weights: [-0.812  2.851]\n","input: [1] actual output: 5 predicted output: 4.89 updated weights: [-0.811  2.852]\n","input: [2] actual output: 7 predicted output: 6.933999999999999 updated weights: [-0.81   2.853]\n","input: [3] actual output: 9 predicted output: 8.982000000000001 updated weights: [-0.809  2.853]\n","input: [4] actual output: 11 predicted output: 11.029 updated weights: [-0.81   2.853]\n","input: [5] actual output: 13 predicted output: 13.068 updated weights: [-0.813  2.852]\n","input: [1] actual output: 5 predicted output: 4.891 updated weights: [-0.812  2.853]\n","input: [2] actual output: 7 predicted output: 6.9350000000000005 updated weights: [-0.811  2.854]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.81   2.854]\n","input: [4] actual output: 11 predicted output: 11.030000000000001 updated weights: [-0.811  2.854]\n","input: [5] actual output: 13 predicted output: 13.068999999999999 updated weights: [-0.814  2.853]\n","input: [1] actual output: 5 predicted output: 4.892 updated weights: [-0.813  2.854]\n","input: [2] actual output: 7 predicted output: 6.936000000000001 updated weights: [-0.812  2.855]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.812  2.855]\n","input: [4] actual output: 11 predicted output: 11.027000000000001 updated weights: [-0.813  2.855]\n","input: [5] actual output: 13 predicted output: 13.065000000000001 updated weights: [-0.816  2.854]\n","input: [1] actual output: 5 predicted output: 4.892 updated weights: [-0.815  2.855]\n","input: [2] actual output: 7 predicted output: 6.9350000000000005 updated weights: [-0.814  2.856]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.813  2.856]\n","input: [4] actual output: 11 predicted output: 11.028 updated weights: [-0.814  2.856]\n","input: [5] actual output: 13 predicted output: 13.066 updated weights: [-0.817  2.855]\n","input: [1] actual output: 5 predicted output: 4.893000000000001 updated weights: [-0.816  2.856]\n","input: [2] actual output: 7 predicted output: 6.936 updated weights: [-0.815  2.857]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.814  2.857]\n","input: [4] actual output: 11 predicted output: 11.029 updated weights: [-0.815  2.857]\n","input: [5] actual output: 13 predicted output: 13.067 updated weights: [-0.818  2.856]\n","input: [1] actual output: 5 predicted output: 4.894 updated weights: [-0.817  2.857]\n","input: [2] actual output: 7 predicted output: 6.937 updated weights: [-0.816  2.858]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.816  2.858]\n","input: [4] actual output: 11 predicted output: 11.026000000000002 updated weights: [-0.817  2.858]\n","input: [5] actual output: 13 predicted output: 13.063000000000002 updated weights: [-0.82   2.857]\n","input: [1] actual output: 5 predicted output: 4.894 updated weights: [-0.819  2.858]\n","input: [2] actual output: 7 predicted output: 6.936 updated weights: [-0.818  2.859]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.817  2.859]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.818  2.859]\n","input: [5] actual output: 13 predicted output: 13.064 updated weights: [-0.821  2.858]\n","input: [1] actual output: 5 predicted output: 4.895 updated weights: [-0.82   2.859]\n","input: [2] actual output: 7 predicted output: 6.937 updated weights: [-0.819  2.86 ]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.818  2.86 ]\n","input: [4] actual output: 11 predicted output: 11.027999999999999 updated weights: [-0.819  2.86 ]\n","input: [5] actual output: 13 predicted output: 13.064999999999998 updated weights: [-0.822  2.859]\n","input: [1] actual output: 5 predicted output: 4.896 updated weights: [-0.821  2.86 ]\n","input: [2] actual output: 7 predicted output: 6.937999999999999 updated weights: [-0.82   2.861]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.82   2.861]\n","input: [4] actual output: 11 predicted output: 11.025000000000002 updated weights: [-0.821  2.861]\n","input: [5] actual output: 13 predicted output: 13.061000000000003 updated weights: [-0.824  2.86 ]\n","input: [1] actual output: 5 predicted output: 4.896 updated weights: [-0.823  2.861]\n","input: [2] actual output: 7 predicted output: 6.937000000000001 updated weights: [-0.822  2.862]\n","input: [3] actual output: 9 predicted output: 8.982000000000001 updated weights: [-0.821  2.862]\n","input: [4] actual output: 11 predicted output: 11.026000000000002 updated weights: [-0.822  2.862]\n","input: [5] actual output: 13 predicted output: 13.062000000000001 updated weights: [-0.825  2.861]\n","input: [1] actual output: 5 predicted output: 4.897 updated weights: [-0.824  2.862]\n","input: [2] actual output: 7 predicted output: 6.938000000000001 updated weights: [-0.823  2.863]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.822  2.863]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.823  2.863]\n","input: [5] actual output: 13 predicted output: 13.062999999999999 updated weights: [-0.826  2.862]\n","input: [1] actual output: 5 predicted output: 4.898 updated weights: [-0.825  2.863]\n","input: [2] actual output: 7 predicted output: 6.939 updated weights: [-0.824  2.864]\n","input: [3] actual output: 9 predicted output: 8.983999999999998 updated weights: [-0.824  2.864]\n","input: [4] actual output: 11 predicted output: 11.024000000000001 updated weights: [-0.825  2.864]\n","input: [5] actual output: 13 predicted output: 13.059000000000001 updated weights: [-0.828  2.863]\n","input: [1] actual output: 5 predicted output: 4.898 updated weights: [-0.827  2.864]\n","input: [2] actual output: 7 predicted output: 6.938 updated weights: [-0.826  2.865]\n","input: [3] actual output: 9 predicted output: 8.982000000000001 updated weights: [-0.825  2.865]\n","input: [4] actual output: 11 predicted output: 11.025 updated weights: [-0.826  2.865]\n","input: [5] actual output: 13 predicted output: 13.06 updated weights: [-0.829  2.864]\n","input: [1] actual output: 5 predicted output: 4.899 updated weights: [-0.828  2.865]\n","input: [2] actual output: 7 predicted output: 6.939000000000001 updated weights: [-0.827  2.866]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.826  2.866]\n","input: [4] actual output: 11 predicted output: 11.026 updated weights: [-0.827  2.866]\n","input: [5] actual output: 13 predicted output: 13.061 updated weights: [-0.83   2.865]\n","input: [1] actual output: 5 predicted output: 4.9 updated weights: [-0.829  2.866]\n","input: [2] actual output: 7 predicted output: 6.9399999999999995 updated weights: [-0.828  2.867]\n","input: [3] actual output: 9 predicted output: 8.983999999999998 updated weights: [-0.828  2.867]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.829  2.867]\n","input: [5] actual output: 13 predicted output: 13.057000000000002 updated weights: [-0.832  2.866]\n","input: [1] actual output: 5 predicted output: 4.9 updated weights: [-0.831  2.867]\n","input: [2] actual output: 7 predicted output: 6.939 updated weights: [-0.83   2.868]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.829  2.868]\n","input: [4] actual output: 11 predicted output: 11.024 updated weights: [-0.83   2.868]\n","input: [5] actual output: 13 predicted output: 13.058000000000002 updated weights: [-0.833  2.867]\n","input: [1] actual output: 5 predicted output: 4.901 updated weights: [-0.832  2.868]\n","input: [2] actual output: 7 predicted output: 6.9399999999999995 updated weights: [-0.831  2.869]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.83   2.869]\n","input: [4] actual output: 11 predicted output: 11.025 updated weights: [-0.831  2.869]\n","input: [5] actual output: 13 predicted output: 13.059000000000001 updated weights: [-0.834  2.868]\n","input: [1] actual output: 5 predicted output: 4.901999999999999 updated weights: [-0.833  2.869]\n","input: [2] actual output: 7 predicted output: 6.941000000000001 updated weights: [-0.832  2.87 ]\n","input: [3] actual output: 9 predicted output: 8.983999999999998 updated weights: [-0.832  2.87 ]\n","input: [4] actual output: 11 predicted output: 11.022000000000002 updated weights: [-0.833  2.87 ]\n","input: [5] actual output: 13 predicted output: 13.055000000000003 updated weights: [-0.836  2.869]\n","input: [1] actual output: 5 predicted output: 4.902000000000001 updated weights: [-0.835  2.87 ]\n","input: [2] actual output: 7 predicted output: 6.94 updated weights: [-0.834  2.871]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.833  2.871]\n","input: [4] actual output: 11 predicted output: 11.023000000000001 updated weights: [-0.834  2.871]\n","input: [5] actual output: 13 predicted output: 13.056000000000001 updated weights: [-0.837  2.87 ]\n","input: [1] actual output: 5 predicted output: 4.9030000000000005 updated weights: [-0.836  2.871]\n","input: [2] actual output: 7 predicted output: 6.941000000000001 updated weights: [-0.835  2.872]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.834  2.872]\n","input: [4] actual output: 11 predicted output: 11.024 updated weights: [-0.835  2.872]\n","input: [5] actual output: 13 predicted output: 13.056999999999999 updated weights: [-0.838  2.871]\n","input: [1] actual output: 5 predicted output: 4.904 updated weights: [-0.837  2.872]\n","input: [2] actual output: 7 predicted output: 6.942 updated weights: [-0.836  2.873]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.836  2.873]\n","input: [4] actual output: 11 predicted output: 11.021 updated weights: [-0.837  2.873]\n","input: [5] actual output: 13 predicted output: 13.053000000000004 updated weights: [-0.84   2.872]\n","input: [1] actual output: 5 predicted output: 4.904 updated weights: [-0.839  2.873]\n","input: [2] actual output: 7 predicted output: 6.941000000000001 updated weights: [-0.838  2.874]\n","input: [3] actual output: 9 predicted output: 8.982000000000001 updated weights: [-0.837  2.874]\n","input: [4] actual output: 11 predicted output: 11.022 updated weights: [-0.838  2.874]\n","input: [5] actual output: 13 predicted output: 13.054000000000002 updated weights: [-0.841  2.873]\n","input: [1] actual output: 5 predicted output: 4.905 updated weights: [-0.84   2.874]\n","input: [2] actual output: 7 predicted output: 6.942 updated weights: [-0.839  2.875]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.838  2.875]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.839  2.875]\n","input: [5] actual output: 13 predicted output: 13.055 updated weights: [-0.842  2.874]\n","input: [1] actual output: 5 predicted output: 4.906000000000001 updated weights: [-0.841  2.875]\n","input: [2] actual output: 7 predicted output: 6.943 updated weights: [-0.84   2.876]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.84   2.876]\n","input: [4] actual output: 11 predicted output: 11.02 updated weights: [-0.841  2.876]\n","input: [5] actual output: 13 predicted output: 13.050999999999998 updated weights: [-0.844  2.875]\n","input: [1] actual output: 5 predicted output: 4.906000000000001 updated weights: [-0.843  2.876]\n","input: [2] actual output: 7 predicted output: 6.942 updated weights: [-0.842  2.877]\n","input: [3] actual output: 9 predicted output: 8.982 updated weights: [-0.841  2.877]\n","input: [4] actual output: 11 predicted output: 11.020999999999997 updated weights: [-0.842  2.877]\n","input: [5] actual output: 13 predicted output: 13.051999999999996 updated weights: [-0.845  2.876]\n","input: [1] actual output: 5 predicted output: 4.907 updated weights: [-0.844  2.877]\n","input: [2] actual output: 7 predicted output: 6.943 updated weights: [-0.843  2.878]\n","input: [3] actual output: 9 predicted output: 8.983 updated weights: [-0.842  2.878]\n","input: [4] actual output: 11 predicted output: 11.022 updated weights: [-0.843  2.878]\n","input: [5] actual output: 13 predicted output: 13.053 updated weights: [-0.846  2.877]\n","input: [1] actual output: 5 predicted output: 4.9079999999999995 updated weights: [-0.845  2.878]\n","input: [2] actual output: 7 predicted output: 6.944000000000001 updated weights: [-0.844  2.879]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.844  2.879]\n","input: [4] actual output: 11 predicted output: 11.019 updated weights: [-0.845  2.879]\n","input: [5] actual output: 13 predicted output: 13.049 updated weights: [-0.847  2.879]\n","input: [1] actual output: 5 predicted output: 4.911 updated weights: [-0.846  2.88 ]\n","input: [2] actual output: 7 predicted output: 6.9479999999999995 updated weights: [-0.845  2.881]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.845  2.881]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.846  2.881]\n","input: [5] actual output: 13 predicted output: 13.056000000000001 updated weights: [-0.849  2.88 ]\n","input: [1] actual output: 5 predicted output: 4.911 updated weights: [-0.848  2.881]\n","input: [2] actual output: 7 predicted output: 6.946999999999999 updated weights: [-0.847  2.882]\n","input: [3] actual output: 9 predicted output: 8.987 updated weights: [-0.847  2.882]\n","input: [4] actual output: 11 predicted output: 11.022 updated weights: [-0.848  2.882]\n","input: [5] actual output: 13 predicted output: 13.052 updated weights: [-0.851  2.881]\n","input: [1] actual output: 5 predicted output: 4.911 updated weights: [-0.85   2.882]\n","input: [2] actual output: 7 predicted output: 6.946 updated weights: [-0.849  2.883]\n","input: [3] actual output: 9 predicted output: 8.985000000000001 updated weights: [-0.849  2.883]\n","input: [4] actual output: 11 predicted output: 11.018999999999998 updated weights: [-0.85   2.883]\n","input: [5] actual output: 13 predicted output: 13.047999999999998 updated weights: [-0.852  2.883]\n","input: [1] actual output: 5 predicted output: 4.914 updated weights: [-0.851  2.884]\n","input: [2] actual output: 7 predicted output: 6.949999999999999 updated weights: [-0.85   2.884]\n","input: [3] actual output: 9 predicted output: 8.985999999999999 updated weights: [-0.85   2.884]\n","input: [4] actual output: 11 predicted output: 11.02 updated weights: [-0.851  2.884]\n","input: [5] actual output: 13 predicted output: 13.049 updated weights: [-0.853  2.884]\n","input: [1] actual output: 5 predicted output: 4.914999999999999 updated weights: [-0.852  2.885]\n","input: [2] actual output: 7 predicted output: 6.951 updated weights: [-0.851  2.885]\n","input: [3] actual output: 9 predicted output: 8.986999999999998 updated weights: [-0.851  2.885]\n","input: [4] actual output: 11 predicted output: 11.020999999999999 updated weights: [-0.852  2.885]\n","input: [5] actual output: 13 predicted output: 13.049999999999999 updated weights: [-0.854  2.884]\n","input: [1] actual output: 5 predicted output: 4.914 updated weights: [-0.853  2.885]\n","input: [2] actual output: 7 predicted output: 6.949 updated weights: [-0.852  2.886]\n","input: [3] actual output: 9 predicted output: 8.988000000000001 updated weights: [-0.852  2.886]\n","input: [4] actual output: 11 predicted output: 11.022000000000002 updated weights: [-0.853  2.886]\n","input: [5] actual output: 13 predicted output: 13.050999999999998 updated weights: [-0.856  2.885]\n","input: [1] actual output: 5 predicted output: 4.914 updated weights: [-0.855  2.886]\n","input: [2] actual output: 7 predicted output: 6.948 updated weights: [-0.854  2.887]\n","input: [3] actual output: 9 predicted output: 8.986 updated weights: [-0.854  2.887]\n","input: [4] actual output: 11 predicted output: 11.019 updated weights: [-0.855  2.887]\n","input: [5] actual output: 13 predicted output: 13.047 updated weights: [-0.857  2.887]\n","input: [1] actual output: 5 predicted output: 4.917 updated weights: [-0.856  2.888]\n","input: [2] actual output: 7 predicted output: 6.952 updated weights: [-0.855  2.888]\n","input: [3] actual output: 9 predicted output: 8.987 updated weights: [-0.855  2.888]\n","input: [4] actual output: 11 predicted output: 11.02 updated weights: [-0.856  2.888]\n","input: [5] actual output: 13 predicted output: 13.048 updated weights: [-0.858  2.888]\n","input: [1] actual output: 5 predicted output: 4.917999999999999 updated weights: [-0.857  2.889]\n","input: [2] actual output: 7 predicted output: 6.952999999999999 updated weights: [-0.856  2.889]\n","input: [3] actual output: 9 predicted output: 8.988 updated weights: [-0.856  2.889]\n","input: [4] actual output: 11 predicted output: 11.020999999999999 updated weights: [-0.857  2.889]\n","input: [5] actual output: 13 predicted output: 13.048999999999998 updated weights: [-0.859  2.889]\n","input: [1] actual output: 5 predicted output: 4.919 updated weights: [-0.858  2.89 ]\n","input: [2] actual output: 7 predicted output: 6.954000000000001 updated weights: [-0.857  2.89 ]\n","input: [3] actual output: 9 predicted output: 8.989 updated weights: [-0.857  2.89 ]\n","input: [4] actual output: 11 predicted output: 11.022000000000002 updated weights: [-0.858  2.89 ]\n","input: [5] actual output: 13 predicted output: 13.05 updated weights: [-0.86  2.89]\n","input: [1] actual output: 5 predicted output: 4.92 updated weights: [-0.859  2.891]\n","input: [2] actual output: 7 predicted output: 6.955 updated weights: [-0.858  2.891]\n","input: [3] actual output: 9 predicted output: 8.99 updated weights: [-0.858  2.891]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.859  2.891]\n","input: [5] actual output: 13 predicted output: 13.051 updated weights: [-0.862  2.89 ]\n","input: [1] actual output: 5 predicted output: 4.918 updated weights: [-0.861  2.891]\n","input: [2] actual output: 7 predicted output: 6.9510000000000005 updated weights: [-0.86   2.891]\n","input: [3] actual output: 9 predicted output: 8.984 updated weights: [-0.86   2.891]\n","input: [4] actual output: 11 predicted output: 11.015 updated weights: [-0.861  2.891]\n","input: [5] actual output: 13 predicted output: 13.041 updated weights: [-0.863  2.891]\n","input: [1] actual output: 5 predicted output: 4.9190000000000005 updated weights: [-0.862  2.892]\n","input: [2] actual output: 7 predicted output: 6.952 updated weights: [-0.861  2.892]\n","input: [3] actual output: 9 predicted output: 8.985 updated weights: [-0.861  2.892]\n","input: [4] actual output: 11 predicted output: 11.015999999999998 updated weights: [-0.862  2.892]\n","input: [5] actual output: 13 predicted output: 13.041999999999998 updated weights: [-0.864  2.892]\n","input: [1] actual output: 5 predicted output: 4.92 updated weights: [-0.863  2.893]\n","input: [2] actual output: 7 predicted output: 6.952999999999999 updated weights: [-0.862  2.893]\n","input: [3] actual output: 9 predicted output: 8.985999999999997 updated weights: [-0.862  2.893]\n","input: [4] actual output: 11 predicted output: 11.017 updated weights: [-0.863  2.893]\n","input: [5] actual output: 13 predicted output: 13.043 updated weights: [-0.865  2.893]\n","input: [1] actual output: 5 predicted output: 4.920999999999999 updated weights: [-0.864  2.894]\n","input: [2] actual output: 7 predicted output: 6.954000000000001 updated weights: [-0.863  2.894]\n","input: [3] actual output: 9 predicted output: 8.987 updated weights: [-0.863  2.894]\n","input: [4] actual output: 11 predicted output: 11.018 updated weights: [-0.864  2.894]\n","input: [5] actual output: 13 predicted output: 13.044 updated weights: [-0.866  2.894]\n","input: [1] actual output: 5 predicted output: 4.922000000000001 updated weights: [-0.865  2.895]\n","input: [2] actual output: 7 predicted output: 6.955 updated weights: [-0.864  2.895]\n","input: [3] actual output: 9 predicted output: 8.988 updated weights: [-0.864  2.895]\n","input: [4] actual output: 11 predicted output: 11.019 updated weights: [-0.865  2.895]\n","input: [5] actual output: 13 predicted output: 13.044999999999998 updated weights: [-0.867  2.895]\n","input: [1] actual output: 5 predicted output: 4.923 updated weights: [-0.866  2.896]\n","input: [2] actual output: 7 predicted output: 6.9559999999999995 updated weights: [-0.865  2.896]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.865  2.896]\n","input: [4] actual output: 11 predicted output: 11.02 updated weights: [-0.866  2.896]\n","input: [5] actual output: 13 predicted output: 13.046 updated weights: [-0.868  2.896]\n","input: [1] actual output: 5 predicted output: 4.9239999999999995 updated weights: [-0.867  2.897]\n","input: [2] actual output: 7 predicted output: 6.956999999999999 updated weights: [-0.866  2.897]\n","input: [3] actual output: 9 predicted output: 8.989999999999998 updated weights: [-0.866  2.897]\n","input: [4] actual output: 11 predicted output: 11.020999999999999 updated weights: [-0.867  2.897]\n","input: [5] actual output: 13 predicted output: 13.046999999999999 updated weights: [-0.869  2.897]\n","input: [1] actual output: 5 predicted output: 4.924999999999999 updated weights: [-0.868  2.898]\n","input: [2] actual output: 7 predicted output: 6.958 updated weights: [-0.867  2.898]\n","input: [3] actual output: 9 predicted output: 8.991000000000001 updated weights: [-0.867  2.898]\n","input: [4] actual output: 11 predicted output: 11.022 updated weights: [-0.868  2.898]\n","input: [5] actual output: 13 predicted output: 13.048 updated weights: [-0.87   2.898]\n","input: [1] actual output: 5 predicted output: 4.926 updated weights: [-0.869  2.899]\n","input: [2] actual output: 7 predicted output: 6.9590000000000005 updated weights: [-0.868  2.899]\n","input: [3] actual output: 9 predicted output: 8.991999999999999 updated weights: [-0.868  2.899]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.869  2.899]\n","input: [5] actual output: 13 predicted output: 13.049000000000003 updated weights: [-0.871  2.899]\n","input: [1] actual output: 5 predicted output: 4.927 updated weights: [-0.87  2.9 ]\n","input: [2] actual output: 7 predicted output: 6.959999999999999 updated weights: [-0.869  2.9  ]\n","input: [3] actual output: 9 predicted output: 8.992999999999999 updated weights: [-0.869  2.9  ]\n","input: [4] actual output: 11 predicted output: 11.024 updated weights: [-0.87  2.9 ]\n","input: [5] actual output: 13 predicted output: 13.05 updated weights: [-0.872  2.899]\n","input: [1] actual output: 5 predicted output: 4.926 updated weights: [-0.871  2.9  ]\n","input: [2] actual output: 7 predicted output: 6.958 updated weights: [-0.87  2.9 ]\n","input: [3] actual output: 9 predicted output: 8.99 updated weights: [-0.87  2.9 ]\n","input: [4] actual output: 11 predicted output: 11.02 updated weights: [-0.871  2.9  ]\n","input: [5] actual output: 13 predicted output: 13.045 updated weights: [-0.873  2.9  ]\n","input: [1] actual output: 5 predicted output: 4.927 updated weights: [-0.872  2.901]\n","input: [2] actual output: 7 predicted output: 6.959 updated weights: [-0.871  2.901]\n","input: [3] actual output: 9 predicted output: 8.991 updated weights: [-0.871  2.901]\n","input: [4] actual output: 11 predicted output: 11.020999999999999 updated weights: [-0.872  2.901]\n","input: [5] actual output: 13 predicted output: 13.046 updated weights: [-0.874  2.901]\n","input: [1] actual output: 5 predicted output: 4.927999999999999 updated weights: [-0.873  2.902]\n","input: [2] actual output: 7 predicted output: 6.96 updated weights: [-0.872  2.902]\n","input: [3] actual output: 9 predicted output: 8.992 updated weights: [-0.872  2.902]\n","input: [4] actual output: 11 predicted output: 11.022000000000002 updated weights: [-0.873  2.902]\n","input: [5] actual output: 13 predicted output: 13.047 updated weights: [-0.875  2.902]\n","input: [1] actual output: 5 predicted output: 4.929 updated weights: [-0.874  2.903]\n","input: [2] actual output: 7 predicted output: 6.961 updated weights: [-0.873  2.903]\n","input: [3] actual output: 9 predicted output: 8.993 updated weights: [-0.873  2.903]\n","input: [4] actual output: 11 predicted output: 11.023000000000001 updated weights: [-0.874  2.903]\n","input: [5] actual output: 13 predicted output: 13.048 updated weights: [-0.876  2.903]\n","input: [1] actual output: 5 predicted output: 4.93 updated weights: [-0.875  2.904]\n","input: [2] actual output: 7 predicted output: 6.962 updated weights: [-0.874  2.904]\n","input: [3] actual output: 9 predicted output: 8.994 updated weights: [-0.874  2.904]\n","input: [4] actual output: 11 predicted output: 11.024 updated weights: [-0.875  2.904]\n","input: [5] actual output: 13 predicted output: 13.049 updated weights: [-0.877  2.904]\n","input: [1] actual output: 5 predicted output: 4.931 updated weights: [-0.876  2.905]\n","input: [2] actual output: 7 predicted output: 6.962999999999999 updated weights: [-0.875  2.905]\n","input: [3] actual output: 9 predicted output: 8.995 updated weights: [-0.875  2.905]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.876  2.905]\n","input: [5] actual output: 13 predicted output: 13.049999999999999 updated weights: [-0.878  2.904]\n","input: [1] actual output: 5 predicted output: 4.93 updated weights: [-0.877  2.905]\n","input: [2] actual output: 7 predicted output: 6.9609999999999985 updated weights: [-0.876  2.905]\n","input: [3] actual output: 9 predicted output: 8.991999999999999 updated weights: [-0.876  2.905]\n","input: [4] actual output: 11 predicted output: 11.020999999999999 updated weights: [-0.877  2.905]\n","input: [5] actual output: 13 predicted output: 13.044999999999998 updated weights: [-0.879  2.905]\n","input: [1] actual output: 5 predicted output: 4.930999999999999 updated weights: [-0.878  2.906]\n","input: [2] actual output: 7 predicted output: 6.962 updated weights: [-0.877  2.906]\n","input: [3] actual output: 9 predicted output: 8.993 updated weights: [-0.877  2.906]\n","input: [4] actual output: 11 predicted output: 11.022 updated weights: [-0.878  2.906]\n","input: [5] actual output: 13 predicted output: 13.046000000000001 updated weights: [-0.88   2.906]\n","input: [1] actual output: 5 predicted output: 4.932 updated weights: [-0.879  2.907]\n","input: [2] actual output: 7 predicted output: 6.963 updated weights: [-0.878  2.907]\n","input: [3] actual output: 9 predicted output: 8.994 updated weights: [-0.878  2.907]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.879  2.907]\n","input: [5] actual output: 13 predicted output: 13.047 updated weights: [-0.881  2.907]\n","input: [1] actual output: 5 predicted output: 4.933 updated weights: [-0.88   2.908]\n","input: [2] actual output: 7 predicted output: 6.964 updated weights: [-0.879  2.908]\n","input: [3] actual output: 9 predicted output: 8.995 updated weights: [-0.879  2.908]\n","input: [4] actual output: 11 predicted output: 11.024 updated weights: [-0.88   2.908]\n","input: [5] actual output: 13 predicted output: 13.047999999999998 updated weights: [-0.882  2.908]\n","input: [1] actual output: 5 predicted output: 4.933999999999999 updated weights: [-0.881  2.909]\n","input: [2] actual output: 7 predicted output: 6.964999999999999 updated weights: [-0.88   2.909]\n","input: [3] actual output: 9 predicted output: 8.995999999999999 updated weights: [-0.88   2.909]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.881  2.909]\n","input: [5] actual output: 13 predicted output: 13.048999999999996 updated weights: [-0.883  2.909]\n","input: [1] actual output: 5 predicted output: 4.935 updated weights: [-0.882  2.91 ]\n","input: [2] actual output: 7 predicted output: 6.966 updated weights: [-0.881  2.91 ]\n","input: [3] actual output: 9 predicted output: 8.997 updated weights: [-0.881  2.91 ]\n","input: [4] actual output: 11 predicted output: 11.026 updated weights: [-0.882  2.91 ]\n","input: [5] actual output: 13 predicted output: 13.05 updated weights: [-0.885  2.91 ]\n","input: [1] actual output: 5 predicted output: 4.9350000000000005 updated weights: [-0.884  2.911]\n","input: [2] actual output: 7 predicted output: 6.965 updated weights: [-0.883  2.911]\n","input: [3] actual output: 9 predicted output: 8.995000000000001 updated weights: [-0.883  2.911]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.884  2.911]\n","input: [5] actual output: 13 predicted output: 13.046 updated weights: [-0.886  2.911]\n","input: [1] actual output: 5 predicted output: 4.936 updated weights: [-0.885  2.912]\n","input: [2] actual output: 7 predicted output: 6.966 updated weights: [-0.884  2.912]\n","input: [3] actual output: 9 predicted output: 8.996 updated weights: [-0.884  2.912]\n","input: [4] actual output: 11 predicted output: 11.024000000000001 updated weights: [-0.885  2.912]\n","input: [5] actual output: 13 predicted output: 13.046999999999997 updated weights: [-0.887  2.912]\n","input: [1] actual output: 5 predicted output: 4.936999999999999 updated weights: [-0.886  2.913]\n","input: [2] actual output: 7 predicted output: 6.966999999999999 updated weights: [-0.885  2.913]\n","input: [3] actual output: 9 predicted output: 8.996999999999998 updated weights: [-0.885  2.913]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.886  2.913]\n","input: [5] actual output: 13 predicted output: 13.048 updated weights: [-0.888  2.913]\n","input: [1] actual output: 5 predicted output: 4.938 updated weights: [-0.887  2.914]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.886  2.914]\n","input: [3] actual output: 9 predicted output: 8.998000000000001 updated weights: [-0.886  2.914]\n","input: [4] actual output: 11 predicted output: 11.026 updated weights: [-0.887  2.914]\n","input: [5] actual output: 13 predicted output: 13.049 updated weights: [-0.889  2.914]\n","input: [1] actual output: 5 predicted output: 4.939 updated weights: [-0.888  2.915]\n","input: [2] actual output: 7 predicted output: 6.969 updated weights: [-0.887  2.915]\n","input: [3] actual output: 9 predicted output: 8.999000000000002 updated weights: [-0.887  2.915]\n","input: [4] actual output: 11 predicted output: 11.027000000000001 updated weights: [-0.888  2.915]\n","input: [5] actual output: 13 predicted output: 13.049999999999997 updated weights: [-0.89   2.914]\n","input: [1] actual output: 5 predicted output: 4.938000000000001 updated weights: [-0.889  2.915]\n","input: [2] actual output: 7 predicted output: 6.967 updated weights: [-0.888  2.915]\n","input: [3] actual output: 9 predicted output: 8.996000000000002 updated weights: [-0.888  2.915]\n","input: [4] actual output: 11 predicted output: 11.023 updated weights: [-0.889  2.915]\n","input: [5] actual output: 13 predicted output: 13.044999999999998 updated weights: [-0.891  2.915]\n","input: [1] actual output: 5 predicted output: 4.939 updated weights: [-0.89   2.916]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.889  2.916]\n","input: [3] actual output: 9 predicted output: 8.997 updated weights: [-0.889  2.916]\n","input: [4] actual output: 11 predicted output: 11.024000000000001 updated weights: [-0.89   2.916]\n","input: [5] actual output: 13 predicted output: 13.046 updated weights: [-0.892  2.916]\n","input: [1] actual output: 5 predicted output: 4.9399999999999995 updated weights: [-0.891  2.917]\n","input: [2] actual output: 7 predicted output: 6.968999999999999 updated weights: [-0.89   2.917]\n","input: [3] actual output: 9 predicted output: 8.998 updated weights: [-0.89   2.917]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.891  2.917]\n","input: [5] actual output: 13 predicted output: 13.046999999999999 updated weights: [-0.893  2.917]\n","input: [1] actual output: 5 predicted output: 4.941 updated weights: [-0.892  2.918]\n","input: [2] actual output: 7 predicted output: 6.970000000000001 updated weights: [-0.891  2.918]\n","input: [3] actual output: 9 predicted output: 8.999000000000002 updated weights: [-0.891  2.918]\n","input: [4] actual output: 11 predicted output: 11.026 updated weights: [-0.892  2.918]\n","input: [5] actual output: 13 predicted output: 13.047999999999998 updated weights: [-0.894  2.918]\n","input: [1] actual output: 5 predicted output: 4.942 updated weights: [-0.893  2.919]\n","input: [2] actual output: 7 predicted output: 6.971 updated weights: [-0.892  2.919]\n","input: [4] actual output: 11 predicted output: 11.027000000000001 updated weights: [-0.893  2.919]\n","input: [5] actual output: 13 predicted output: 13.049000000000001 updated weights: [-0.895  2.919]\n","input: [1] actual output: 5 predicted output: 4.943 updated weights: [-0.894  2.92 ]\n","input: [2] actual output: 7 predicted output: 6.9719999999999995 updated weights: [-0.893  2.92 ]\n","input: [3] actual output: 9 predicted output: 9.001 updated weights: [-0.893  2.92 ]\n","input: [4] actual output: 11 predicted output: 11.028 updated weights: [-0.894  2.92 ]\n","input: [5] actual output: 13 predicted output: 13.049999999999999 updated weights: [-0.896  2.919]\n","input: [1] actual output: 5 predicted output: 4.942 updated weights: [-0.895  2.92 ]\n","input: [2] actual output: 7 predicted output: 6.97 updated weights: [-0.894  2.92 ]\n","input: [3] actual output: 9 predicted output: 8.998 updated weights: [-0.894  2.92 ]\n","input: [4] actual output: 11 predicted output: 11.024 updated weights: [-0.895  2.92 ]\n","input: [5] actual output: 13 predicted output: 13.045 updated weights: [-0.897  2.92 ]\n","input: [1] actual output: 5 predicted output: 4.943 updated weights: [-0.896  2.921]\n","input: [2] actual output: 7 predicted output: 6.971 updated weights: [-0.895  2.921]\n","input: [3] actual output: 9 predicted output: 8.998999999999999 updated weights: [-0.895  2.921]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.896  2.921]\n","input: [5] actual output: 13 predicted output: 13.045999999999998 updated weights: [-0.898  2.921]\n","input: [1] actual output: 5 predicted output: 4.943999999999999 updated weights: [-0.897  2.922]\n","input: [2] actual output: 7 predicted output: 6.972000000000001 updated weights: [-0.896  2.922]\n","input: [4] actual output: 11 predicted output: 11.026000000000002 updated weights: [-0.897  2.922]\n","input: [5] actual output: 13 predicted output: 13.047 updated weights: [-0.899  2.922]\n","input: [1] actual output: 5 predicted output: 4.945 updated weights: [-0.898  2.923]\n","input: [2] actual output: 7 predicted output: 6.973 updated weights: [-0.897  2.923]\n","input: [3] actual output: 9 predicted output: 9.001000000000001 updated weights: [-0.897  2.923]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.898  2.923]\n","input: [5] actual output: 13 predicted output: 13.048 updated weights: [-0.9    2.923]\n","input: [1] actual output: 5 predicted output: 4.946 updated weights: [-0.899  2.924]\n","input: [2] actual output: 7 predicted output: 6.974 updated weights: [-0.898  2.924]\n","input: [3] actual output: 9 predicted output: 9.002 updated weights: [-0.898  2.924]\n","input: [4] actual output: 11 predicted output: 11.027999999999999 updated weights: [-0.899  2.924]\n","input: [5] actual output: 13 predicted output: 13.049 updated weights: [-0.901  2.924]\n","input: [1] actual output: 5 predicted output: 4.946999999999999 updated weights: [-0.9    2.925]\n","input: [2] actual output: 7 predicted output: 6.975 updated weights: [-0.9    2.925]\n","input: [3] actual output: 9 predicted output: 8.999999999999998 updated weights: [-0.9    2.925]\n","input: [4] actual output: 11 predicted output: 11.024999999999999 updated weights: [-0.901  2.925]\n","input: [5] actual output: 13 predicted output: 13.045000000000002 updated weights: [-0.903  2.925]\n","input: [1] actual output: 5 predicted output: 4.946999999999999 updated weights: [-0.902  2.926]\n","input: [2] actual output: 7 predicted output: 6.974 updated weights: [-0.901  2.926]\n","input: [3] actual output: 9 predicted output: 9.001000000000001 updated weights: [-0.901  2.926]\n","input: [4] actual output: 11 predicted output: 11.026000000000002 updated weights: [-0.902  2.926]\n","input: [5] actual output: 13 predicted output: 13.046000000000001 updated weights: [-0.904  2.926]\n","input: [1] actual output: 5 predicted output: 4.948 updated weights: [-0.903  2.927]\n","input: [2] actual output: 7 predicted output: 6.975 updated weights: [-0.902  2.927]\n","input: [3] actual output: 9 predicted output: 9.002 updated weights: [-0.902  2.927]\n","input: [4] actual output: 11 predicted output: 11.027 updated weights: [-0.903  2.927]\n","input: [5] actual output: 13 predicted output: 13.046999999999999 updated weights: [-0.905  2.927]\n","input: [1] actual output: 5 predicted output: 4.949 updated weights: [-0.904  2.928]\n","input: [2] actual output: 7 predicted output: 6.976 updated weights: [-0.904  2.928]\n","input: [4] actual output: 11 predicted output: 11.024000000000001 updated weights: [-0.905  2.928]\n","input: [5] actual output: 13 predicted output: 13.043 updated weights: [-0.907  2.928]\n","input: [1] actual output: 5 predicted output: 4.949 updated weights: [-0.906  2.929]\n","input: [2] actual output: 7 predicted output: 6.975 updated weights: [-0.906  2.929]\n","input: [3] actual output: 9 predicted output: 8.998 updated weights: [-0.906  2.929]\n","input: [4] actual output: 11 predicted output: 11.020999999999999 updated weights: [-0.907  2.929]\n","input: [5] actual output: 13 predicted output: 13.039 updated weights: [-0.909  2.929]\n","input: [1] actual output: 5 predicted output: 4.949 updated weights: [-0.908  2.93 ]\n","input: [2] actual output: 7 predicted output: 6.974 updated weights: [-0.907  2.93 ]\n","input: [3] actual output: 9 predicted output: 8.999 updated weights: [-0.907  2.93 ]\n","input: [4] actual output: 11 predicted output: 11.022 updated weights: [-0.908  2.93 ]\n","input: [5] actual output: 13 predicted output: 13.04 updated weights: [-0.91  2.93]\n","input: [1] actual output: 5 predicted output: 4.95 updated weights: [-0.91   2.931]\n","input: [2] actual output: 7 predicted output: 6.973 updated weights: [-0.909  2.931]\n","input: [3] actual output: 9 predicted output: 8.997 updated weights: [-0.909  2.931]\n","input: [4] actual output: 11 predicted output: 11.019000000000002 updated weights: [-0.91   2.931]\n","input: [5] actual output: 13 predicted output: 13.036000000000001 updated weights: [-0.912  2.931]\n","input: [1] actual output: 5 predicted output: 4.95 updated weights: [-0.912  2.932]\n","input: [2] actual output: 7 predicted output: 6.9719999999999995 updated weights: [-0.911  2.932]\n","input: [3] actual output: 9 predicted output: 8.995 updated weights: [-0.911  2.932]\n","input: [4] actual output: 11 predicted output: 11.016 updated weights: [-0.912  2.932]\n","input: [5] actual output: 13 predicted output: 13.032 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: [-0.913  2.932]\n","input: [5] actual output: 13 predicted output: 13.027 updated weights: [-0.914  2.932]\n","input: [1] actual output: 5 predicted output: 4.949999999999999 updated weights: [-0.914  2.932]\n","input: [2] actual output: 7 predicted output: 6.968 updated weights: [-0.913  2.932]\n","input: [3] actual output: 9 predicted output: 8.988999999999999 updated weights: [-0.913  2.932]\n","input: [4] actual output: 11 predicted output: 11.008000000000001 updated weights: "]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-70fd69ec0de1>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Round to 3 decimal points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Round to 3 decimal points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"actual output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predicted output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"updated weights:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmse_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["predictFx(X,y,weights)"],"metadata":{"id":"e441JsjQHTaA","outputId":"e823da33-3cbd-40aa-d081-5aa6fdd25505","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X\tActual\tPredicted\n","[1] \t 5 \t 5\n","[2] \t 7 \t 7\n","[3] \t 9 \t 9\n","[4] \t 11 \t 11\n","[5] \t 13 \t 13\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def gradient_descent(x,y):\n","    m_curr = b_curr = 0\n","    iterations = 10000\n","    n = len(x)\n","    learning_rate = 0.08\n","\n","    for i in range(iterations):\n","        y_predicted = m_curr * x + b_curr\n","        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n","        md = -(2/n)*sum(x*(y-y_predicted))\n","        bd = -(2/n)*sum(y-y_predicted)\n","        m_curr = m_curr - learning_rate * md\n","        b_curr = b_curr - learning_rate * bd\n","        print (\"m {}, b {}, cost {} iteration {}\".format(m_curr,b_curr,cost, i))\n","\n","x = np.array([1,2,3,4,5])\n","y = np.array([5,7,9,11,13])\n","\n","gradient_descent(x,y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBTOPLyLxTEr","outputId":"c6f4d7e4-d654-4473-afa1-d87d20d68462"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5000\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5001\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5002\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5003\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5004\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5005\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5006\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5007\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5008\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5009\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5010\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5011\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5012\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5013\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5014\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5015\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5016\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5017\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5018\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5019\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5020\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5021\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5022\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5023\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5024\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5025\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5026\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5027\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5028\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5029\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5030\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5031\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5032\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5033\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5034\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5035\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5036\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5037\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5038\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5039\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5040\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5041\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5042\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5043\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5044\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5045\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5046\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5047\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5048\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5049\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5050\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5051\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5052\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5053\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5054\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5055\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5056\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5057\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5058\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5059\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5060\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5061\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5062\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5063\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5064\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5065\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5066\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5067\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5068\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5069\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5070\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5071\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5072\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5073\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5074\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5075\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5076\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5077\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5078\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5079\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5080\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5081\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5082\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5083\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5084\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5085\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5086\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5087\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5088\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5089\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5090\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5091\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5092\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5093\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5094\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5095\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5096\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5097\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5098\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5099\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5100\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5101\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5102\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5103\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5104\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5105\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5106\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5107\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5108\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5109\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5110\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5111\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5112\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5113\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5114\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5115\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5116\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5117\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5118\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5119\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5120\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5121\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5122\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5123\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5124\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5125\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5126\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5127\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5128\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5129\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5130\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5131\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5132\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5133\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5134\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5135\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5136\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5137\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5138\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5139\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5140\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5141\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5142\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5143\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5144\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5145\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5146\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5147\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5148\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5149\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5150\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5151\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5152\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5153\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5154\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5155\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5156\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5157\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5158\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5159\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5160\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5161\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5162\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5163\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5164\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5165\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5166\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5167\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5168\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5169\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5170\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5171\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5172\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5173\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5174\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5175\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5176\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5177\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5178\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5179\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5180\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5181\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5182\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5183\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5184\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5185\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5186\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5187\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5188\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5189\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5190\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5191\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5192\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5193\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5194\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5195\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5196\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5197\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5198\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5199\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5200\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5201\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5202\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5203\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5204\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5205\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5206\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5207\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5208\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5209\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5210\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5211\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5212\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5213\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5214\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5215\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5216\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5217\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5218\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5219\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5220\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5221\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5222\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5223\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5224\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5225\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5226\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5227\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5228\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5229\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5230\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5231\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5232\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5233\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5234\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5235\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5236\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5237\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5238\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5239\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5240\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5241\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5242\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5243\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5244\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5245\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5246\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5247\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5248\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5249\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5250\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5251\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5252\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5253\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5254\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5255\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5256\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5257\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5258\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5259\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5260\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5261\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5262\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5263\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5264\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5265\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5266\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5267\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5268\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5269\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5270\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5271\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5272\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5273\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5274\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5275\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5276\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5277\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5278\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5279\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5280\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5281\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5282\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5283\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5284\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5285\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5286\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5287\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5288\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5289\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5290\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5291\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5292\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5293\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5294\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5295\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5296\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5297\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5298\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5299\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5300\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5301\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5302\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5303\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5304\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5305\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5306\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5307\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5308\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5309\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5310\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5311\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5312\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5313\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5314\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5315\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5316\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5317\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5318\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5319\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5320\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5321\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5322\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5323\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5324\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5325\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5326\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5327\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5328\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5329\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5330\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5331\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5332\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5333\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5334\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5335\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5336\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5337\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5338\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5339\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5340\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5341\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5342\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5343\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5344\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5345\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5346\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5347\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5348\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5349\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5350\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5351\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5352\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5353\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5354\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5355\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5356\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5357\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5358\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5359\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5360\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5361\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5362\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5363\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5364\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5365\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5366\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5367\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5368\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5369\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5370\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5371\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5372\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5373\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5374\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5375\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5376\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5377\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5378\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5379\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5380\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5381\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5382\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5383\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5384\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5385\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5386\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5387\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5388\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5389\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5390\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5391\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5392\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5393\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5394\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5395\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5396\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5397\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5398\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5399\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5400\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5401\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5402\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5403\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5404\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5405\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5406\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5407\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5408\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5409\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5410\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5411\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5412\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5413\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5414\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5415\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5416\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5417\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5418\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5419\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5420\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5421\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5422\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5423\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5424\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5425\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5426\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5427\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5428\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5429\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5430\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5431\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5432\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5433\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5434\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5435\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5436\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5437\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5438\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5439\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5440\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5441\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5442\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5443\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5444\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5445\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5446\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5447\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5448\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5449\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5450\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5451\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5452\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5453\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5454\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5455\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5456\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5457\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5458\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5459\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5460\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5461\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5462\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5463\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5464\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5465\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5466\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5467\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5468\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5469\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5470\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5471\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5472\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5473\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5474\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5475\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5476\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5477\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5478\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5479\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5480\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5481\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5482\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5483\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5484\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5485\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5486\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5487\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5488\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5489\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5490\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5491\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5492\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5493\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5494\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5495\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5496\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5497\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5498\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5499\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5500\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5501\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5502\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5503\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5504\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5505\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5506\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5507\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5508\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5509\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5510\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5511\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5512\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5513\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5514\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5515\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5516\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5517\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5518\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5519\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5520\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5521\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5522\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5523\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5524\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5525\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5526\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5527\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5528\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5529\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5530\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5531\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5532\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5533\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5534\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5535\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5536\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5537\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5538\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5539\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5540\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5541\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5542\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5543\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5544\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5545\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5546\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5547\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5548\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5549\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5550\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5551\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5552\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5553\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5554\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5555\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5556\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5557\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5558\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5559\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5560\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5561\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5562\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5563\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5564\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5565\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5566\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5567\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5568\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5569\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5570\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5571\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5572\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5573\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5574\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5575\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5576\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5577\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5578\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5579\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5580\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5581\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5582\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5583\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5584\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5585\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5586\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5587\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5588\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5589\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5590\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5591\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5592\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5593\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5594\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5595\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5596\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5597\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5598\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5599\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5600\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5601\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5602\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5603\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5604\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5605\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5606\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5607\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5608\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5609\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5610\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5611\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5612\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5613\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5614\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5615\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5616\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5617\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5618\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5619\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5620\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5621\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5622\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5623\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5624\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5625\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5626\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5627\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5628\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5629\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5630\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5631\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5632\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5633\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5634\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5635\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5636\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5637\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5638\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5639\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5640\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5641\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5642\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5643\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5644\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5645\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5646\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5647\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5648\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5649\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5650\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5651\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5652\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5653\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5654\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5655\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5656\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5657\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5658\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5659\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5660\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5661\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5662\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5663\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5664\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5665\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5666\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5667\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5668\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5669\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5670\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5671\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5672\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5673\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5674\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5675\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5676\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5677\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5678\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5679\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5680\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5681\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5682\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5683\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5684\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5685\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5686\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5687\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5688\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5689\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5690\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5691\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5692\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5693\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5694\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5695\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5696\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5697\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5698\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5699\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5700\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5701\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5702\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5703\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5704\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5705\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5706\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5707\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5708\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5709\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5710\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5711\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5712\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5713\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5714\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5715\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5716\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5717\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5718\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5719\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5720\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5721\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5722\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5723\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5724\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5725\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5726\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5727\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5728\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5729\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5730\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5731\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5732\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5733\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5734\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5735\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5736\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5737\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5738\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5739\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5740\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5741\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5742\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5743\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5744\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5745\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5746\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5747\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5748\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5749\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5750\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5751\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5752\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5753\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5754\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5755\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5756\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5757\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5758\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5759\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5760\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5761\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5762\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5763\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5764\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5765\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5766\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5767\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5768\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5769\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5770\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5771\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5772\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5773\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5774\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5775\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5776\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5777\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5778\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5779\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5780\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5781\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5782\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5783\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5784\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5785\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5786\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5787\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5788\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5789\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5790\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5791\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5792\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5793\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5794\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5795\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5796\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5797\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5798\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5799\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5800\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5801\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5802\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5803\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5804\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5805\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5806\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5807\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5808\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5809\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5810\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5811\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5812\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5813\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5814\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5815\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5816\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5817\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5818\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5819\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5820\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5821\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5822\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5823\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5824\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5825\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5826\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5827\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5828\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5829\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5830\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5831\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5832\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5833\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5834\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5835\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5836\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5837\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5838\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5839\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5840\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5841\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5842\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5843\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5844\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5845\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5846\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5847\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5848\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5849\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5850\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5851\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5852\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5853\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5854\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5855\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5856\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5857\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5858\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5859\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5860\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5861\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5862\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5863\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5864\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5865\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5866\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5867\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5868\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5869\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5870\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5871\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5872\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5873\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5874\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5875\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5876\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5877\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5878\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5879\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5880\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5881\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5882\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5883\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5884\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5885\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5886\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5887\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5888\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5889\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5890\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5891\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5892\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5893\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5894\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5895\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5896\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5897\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5898\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5899\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5900\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5901\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5902\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5903\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5904\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5905\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5906\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5907\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5908\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5909\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5910\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5911\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5912\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5913\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5914\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5915\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5916\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5917\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5918\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5919\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5920\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5921\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5922\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5923\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5924\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5925\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5926\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5927\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5928\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5929\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5930\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5931\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5932\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5933\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5934\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5935\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5936\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5937\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5938\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5939\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5940\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5941\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5942\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5943\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5944\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5945\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5946\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5947\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5948\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5949\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5950\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5951\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5952\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5953\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5954\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5955\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5956\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5957\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5958\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5959\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5960\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5961\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5962\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5963\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5964\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5965\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5966\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5967\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5968\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5969\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5970\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5971\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5972\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5973\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5974\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5975\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5976\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5977\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5978\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5979\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5980\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5981\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5982\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5983\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5984\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5985\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5986\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5987\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5988\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5989\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5990\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5991\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5992\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5993\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5994\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5995\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5996\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5997\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 5998\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 5999\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6000\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6001\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6002\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6003\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6004\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6005\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6006\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6007\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6008\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6009\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6010\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6011\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6012\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6013\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6014\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6015\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6016\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6017\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6018\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6019\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6020\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6021\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6022\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6023\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6024\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6025\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6026\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6027\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6028\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6029\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6030\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6031\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6032\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6033\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6034\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6035\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6036\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6037\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6038\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6039\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6040\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6041\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6042\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6043\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6044\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6045\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6046\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6047\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6048\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6049\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6050\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6051\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6052\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6053\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6054\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6055\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6056\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6057\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6058\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6059\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6060\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6061\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6062\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6063\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6064\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6065\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6066\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6067\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6068\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6069\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6070\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6071\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6072\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6073\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6074\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6075\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6076\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6077\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6078\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6079\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6080\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6081\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6082\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6083\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6084\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6085\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6086\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6087\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6088\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6089\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6090\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6091\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6092\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6093\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6094\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6095\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6096\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6097\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6098\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6099\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6100\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6101\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6102\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6103\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6104\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6105\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6106\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6107\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6108\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6109\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6110\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6111\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6112\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6113\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6114\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6115\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6116\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6117\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6118\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6119\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6120\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6121\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6122\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6123\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6124\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6125\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6126\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6127\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6128\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6129\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6130\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6131\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6132\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6133\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6134\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6135\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6136\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6137\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6138\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6139\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6140\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6141\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6142\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6143\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6144\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6145\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6146\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6147\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6148\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6149\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6150\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6151\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6152\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6153\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6154\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6155\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6156\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6157\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6158\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6159\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6160\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6161\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6162\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6163\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6164\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6165\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6166\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6167\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6168\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6169\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6170\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6171\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6172\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6173\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6174\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6175\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6176\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6177\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6178\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6179\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6180\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6181\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6182\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6183\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6184\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6185\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6186\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6187\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6188\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6189\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6190\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6191\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6192\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6193\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6194\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6195\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6196\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6197\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6198\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6199\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6200\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6201\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6202\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6203\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6204\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6205\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6206\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6207\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6208\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6209\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6210\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6211\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6212\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6213\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6214\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6215\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6216\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6217\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6218\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6219\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6220\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6221\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6222\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6223\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6224\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6225\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6226\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6227\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6228\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6229\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6230\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6231\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6232\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6233\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6234\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6235\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6236\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6237\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6238\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6239\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6240\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6241\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6242\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6243\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6244\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6245\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6246\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6247\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6248\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6249\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6250\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6251\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6252\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6253\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6254\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6255\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6256\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6257\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6258\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6259\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6260\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6261\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6262\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6263\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6264\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6265\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6266\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6267\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6268\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6269\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6270\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6271\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6272\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6273\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6274\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6275\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6276\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6277\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6278\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6279\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6280\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6281\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6282\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6283\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6284\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6285\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6286\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6287\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6288\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6289\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6290\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6291\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6292\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6293\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6294\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6295\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6296\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6297\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6298\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6299\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6300\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6301\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6302\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6303\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6304\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6305\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6306\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6307\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6308\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6309\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6310\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6311\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6312\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6313\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6314\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6315\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6316\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6317\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6318\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6319\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6320\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6321\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6322\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6323\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6324\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6325\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6326\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6327\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6328\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6329\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6330\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6331\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6332\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6333\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6334\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6335\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6336\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6337\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6338\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6339\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6340\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6341\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6342\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6343\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6344\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6345\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6346\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6347\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6348\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6349\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6350\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6351\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6352\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6353\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6354\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6355\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6356\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6357\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6358\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6359\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6360\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6361\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6362\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6363\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6364\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6365\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6366\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6367\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6368\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6369\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6370\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6371\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6372\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6373\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6374\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6375\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6376\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6377\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6378\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6379\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6380\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6381\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6382\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6383\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6384\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6385\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6386\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6387\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6388\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6389\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6390\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6391\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6392\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6393\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6394\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6395\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6396\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6397\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6398\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6399\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6400\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6401\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6402\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6403\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6404\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6405\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6406\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6407\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6408\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6409\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6410\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6411\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6412\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6413\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6414\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6415\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6416\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6417\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6418\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6419\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6420\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6421\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6422\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6423\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6424\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6425\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6426\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6427\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6428\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6429\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6430\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6431\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6432\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6433\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6434\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6435\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6436\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6437\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6438\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6439\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6440\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6441\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6442\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6443\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6444\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6445\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6446\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6447\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6448\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6449\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6450\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6451\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6452\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6453\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6454\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6455\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6456\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6457\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6458\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6459\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6460\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6461\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6462\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6463\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6464\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6465\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6466\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6467\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6468\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6469\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6470\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6471\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6472\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6473\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6474\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6475\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6476\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6477\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6478\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6479\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6480\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6481\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6482\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6483\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6484\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6485\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6486\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6487\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6488\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6489\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6490\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6491\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6492\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6493\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6494\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6495\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6496\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6497\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6498\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6499\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6500\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6501\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6502\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6503\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6504\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6505\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6506\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6507\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6508\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6509\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6510\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6511\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6512\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6513\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6514\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6515\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6516\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6517\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6518\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6519\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6520\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6521\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6522\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6523\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6524\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6525\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6526\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6527\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6528\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6529\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6530\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6531\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6532\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6533\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6534\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6535\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6536\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6537\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6538\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6539\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6540\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6541\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6542\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6543\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6544\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6545\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6546\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6547\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6548\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6549\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6550\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6551\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6552\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6553\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6554\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6555\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6556\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6557\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6558\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6559\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6560\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6561\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6562\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6563\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6564\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6565\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6566\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6567\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6568\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6569\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6570\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6571\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6572\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6573\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6574\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6575\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6576\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6577\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6578\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6579\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6580\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6581\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6582\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6583\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6584\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6585\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6586\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6587\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6588\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6589\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6590\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6591\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6592\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6593\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6594\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6595\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6596\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6597\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6598\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6599\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6600\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6601\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6602\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6603\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6604\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6605\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6606\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6607\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6608\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6609\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6610\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6611\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6612\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6613\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6614\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6615\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6616\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6617\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6618\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6619\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6620\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6621\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6622\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6623\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6624\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6625\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6626\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6627\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6628\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6629\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6630\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6631\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6632\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6633\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6634\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6635\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6636\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6637\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6638\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6639\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6640\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6641\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6642\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6643\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6644\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6645\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6646\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6647\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6648\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6649\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6650\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6651\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6652\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6653\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6654\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6655\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6656\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6657\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6658\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6659\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6660\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6661\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6662\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6663\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6664\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6665\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6666\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6667\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6668\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6669\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6670\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6671\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6672\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6673\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6674\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6675\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6676\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6677\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6678\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6679\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6680\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6681\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6682\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6683\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6684\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6685\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6686\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6687\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6688\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6689\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6690\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6691\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6692\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6693\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6694\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6695\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6696\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6697\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6698\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6699\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6700\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6701\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6702\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6703\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6704\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6705\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6706\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6707\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6708\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6709\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6710\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6711\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6712\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6713\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6714\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6715\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6716\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6717\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6718\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6719\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6720\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6721\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6722\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6723\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6724\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6725\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6726\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6727\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6728\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6729\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6730\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6731\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6732\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6733\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6734\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6735\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6736\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6737\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6738\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6739\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6740\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6741\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6742\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6743\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6744\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6745\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6746\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6747\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6748\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6749\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6750\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6751\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6752\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6753\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6754\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6755\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6756\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6757\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6758\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6759\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6760\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6761\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6762\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6763\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6764\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6765\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6766\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6767\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6768\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6769\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6770\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6771\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6772\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6773\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6774\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6775\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6776\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6777\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6778\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6779\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6780\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6781\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6782\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6783\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6784\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6785\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6786\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6787\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6788\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6789\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6790\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6791\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6792\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6793\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6794\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6795\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6796\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6797\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6798\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6799\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6800\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6801\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6802\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6803\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6804\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6805\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6806\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6807\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6808\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6809\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6810\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6811\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6812\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6813\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6814\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6815\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6816\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6817\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6818\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6819\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6820\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6821\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6822\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6823\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6824\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6825\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6826\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6827\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6828\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6829\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6830\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6831\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6832\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6833\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6834\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6835\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6836\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6837\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6838\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6839\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6840\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6841\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6842\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6843\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6844\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6845\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6846\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6847\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6848\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6849\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6850\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6851\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6852\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6853\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6854\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6855\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6856\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6857\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6858\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6859\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6860\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6861\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6862\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6863\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6864\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6865\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6866\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6867\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6868\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6869\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6870\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6871\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6872\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6873\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6874\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6875\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6876\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6877\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6878\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6879\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6880\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6881\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6882\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6883\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6884\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6885\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6886\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6887\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6888\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6889\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6890\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6891\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6892\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6893\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6894\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6895\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6896\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6897\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6898\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6899\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6900\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6901\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6902\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6903\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6904\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6905\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6906\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6907\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6908\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6909\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6910\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6911\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6912\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6913\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6914\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6915\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6916\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6917\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6918\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6919\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6920\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6921\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6922\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6923\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6924\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6925\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6926\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6927\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6928\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6929\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6930\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6931\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6932\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6933\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6934\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6935\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6936\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6937\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6938\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6939\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6940\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6941\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6942\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6943\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6944\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6945\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6946\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6947\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6948\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6949\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6950\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6951\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6952\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6953\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6954\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6955\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6956\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6957\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6958\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6959\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6960\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6961\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6962\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6963\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6964\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6965\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6966\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6967\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6968\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6969\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6970\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6971\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6972\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6973\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6974\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6975\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6976\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6977\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6978\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6979\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6980\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6981\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6982\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6983\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6984\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6985\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6986\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6987\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6988\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6989\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6990\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6991\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6992\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6993\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6994\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6995\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6996\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6997\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 6998\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 6999\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7000\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7001\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7002\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7003\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7004\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7005\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7006\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7007\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7008\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7009\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7010\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7011\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7012\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7013\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7014\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7015\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7016\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7017\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7018\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7019\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7020\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7021\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7022\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7023\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7024\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7025\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7026\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7027\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7028\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7029\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7030\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7031\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7032\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7033\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7034\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7035\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7036\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7037\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7038\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7039\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7040\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7041\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7042\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7043\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7044\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7045\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7046\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7047\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7048\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7049\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7050\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7051\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7052\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7053\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7054\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7055\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7056\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7057\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7058\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7059\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7060\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7061\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7062\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7063\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7064\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7065\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7066\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7067\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7068\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7069\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7070\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7071\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7072\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7073\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7074\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7075\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7076\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7077\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7078\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7079\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7080\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7081\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7082\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7083\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7084\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7085\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7086\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7087\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7088\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7089\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7090\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7091\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7092\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7093\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7094\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7095\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7096\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7097\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7098\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7099\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7100\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7101\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7102\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7103\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7104\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7105\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7106\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7107\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7108\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7109\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7110\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7111\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7112\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7113\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7114\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7115\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7116\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7117\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7118\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7119\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7120\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7121\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7122\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7123\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7124\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7125\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7126\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7127\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7128\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7129\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7130\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7131\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7132\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7133\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7134\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7135\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7136\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7137\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7138\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7139\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7140\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7141\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7142\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7143\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7144\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7145\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7146\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7147\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7148\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7149\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7150\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7151\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7152\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7153\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7154\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7155\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7156\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7157\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7158\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7159\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7160\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7161\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7162\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7163\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7164\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7165\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7166\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7167\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7168\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7169\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7170\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7171\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7172\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7173\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7174\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7175\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7176\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7177\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7178\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7179\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7180\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7181\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7182\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7183\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7184\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7185\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7186\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7187\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7188\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7189\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7190\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7191\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7192\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7193\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7194\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7195\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7196\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7197\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7198\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7199\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7200\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7201\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7202\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7203\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7204\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7205\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7206\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7207\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7208\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7209\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7210\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7211\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7212\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7213\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7214\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7215\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7216\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7217\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7218\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7219\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7220\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7221\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7222\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7223\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7224\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7225\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7226\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7227\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7228\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7229\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7230\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7231\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7232\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7233\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7234\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7235\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7236\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7237\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7238\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7239\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7240\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7241\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7242\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7243\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7244\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7245\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7246\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7247\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7248\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7249\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7250\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7251\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7252\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7253\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7254\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7255\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7256\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7257\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7258\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7259\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7260\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7261\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7262\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7263\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7264\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7265\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7266\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7267\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7268\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7269\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7270\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7271\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7272\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7273\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7274\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7275\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7276\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7277\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7278\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7279\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7280\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7281\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7282\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7283\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7284\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7285\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7286\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7287\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7288\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7289\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7290\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7291\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7292\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7293\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7294\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7295\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7296\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7297\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7298\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7299\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7300\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7301\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7302\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7303\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7304\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7305\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7306\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7307\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7308\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7309\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7310\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7311\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7312\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7313\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7314\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7315\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7316\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7317\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7318\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7319\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7320\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7321\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7322\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7323\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7324\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7325\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7326\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7327\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7328\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7329\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7330\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7331\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7332\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7333\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7334\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7335\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7336\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7337\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7338\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7339\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7340\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7341\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7342\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7343\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7344\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7345\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7346\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7347\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7348\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7349\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7350\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7351\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7352\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7353\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7354\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7355\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7356\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7357\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7358\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7359\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7360\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7361\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7362\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7363\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7364\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7365\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7366\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7367\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7368\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7369\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7370\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7371\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7372\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7373\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7374\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7375\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7376\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7377\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7378\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7379\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7380\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7381\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7382\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7383\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7384\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7385\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7386\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7387\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7388\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7389\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7390\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7391\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7392\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7393\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7394\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7395\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7396\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7397\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7398\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7399\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7400\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7401\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7402\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7403\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7404\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7405\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7406\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7407\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7408\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7409\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7410\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7411\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7412\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7413\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7414\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7415\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7416\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7417\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7418\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7419\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7420\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7421\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7422\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7423\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7424\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7425\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7426\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7427\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7428\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7429\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7430\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7431\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7432\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7433\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7434\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7435\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7436\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7437\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7438\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7439\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7440\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7441\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7442\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7443\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7444\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7445\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7446\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7447\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7448\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7449\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7450\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7451\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7452\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7453\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7454\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7455\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7456\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7457\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7458\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7459\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7460\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7461\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7462\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7463\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7464\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7465\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7466\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7467\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7468\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7469\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7470\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7471\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7472\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7473\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7474\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7475\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7476\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7477\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7478\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7479\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7480\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7481\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7482\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7483\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7484\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7485\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7486\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7487\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7488\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7489\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7490\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7491\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7492\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7493\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7494\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7495\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7496\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7497\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7498\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7499\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7500\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7501\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7502\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7503\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7504\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7505\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7506\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7507\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7508\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7509\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7510\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7511\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7512\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7513\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7514\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7515\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7516\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7517\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7518\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7519\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7520\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7521\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7522\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7523\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7524\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7525\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7526\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7527\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7528\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7529\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7530\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7531\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7532\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7533\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7534\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7535\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7536\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7537\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7538\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7539\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7540\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7541\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7542\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7543\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7544\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7545\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7546\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7547\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7548\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7549\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7550\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7551\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7552\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7553\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7554\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7555\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7556\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7557\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7558\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7559\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7560\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7561\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7562\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7563\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7564\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7565\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7566\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7567\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7568\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7569\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7570\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7571\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7572\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7573\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7574\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7575\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7576\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7577\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7578\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7579\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7580\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7581\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7582\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7583\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7584\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7585\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7586\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7587\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7588\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7589\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7590\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7591\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7592\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7593\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7594\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7595\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7596\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7597\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7598\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7599\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7600\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7601\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7602\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7603\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7604\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7605\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7606\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7607\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7608\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7609\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7610\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7611\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7612\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7613\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7614\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7615\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7616\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7617\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7618\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7619\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7620\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7621\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7622\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7623\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7624\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7625\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7626\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7627\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7628\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7629\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7630\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7631\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7632\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7633\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7634\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7635\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7636\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7637\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7638\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7639\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7640\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7641\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7642\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7643\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7644\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7645\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7646\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7647\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7648\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7649\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7650\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7651\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7652\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7653\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7654\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7655\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7656\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7657\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7658\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7659\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7660\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7661\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7662\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7663\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7664\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7665\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7666\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7667\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7668\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7669\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7670\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7671\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7672\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7673\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7674\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7675\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7676\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7677\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7678\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7679\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7680\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7681\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7682\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7683\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7684\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7685\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7686\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7687\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7688\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7689\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7690\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7691\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7692\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7693\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7694\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7695\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7696\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7697\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7698\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7699\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7700\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7701\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7702\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7703\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7704\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7705\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7706\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7707\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7708\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7709\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7710\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7711\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7712\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7713\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7714\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7715\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7716\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7717\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7718\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7719\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7720\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7721\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7722\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7723\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7724\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7725\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7726\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7727\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7728\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7729\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7730\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7731\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7732\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7733\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7734\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7735\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7736\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7737\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7738\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7739\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7740\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7741\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7742\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7743\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7744\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7745\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7746\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7747\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7748\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7749\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7750\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7751\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7752\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7753\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7754\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7755\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7756\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7757\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7758\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7759\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7760\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7761\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7762\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7763\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7764\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7765\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7766\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7767\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7768\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7769\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7770\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7771\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7772\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7773\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7774\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7775\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7776\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7777\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7778\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7779\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7780\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7781\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7782\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7783\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7784\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7785\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7786\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7787\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7788\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7789\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7790\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7791\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7792\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7793\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7794\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7795\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7796\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7797\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7798\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7799\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7800\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7801\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7802\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7803\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7804\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7805\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7806\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7807\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7808\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7809\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7810\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7811\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7812\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7813\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7814\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7815\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7816\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7817\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7818\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7819\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7820\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7821\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7822\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7823\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7824\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7825\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7826\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7827\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7828\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7829\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7830\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7831\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7832\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7833\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7834\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7835\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7836\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7837\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7838\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7839\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7840\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7841\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7842\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7843\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7844\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7845\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7846\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7847\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7848\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7849\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7850\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7851\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7852\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7853\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7854\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7855\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7856\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7857\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7858\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7859\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7860\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7861\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7862\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7863\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7864\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7865\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7866\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7867\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7868\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7869\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7870\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7871\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7872\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7873\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7874\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7875\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7876\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7877\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7878\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7879\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7880\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7881\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7882\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7883\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7884\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7885\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7886\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7887\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7888\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7889\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7890\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7891\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7892\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7893\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7894\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7895\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7896\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7897\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7898\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7899\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7900\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7901\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7902\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7903\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7904\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7905\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7906\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7907\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7908\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7909\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7910\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7911\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7912\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7913\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7914\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7915\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7916\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7917\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7918\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7919\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7920\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7921\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7922\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7923\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7924\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7925\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7926\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7927\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7928\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7929\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7930\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7931\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7932\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7933\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7934\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7935\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7936\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7937\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7938\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7939\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7940\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7941\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7942\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7943\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7944\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7945\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7946\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7947\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7948\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7949\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7950\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7951\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7952\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7953\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7954\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7955\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7956\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7957\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7958\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7959\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7960\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7961\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7962\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7963\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7964\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7965\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7966\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7967\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7968\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7969\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7970\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7971\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7972\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7973\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7974\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7975\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7976\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7977\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7978\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7979\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7980\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7981\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7982\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7983\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7984\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7985\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7986\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7987\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7988\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7989\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7990\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7991\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7992\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7993\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7994\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7995\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7996\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7997\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 7998\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 7999\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8000\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8001\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8002\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8003\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8004\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8005\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8006\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8007\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8008\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8009\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8010\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8011\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8012\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8013\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8014\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8015\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8016\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8017\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8018\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8019\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8020\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8021\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8022\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8023\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8024\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8025\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8026\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8027\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8028\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8029\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8030\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8031\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8032\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8033\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8034\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8035\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8036\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8037\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8038\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8039\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8040\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8041\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8042\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8043\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8044\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8045\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8046\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8047\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8048\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8049\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8050\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8051\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8052\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8053\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8054\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8055\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8056\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8057\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8058\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8059\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8060\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8061\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8062\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8063\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8064\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8065\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8066\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8067\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8068\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8069\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8070\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8071\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8072\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8073\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8074\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8075\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8076\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8077\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8078\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8079\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8080\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8081\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8082\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8083\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8084\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8085\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8086\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8087\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8088\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8089\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8090\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8091\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8092\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8093\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8094\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8095\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8096\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8097\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8098\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8099\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8100\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8101\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8102\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8103\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8104\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8105\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8106\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8107\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8108\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8109\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8110\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8111\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8112\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8113\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8114\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8115\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8116\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8117\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8118\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8119\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8120\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8121\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8122\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8123\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8124\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8125\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8126\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8127\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8128\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8129\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8130\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8131\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8132\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8133\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8134\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8135\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8136\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8137\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8138\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8139\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8140\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8141\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8142\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8143\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8144\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8145\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8146\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8147\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8148\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8149\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8150\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8151\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8152\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8153\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8154\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8155\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8156\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8157\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8158\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8159\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8160\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8161\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8162\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8163\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8164\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8165\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8166\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8167\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8168\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8169\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8170\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8171\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8172\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8173\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8174\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8175\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8176\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8177\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8178\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8179\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8180\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8181\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8182\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8183\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8184\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8185\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8186\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8187\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8188\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8189\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8190\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8191\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8192\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8193\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8194\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8195\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8196\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8197\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8198\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8199\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8200\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8201\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8202\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8203\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8204\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8205\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8206\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8207\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8208\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8209\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8210\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8211\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8212\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8213\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8214\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8215\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8216\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8217\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8218\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8219\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8220\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8221\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8222\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8223\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8224\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8225\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8226\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8227\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8228\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8229\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8230\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8231\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8232\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8233\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8234\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8235\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8236\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8237\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8238\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8239\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8240\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8241\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8242\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8243\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8244\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8245\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8246\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8247\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8248\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8249\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8250\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8251\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8252\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8253\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8254\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8255\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8256\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8257\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8258\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8259\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8260\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8261\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8262\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8263\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8264\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8265\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8266\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8267\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8268\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8269\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8270\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8271\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8272\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8273\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8274\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8275\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8276\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8277\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8278\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8279\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8280\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8281\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8282\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8283\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8284\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8285\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8286\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8287\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8288\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8289\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8290\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8291\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8292\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8293\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8294\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8295\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8296\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8297\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8298\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8299\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8300\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8301\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8302\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8303\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8304\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8305\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8306\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8307\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8308\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8309\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8310\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8311\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8312\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8313\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8314\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8315\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8316\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8317\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8318\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8319\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8320\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8321\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8322\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8323\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8324\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8325\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8326\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8327\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8328\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8329\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8330\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8331\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8332\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8333\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8334\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8335\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8336\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8337\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8338\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8339\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8340\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8341\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8342\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8343\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8344\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8345\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8346\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8347\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8348\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8349\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8350\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8351\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8352\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8353\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8354\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8355\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8356\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8357\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8358\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8359\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8360\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8361\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8362\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8363\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8364\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8365\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8366\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8367\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8368\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8369\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8370\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8371\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8372\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8373\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8374\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8375\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8376\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8377\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8378\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8379\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8380\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8381\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8382\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8383\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8384\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8385\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8386\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8387\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8388\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8389\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8390\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8391\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8392\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8393\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8394\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8395\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8396\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8397\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8398\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8399\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8400\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8401\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8402\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8403\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8404\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8405\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8406\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8407\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8408\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8409\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8410\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8411\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8412\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8413\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8414\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8415\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8416\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8417\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8418\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8419\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8420\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8421\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8422\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8423\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8424\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8425\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8426\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8427\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8428\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8429\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8430\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8431\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8432\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8433\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8434\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8435\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8436\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8437\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8438\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8439\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8440\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8441\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8442\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8443\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8444\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8445\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8446\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8447\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8448\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8449\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8450\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8451\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8452\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8453\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8454\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8455\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8456\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8457\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8458\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8459\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8460\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8461\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8462\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8463\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8464\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8465\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8466\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8467\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8468\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8469\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8470\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8471\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8472\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8473\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8474\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8475\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8476\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8477\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8478\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8479\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8480\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8481\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8482\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8483\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8484\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8485\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8486\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8487\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8488\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8489\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8490\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8491\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8492\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8493\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8494\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8495\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8496\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8497\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8498\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8499\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8500\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8501\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8502\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8503\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8504\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8505\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8506\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8507\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8508\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8509\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8510\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8511\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8512\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8513\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8514\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8515\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8516\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8517\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8518\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8519\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8520\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8521\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8522\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8523\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8524\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8525\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8526\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8527\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8528\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8529\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8530\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8531\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8532\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8533\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8534\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8535\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8536\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8537\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8538\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8539\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8540\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8541\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8542\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8543\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8544\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8545\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8546\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8547\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8548\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8549\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8550\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8551\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8552\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8553\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8554\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8555\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8556\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8557\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8558\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8559\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8560\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8561\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8562\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8563\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8564\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8565\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8566\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8567\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8568\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8569\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8570\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8571\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8572\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8573\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8574\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8575\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8576\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8577\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8578\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8579\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8580\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8581\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8582\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8583\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8584\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8585\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8586\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8587\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8588\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8589\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8590\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8591\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8592\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8593\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8594\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8595\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8596\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8597\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8598\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8599\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8600\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8601\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8602\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8603\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8604\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8605\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8606\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8607\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8608\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8609\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8610\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8611\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8612\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8613\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8614\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8615\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8616\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8617\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8618\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8619\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8620\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8621\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8622\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8623\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8624\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8625\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8626\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8627\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8628\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8629\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8630\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8631\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8632\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8633\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8634\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8635\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8636\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8637\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8638\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8639\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8640\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8641\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8642\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8643\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8644\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8645\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8646\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8647\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8648\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8649\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8650\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8651\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8652\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8653\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8654\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8655\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8656\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8657\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8658\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8659\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8660\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8661\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8662\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8663\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8664\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8665\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8666\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8667\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8668\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8669\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8670\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8671\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8672\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8673\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8674\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8675\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8676\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8677\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8678\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8679\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8680\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8681\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8682\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8683\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8684\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8685\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8686\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8687\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8688\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8689\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8690\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8691\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8692\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8693\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8694\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8695\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8696\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8697\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8698\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8699\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8700\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8701\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8702\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8703\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8704\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8705\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8706\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8707\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8708\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8709\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8710\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8711\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8712\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8713\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8714\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8715\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8716\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8717\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8718\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8719\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8720\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8721\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8722\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8723\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8724\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8725\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8726\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8727\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8728\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8729\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8730\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8731\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8732\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8733\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8734\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8735\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8736\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8737\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8738\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8739\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8740\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8741\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8742\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8743\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8744\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8745\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8746\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8747\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8748\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8749\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8750\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8751\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8752\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8753\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8754\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8755\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8756\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8757\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8758\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8759\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8760\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8761\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8762\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8763\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8764\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8765\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8766\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8767\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8768\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8769\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8770\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8771\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8772\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8773\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8774\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8775\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8776\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8777\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8778\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8779\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8780\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8781\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8782\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8783\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8784\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8785\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8786\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8787\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8788\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8789\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8790\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8791\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8792\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8793\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8794\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8795\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8796\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8797\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8798\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8799\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8800\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8801\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8802\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8803\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8804\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8805\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8806\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8807\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8808\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8809\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8810\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8811\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8812\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8813\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8814\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8815\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8816\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8817\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8818\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8819\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8820\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8821\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8822\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8823\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8824\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8825\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8826\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8827\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8828\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8829\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8830\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8831\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8832\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8833\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8834\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8835\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8836\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8837\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8838\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8839\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8840\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8841\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8842\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8843\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8844\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8845\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8846\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8847\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8848\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8849\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8850\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8851\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8852\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8853\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8854\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8855\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8856\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8857\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8858\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8859\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8860\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8861\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8862\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8863\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8864\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8865\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8866\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8867\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8868\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8869\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8870\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8871\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8872\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8873\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8874\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8875\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8876\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8877\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8878\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8879\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8880\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8881\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8882\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8883\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8884\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8885\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8886\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8887\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8888\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8889\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8890\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8891\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8892\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8893\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8894\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8895\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8896\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8897\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8898\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8899\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8900\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8901\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8902\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8903\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8904\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8905\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8906\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8907\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8908\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8909\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8910\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8911\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8912\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8913\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8914\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8915\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8916\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8917\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8918\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8919\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8920\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8921\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8922\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8923\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8924\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8925\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8926\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8927\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8928\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8929\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8930\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8931\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8932\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8933\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8934\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8935\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8936\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8937\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8938\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8939\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8940\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8941\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8942\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8943\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8944\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8945\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8946\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8947\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8948\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8949\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8950\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8951\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8952\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8953\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8954\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8955\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8956\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8957\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8958\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8959\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8960\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8961\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8962\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8963\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8964\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8965\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8966\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8967\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8968\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8969\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8970\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8971\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8972\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8973\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8974\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8975\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8976\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8977\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8978\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8979\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8980\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8981\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8982\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8983\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8984\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8985\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8986\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8987\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8988\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8989\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8990\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8991\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8992\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8993\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8994\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8995\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8996\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8997\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 8998\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 8999\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9000\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9001\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9002\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9003\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9004\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9005\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9006\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9007\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9008\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9009\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9010\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9011\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9012\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9013\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9014\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9015\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9016\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9017\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9018\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9019\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9020\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9021\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9022\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9023\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9024\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9025\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9026\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9027\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9028\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9029\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9030\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9031\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9032\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9033\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9034\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9035\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9036\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9037\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9038\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9039\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9040\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9041\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9042\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9043\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9044\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9045\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9046\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9047\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9048\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9049\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9050\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9051\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9052\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9053\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9054\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9055\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9056\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9057\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9058\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9059\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9060\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9061\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9062\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9063\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9064\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9065\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9066\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9067\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9068\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9069\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9070\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9071\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9072\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9073\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9074\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9075\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9076\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9077\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9078\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9079\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9080\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9081\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9082\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9083\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9084\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9085\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9086\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9087\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9088\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9089\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9090\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9091\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9092\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9093\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9094\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9095\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9096\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9097\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9098\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9099\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9100\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9101\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9102\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9103\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9104\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9105\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9106\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9107\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9108\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9109\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9110\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9111\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9112\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9113\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9114\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9115\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9116\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9117\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9118\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9119\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9120\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9121\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9122\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9123\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9124\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9125\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9126\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9127\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9128\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9129\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9130\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9131\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9132\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9133\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9134\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9135\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9136\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9137\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9138\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9139\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9140\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9141\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9142\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9143\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9144\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9145\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9146\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9147\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9148\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9149\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9150\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9151\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9152\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9153\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9154\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9155\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9156\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9157\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9158\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9159\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9160\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9161\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9162\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9163\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9164\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9165\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9166\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9167\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9168\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9169\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9170\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9171\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9172\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9173\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9174\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9175\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9176\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9177\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9178\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9179\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9180\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9181\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9182\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9183\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9184\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9185\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9186\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9187\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9188\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9189\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9190\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9191\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9192\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9193\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9194\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9195\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9196\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9197\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9198\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9199\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9200\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9201\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9202\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9203\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9204\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9205\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9206\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9207\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9208\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9209\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9210\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9211\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9212\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9213\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9214\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9215\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9216\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9217\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9218\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9219\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9220\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9221\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9222\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9223\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9224\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9225\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9226\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9227\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9228\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9229\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9230\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9231\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9232\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9233\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9234\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9235\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9236\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9237\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9238\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9239\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9240\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9241\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9242\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9243\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9244\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9245\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9246\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9247\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9248\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9249\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9250\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9251\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9252\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9253\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9254\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9255\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9256\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9257\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9258\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9259\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9260\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9261\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9262\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9263\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9264\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9265\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9266\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9267\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9268\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9269\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9270\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9271\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9272\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9273\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9274\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9275\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9276\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9277\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9278\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9279\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9280\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9281\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9282\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9283\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9284\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9285\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9286\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9287\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9288\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9289\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9290\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9291\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9292\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9293\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9294\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9295\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9296\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9297\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9298\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9299\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9300\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9301\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9302\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9303\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9304\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9305\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9306\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9307\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9308\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9309\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9310\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9311\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9312\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9313\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9314\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9315\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9316\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9317\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9318\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9319\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9320\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9321\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9322\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9323\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9324\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9325\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9326\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9327\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9328\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9329\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9330\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9331\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9332\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9333\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9334\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9335\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9336\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9337\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9338\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9339\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9340\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9341\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9342\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9343\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9344\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9345\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9346\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9347\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9348\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9349\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9350\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9351\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9352\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9353\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9354\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9355\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9356\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9357\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9358\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9359\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9360\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9361\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9362\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9363\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9364\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9365\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9366\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9367\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9368\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9369\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9370\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9371\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9372\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9373\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9374\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9375\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9376\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9377\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9378\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9379\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9380\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9381\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9382\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9383\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9384\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9385\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9386\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9387\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9388\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9389\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9390\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9391\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9392\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9393\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9394\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9395\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9396\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9397\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9398\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9399\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9400\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9401\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9402\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9403\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9404\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9405\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9406\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9407\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9408\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9409\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9410\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9411\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9412\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9413\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9414\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9415\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9416\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9417\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9418\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9419\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9420\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9421\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9422\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9423\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9424\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9425\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9426\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9427\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9428\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9429\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9430\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9431\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9432\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9433\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9434\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9435\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9436\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9437\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9438\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9439\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9440\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9441\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9442\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9443\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9444\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9445\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9446\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9447\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9448\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9449\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9450\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9451\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9452\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9453\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9454\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9455\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9456\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9457\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9458\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9459\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9460\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9461\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9462\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9463\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9464\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9465\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9466\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9467\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9468\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9469\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9470\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9471\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9472\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9473\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9474\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9475\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9476\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9477\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9478\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9479\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9480\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9481\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9482\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9483\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9484\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9485\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9486\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9487\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9488\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9489\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9490\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9491\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9492\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9493\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9494\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9495\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9496\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9497\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9498\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9499\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9500\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9501\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9502\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9503\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9504\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9505\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9506\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9507\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9508\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9509\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9510\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9511\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9512\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9513\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9514\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9515\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9516\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9517\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9518\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9519\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9520\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9521\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9522\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9523\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9524\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9525\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9526\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9527\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9528\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9529\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9530\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9531\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9532\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9533\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9534\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9535\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9536\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9537\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9538\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9539\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9540\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9541\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9542\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9543\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9544\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9545\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9546\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9547\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9548\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9549\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9550\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9551\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9552\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9553\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9554\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9555\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9556\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9557\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9558\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9559\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9560\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9561\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9562\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9563\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9564\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9565\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9566\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9567\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9568\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9569\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9570\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9571\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9572\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9573\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9574\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9575\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9576\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9577\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9578\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9579\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9580\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9581\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9582\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9583\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9584\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9585\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9586\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9587\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9588\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9589\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9590\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9591\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9592\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9593\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9594\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9595\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9596\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9597\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9598\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9599\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9600\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9601\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9602\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9603\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9604\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9605\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9606\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9607\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9608\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9609\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9610\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9611\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9612\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9613\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9614\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9615\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9616\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9617\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9618\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9619\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9620\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9621\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9622\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9623\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9624\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9625\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9626\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9627\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9628\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9629\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9630\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9631\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9632\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9633\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9634\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9635\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9636\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9637\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9638\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9639\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9640\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9641\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9642\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9643\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9644\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9645\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9646\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9647\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9648\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9649\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9650\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9651\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9652\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9653\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9654\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9655\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9656\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9657\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9658\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9659\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9660\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9661\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9662\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9663\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9664\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9665\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9666\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9667\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9668\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9669\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9670\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9671\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9672\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9673\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9674\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9675\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9676\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9677\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9678\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9679\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9680\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9681\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9682\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9683\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9684\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9685\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9686\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9687\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9688\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9689\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9690\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9691\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9692\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9693\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9694\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9695\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9696\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9697\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9698\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9699\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9700\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9701\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9702\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9703\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9704\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9705\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9706\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9707\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9708\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9709\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9710\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9711\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9712\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9713\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9714\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9715\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9716\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9717\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9718\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9719\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9720\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9721\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9722\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9723\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9724\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9725\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9726\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9727\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9728\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9729\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9730\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9731\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9732\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9733\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9734\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9735\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9736\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9737\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9738\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9739\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9740\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9741\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9742\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9743\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9744\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9745\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9746\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9747\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9748\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9749\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9750\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9751\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9752\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9753\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9754\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9755\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9756\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9757\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9758\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9759\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9760\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9761\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9762\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9763\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9764\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9765\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9766\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9767\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9768\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9769\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9770\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9771\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9772\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9773\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9774\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9775\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9776\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9777\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9778\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9779\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9780\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9781\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9782\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9783\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9784\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9785\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9786\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9787\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9788\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9789\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9790\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9791\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9792\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9793\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9794\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9795\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9796\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9797\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9798\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9799\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9800\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9801\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9802\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9803\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9804\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9805\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9806\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9807\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9808\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9809\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9810\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9811\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9812\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9813\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9814\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9815\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9816\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9817\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9818\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9819\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9820\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9821\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9822\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9823\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9824\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9825\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9826\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9827\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9828\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9829\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9830\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9831\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9832\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9833\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9834\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9835\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9836\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9837\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9838\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9839\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9840\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9841\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9842\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9843\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9844\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9845\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9846\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9847\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9848\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9849\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9850\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9851\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9852\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9853\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9854\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9855\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9856\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9857\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9858\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9859\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9860\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9861\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9862\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9863\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9864\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9865\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9866\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9867\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9868\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9869\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9870\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9871\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9872\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9873\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9874\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9875\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9876\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9877\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9878\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9879\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9880\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9881\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9882\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9883\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9884\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9885\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9886\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9887\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9888\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9889\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9890\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9891\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9892\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9893\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9894\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9895\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9896\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9897\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9898\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9899\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9900\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9901\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9902\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9903\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9904\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9905\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9906\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9907\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9908\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9909\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9910\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9911\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9912\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9913\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9914\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9915\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9916\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9917\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9918\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9919\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9920\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9921\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9922\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9923\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9924\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9925\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9926\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9927\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9928\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9929\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9930\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9931\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9932\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9933\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9934\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9935\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9936\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9937\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9938\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9939\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9940\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9941\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9942\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9943\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9944\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9945\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9946\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9947\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9948\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9949\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9950\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9951\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9952\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9953\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9954\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9955\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9956\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9957\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9958\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9959\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9960\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9961\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9962\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9963\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9964\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9965\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9966\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9967\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9968\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9969\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9970\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9971\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9972\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9973\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9974\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9975\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9976\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9977\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9978\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9979\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9980\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9981\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9982\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9983\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9984\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9985\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9986\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9987\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9988\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9989\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9990\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9991\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9992\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9993\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9994\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9995\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9996\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9997\n","m 2.000000000000001, b 2.9999999999999947, cost 1.0255191767873153e-29 iteration 9998\n","m 2.000000000000002, b 2.999999999999995, cost 1.0255191767873153e-29 iteration 9999\n"]}]}]}